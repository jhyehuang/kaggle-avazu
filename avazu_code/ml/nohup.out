2018-07-01 15:22:44,436 - DEBUG - data_preprocessing.py:204 - data1.shape:(6865066, 5)
2018-07-01 15:22:44,436 - DEBUG - data_preprocessing.py:205 - data2.shape:(6865066, 5)
2018-07-01 15:22:44,735 - DEBUG - data_preprocessing.py:208 - 结果.shape:(6865066, 10)
2018-07-01 15:22:44,735 - DEBUG - data_preprocessing.py:209 - 耗时0.000148773193359375
2018-07-01 15:23:05,677 - DEBUG - data_preprocessing.py:204 - data1.shape:(6865066, 10)
2018-07-01 15:23:05,678 - DEBUG - data_preprocessing.py:205 - data2.shape:(6865066, 60)
2018-07-01 15:23:07,823 - DEBUG - data_preprocessing.py:208 - 结果.shape:(6865066, 70)
2018-07-01 15:23:07,823 - DEBUG - data_preprocessing.py:209 - 耗时0.00015616416931152344
2018-07-01 15:23:12,092 - DEBUG - data_preprocessing.py:204 - data1.shape:(6865066, 70)
2018-07-01 15:23:12,092 - DEBUG - data_preprocessing.py:205 - data2.shape:(6865066, 11)
2018-07-01 15:23:18,710 - DEBUG - data_preprocessing.py:208 - 结果.shape:(6865066, 81)
2018-07-01 15:23:18,710 - DEBUG - data_preprocessing.py:209 - 耗时0.0001533031463623047
2018-07-01 15:23:36,568 - DEBUG - data_preprocessing.py:204 - data1.shape:(6865066, 81)
2018-07-01 15:23:36,568 - DEBUG - data_preprocessing.py:205 - data2.shape:(6865066, 20)
2018-07-01 15:23:44,290 - DEBUG - data_preprocessing.py:208 - 结果.shape:(6865066, 101)
2018-07-01 15:23:44,291 - DEBUG - data_preprocessing.py:209 - 耗时0.00016021728515625
2018-07-01 15:23:44,400 - DEBUG - data_preprocessing.py:382 - Index(['C14', 'C17', 'C21', 'device_model', 'site_domain', 'one_day',
       'one_day_hour', 'day_hour_prev', 'day_hour_next', 'is_work_day',
       ...
       'exptv_C17C21', 'cnttv_C17C21', 'exptv_C17site_domain',
       'cnttv_C17site_domain', 'exptv_C21device_model',
       'cnttv_C21device_model', 'exptv_C21site_domain', 'cnttv_C21site_domain',
       'exptv_site_domaindevice_model', 'cnttv_site_domaindevice_model'],
      dtype='object', length=101)
2018-07-01 15:23:45,884 - DEBUG - data_preprocessing.py:204 - data1.shape:(4577464, 5)
2018-07-01 15:23:45,884 - DEBUG - data_preprocessing.py:205 - data2.shape:(4577464, 5)
2018-07-01 15:23:45,949 - DEBUG - data_preprocessing.py:208 - 结果.shape:(4577464, 10)
2018-07-01 15:23:45,949 - DEBUG - data_preprocessing.py:209 - 耗时0.000152587890625
2018-07-01 15:23:59,307 - DEBUG - data_preprocessing.py:204 - data1.shape:(4577464, 10)
2018-07-01 15:23:59,307 - DEBUG - data_preprocessing.py:205 - data2.shape:(4577464, 60)
2018-07-01 15:24:00,712 - DEBUG - data_preprocessing.py:208 - 结果.shape:(4577464, 70)
2018-07-01 15:24:00,712 - DEBUG - data_preprocessing.py:209 - 耗时0.0001590251922607422
2018-07-01 15:24:03,529 - DEBUG - data_preprocessing.py:204 - data1.shape:(4577464, 70)
2018-07-01 15:24:03,529 - DEBUG - data_preprocessing.py:205 - data2.shape:(4577464, 11)
2018-07-01 15:24:07,929 - DEBUG - data_preprocessing.py:208 - 结果.shape:(4577464, 81)
2018-07-01 15:24:07,929 - DEBUG - data_preprocessing.py:209 - 耗时0.00015306472778320312
2018-07-01 15:24:20,302 - DEBUG - data_preprocessing.py:204 - data1.shape:(4577464, 81)
2018-07-01 15:24:20,302 - DEBUG - data_preprocessing.py:205 - data2.shape:(4577464, 20)
2018-07-01 15:24:25,460 - DEBUG - data_preprocessing.py:208 - 结果.shape:(4577464, 101)
2018-07-01 15:24:25,460 - DEBUG - data_preprocessing.py:209 - 耗时0.00016355514526367188
2018-07-01 15:24:25,532 - DEBUG - data_preprocessing.py:391 - (6865066, 101)
2018-07-01 15:24:25,532 - DEBUG - data_preprocessing.py:392 - (4577464, 101)
/home/zhijiehuang/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.
  FutureWarning)
2018-07-01 15:24:51,514 - DEBUG - data_preprocessing.py:411 -            C14   C17  C21  device_model  site_domain  one_day  one_day_hour  \
2445499  21611  2480   61          5524         6124        1             0   

         day_hour_prev  day_hour_next  is_work_day  \
2445499             -1              1            1   

                     ...                exptv_C17C21  cnttv_C17C21  \
2445499              ...                    0.239964        796075   

         exptv_C17site_domain  cnttv_C17site_domain  exptv_C21device_model  \
2445499              0.236913                501032               0.188062   

         cnttv_C21device_model  exptv_C21site_domain  cnttv_C21site_domain  \
2445499                 226216              0.163896               2897548   

         exptv_site_domaindevice_model  cnttv_site_domaindevice_model  
2445499                       0.114806                         384227  

[1 rows x 100 columns]
2018-07-01 15:24:51,520 - DEBUG - data_preprocessing.py:412 - 2445499    0
Name: click, dtype: int64
2018-07-01 15:24:51,524 - DEBUG - lgbm.py:270 - 设置参数
2018-07-01 15:24:51,525 - DEBUG - lgbm.py:276 - 开始训练
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Info] Number of positive: 3090158, number of negative: 3088401
[LightGBM] [Info] This is the GPU trainer!!
[LightGBM] [Info] Total Bins 646
[LightGBM] [Info] Number of data: 6178559, number of used features: 99
[LightGBM] [Info] Using requested OpenCL platform 0 device 0
[LightGBM] [Info] Using GPU Device: GeForce GTX 1070 Ti, Vendor: NVIDIA Corporation
[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...
[LightGBM] [Info] GPU programs have been built
[LightGBM] [Info] Size of histogram bin entry: 12
[LightGBM] [Info] 98 dense feature groups (306.40 MB) transfered to GPU in 0.358357 secs. 0 sparse feature groups
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500142 -> initscore=0.000569
[LightGBM] [Info] Start training from score 0.000569
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
设置参数
(6865066, 101)
[1]	valid_0's binary_logloss: 0.692103
Training until validation scores don't improve for 30 rounds.
[2]	valid_0's binary_logloss: 0.691103
[3]	valid_0's binary_logloss: 0.689974
[4]	valid_0's binary_logloss: 0.689162
[5]	valid_0's binary_logloss: 0.688294
[6]	valid_0's binary_logloss: 0.687423
[7]	valid_0's binary_logloss: 0.68643
[8]	valid_0's binary_logloss: 0.686688
[9]	valid_0's binary_logloss: 0.685682
[10]	valid_0's binary_logloss: 0.684782
[11]	valid_0's binary_logloss: 0.68385
[12]	valid_0's binary_logloss: 0.684123
[13]	valid_0's binary_logloss: 0.683135
[14]	valid_0's binary_logloss: 0.682253
[15]	valid_0's binary_logloss: 0.68139
[16]	valid_0's binary_logloss: 0.680552
[17]	valid_0's binary_logloss: 0.679749
[18]	valid_0's binary_logloss: 0.678836
[19]	valid_0's binary_logloss: 0.677955
[20]	valid_0's binary_logloss: 0.67721
[21]	valid_0's binary_logloss: 0.677377
[22]	valid_0's binary_logloss: 0.676496
[23]	valid_0's binary_logloss: 0.675846
[24]	valid_0's binary_logloss: 0.675036
[25]	valid_0's binary_logloss: 0.674222
[26]	valid_0's binary_logloss: 0.673409
[27]	valid_0's binary_logloss: 0.672775
[28]	valid_0's binary_logloss: 0.673029
[29]	valid_0's binary_logloss: 0.672236
[30]	valid_0's binary_logloss: 0.671456
[31]	valid_0's binary_logloss: 0.671452
[32]	valid_0's binary_logloss: 0.670654
[33]	valid_0's binary_logloss: 0.669984
[34]	valid_0's binary_logloss: 0.669329
[35]	valid_0's binary_logloss: 0.669735
[36]	valid_0's binary_logloss: 0.670168
[37]	valid_0's binary_logloss: 0.669602
[38]	valid_0's binary_logloss: 0.668994
[39]	valid_0's binary_logloss: 0.668296
[40]	valid_0's binary_logloss: 0.668166
[41]	valid_0's binary_logloss: 0.668532
[42]	valid_0's binary_logloss: 0.667693
[43]	valid_0's binary_logloss: 0.668027
[44]	valid_0's binary_logloss: 0.667396
[45]	valid_0's binary_logloss: 0.66667
[46]	valid_0's binary_logloss: 0.667184
[47]	valid_0's binary_logloss: 0.666619
[48]	valid_0's binary_logloss: 0.666494
[49]	valid_0's binary_logloss: 0.666888
[50]	valid_0's binary_logloss: 0.667319
[51]	valid_0's binary_logloss: 0.666744
[52]	valid_0's binary_logloss: 0.665982
[53]	valid_0's binary_logloss: 0.666298
[54]	valid_0's binary_logloss: 0.665696
[55]	valid_0's binary_logloss: 0.665131
[56]	valid_0's binary_logloss: 0.665573
[57]	valid_0's binary_logloss: 0.664915
[58]	valid_0's binary_logloss: 0.665332
[59]	valid_0's binary_logloss: 0.665722
[60]	valid_0's binary_logloss: 0.665074
[61]	valid_0's binary_logloss: 0.665381
[62]	valid_0's binary_logloss: 0.664821
[63]	valid_0's binary_logloss: 0.664264
[64]	valid_0's binary_logloss: 0.664552
[65]	valid_0's binary_logloss: 0.664887
[66]	valid_0's binary_logloss: 0.664171
[67]	valid_0's binary_logloss: 0.66372
[68]	valid_0's binary_logloss: 0.663013
[69]	valid_0's binary_logloss: 0.663396
[70]	valid_0's binary_logloss: 0.663605
[71]	valid_0's binary_logloss: 0.663857
[72]	valid_0's binary_logloss: 0.663139
[73]	valid_0's binary_logloss: 0.662581
[74]	valid_0's binary_logloss: 0.662844
[75]	valid_0's binary_logloss: 0.662383
[76]	valid_0's binary_logloss: 0.662466
[77]	valid_0's binary_logloss: 0.662679
[78]	valid_0's binary_logloss: 0.662904
[79]	valid_0's binary_logloss: 0.662369
[80]	valid_0's binary_logloss: 0.661819
[81]	valid_0's binary_logloss: 0.66209
[82]	valid_0's binary_logloss: 0.661525
[83]	valid_0's binary_logloss: 0.66185
[84]	valid_0's binary_logloss: 0.662187
[85]	valid_0's binary_logloss: 0.662492
[86]	valid_0's binary_logloss: 0.661941
[87]	valid_0's binary_logloss: 0.661306
[88]	valid_0's binary_logloss: 0.661685
[89]	valid_0's binary_logloss: 0.661923
[90]	valid_0's binary_logloss: 0.66224
[91]	valid_0's binary_logloss: 0.662544
[92]	valid_0's binary_logloss: 0.662083
[93]	valid_0's binary_logloss: 0.661533
[94]	valid_0's binary_logloss: 0.66183
[95]	valid_0's binary_logloss: 0.66208
[96]	valid_0's binary_logloss: 0.662339
[97]	valid_0's binary_logloss: 0.66185
[98]	valid_0's binary_logloss: 0.662089
[99]	valid_0's binary_logloss: 0.661554
[100]	valid_0's binary_logloss: 0.661093
[101]	valid_0's binary_logloss: 0.66141
[102]	valid_0's binary_logloss: 0.661715
[103]	valid_0's binary_logloss: 0.661966
[104]	valid_0's binary_logloss: 0.661438
[105]	valid_0's binary_logloss: 0.661744
[106]	valid_0's binary_logloss: 0.662032
[107]	valid_0's binary_logloss: 0.662299
[108]	valid_0's binary_logloss: 0.661755
[109]	valid_0's binary_logloss: 0.661996
[110]	valid_0's binary_logloss: 0.66227
[111]	valid_0's binary_logloss: 0.661619
[112]	valid_0's binary_logloss: 0.661156
[113]	valid_0's binary_logloss: 0.660676
[114]	valid_0's binary_logloss: 0.660191
[115]	valid_0's binary_logloss: 0.659544
[116]	valid_0's binary_logloss: 0.659049
[117]	valid_0's binary_logloss: 0.65926
[118]	valid_0's binary_logloss: 0.658631
[119]	valid_0's binary_logloss: 0.658868
[120]	valid_0's binary_logloss: 0.659131
[121]	valid_0's binary_logloss: 0.65941
[122]	valid_0's binary_logloss: 0.659657
[123]	valid_0's binary_logloss: 0.659006
[124]	valid_0's binary_logloss: 0.658533
[125]	valid_0's binary_logloss: 0.658741
[126]	valid_0's binary_logloss: 0.65903
[127]	valid_0's binary_logloss: 0.658549
[128]	valid_0's binary_logloss: 0.658786
[129]	valid_0's binary_logloss: 0.658224
[130]	valid_0's binary_logloss: 0.657739
[131]	valid_0's binary_logloss: 0.657973
[132]	valid_0's binary_logloss: 0.657459
[133]	valid_0's binary_logloss: 0.657064
[134]	valid_0's binary_logloss: 0.657334
[135]	valid_0's binary_logloss: 0.656791
[136]	valid_0's binary_logloss: 0.657077
[137]	valid_0's binary_logloss: 0.657319
[138]	valid_0's binary_logloss: 0.656751
[139]	valid_0's binary_logloss: 0.65626
[140]	valid_0's binary_logloss: 0.656537
[141]	valid_0's binary_logloss: 0.656784
[142]	valid_0's binary_logloss: 0.657029
[143]	valid_0's binary_logloss: 0.656473
[144]	valid_0's binary_logloss: 0.656682
[145]	valid_0's binary_logloss: 0.656325
[146]	valid_0's binary_logloss: 0.656593
[147]	valid_0's binary_logloss: 0.656853
[148]	valid_0's binary_logloss: 0.657112
[149]	valid_0's binary_logloss: 0.656561
[150]	valid_0's binary_logloss: 0.655973
[151]	valid_0's binary_logloss: 0.656247
[152]	valid_0's binary_logloss: 0.656518
[153]	valid_0's binary_logloss: 0.655925
[154]	valid_0's binary_logloss: 0.656156
[155]	valid_0's binary_logloss: 0.655695
[156]	valid_0's binary_logloss: 0.655978
[157]	valid_0's binary_logloss: 0.656093
[158]	valid_0's binary_logloss: 0.656378
[159]	valid_0's binary_logloss: 0.656663
[160]	valid_0's binary_logloss: 0.656941
[161]	valid_0's binary_logloss: 0.656492
[162]	valid_0's binary_logloss: 0.656689
[163]	valid_0's binary_logloss: 0.656151
[164]	valid_0's binary_logloss: 0.655574
[165]	valid_0's binary_logloss: 0.655006
[166]	valid_0's binary_logloss: 0.65446
[167]	valid_0's binary_logloss: 0.65402
[168]	valid_0's binary_logloss: 0.653614
[169]	valid_0's binary_logloss: 0.653246
[170]	valid_0's binary_logloss: 0.653498
[171]	valid_0's binary_logloss: 0.652974
[172]	valid_0's binary_logloss: 0.653194
[173]	valid_0's binary_logloss: 0.652788
[174]	valid_0's binary_logloss: 0.652384
[175]	valid_0's binary_logloss: 0.651988
[176]	valid_0's binary_logloss: 0.652214
[177]	valid_0's binary_logloss: 0.652456
[178]	valid_0's binary_logloss: 0.652684
[179]	valid_0's binary_logloss: 0.652269
[180]	valid_0's binary_logloss: 0.652499
[181]	valid_0's binary_logloss: 0.65207
[182]	valid_0's binary_logloss: 0.651565
[183]	valid_0's binary_logloss: 0.651035
[184]	valid_0's binary_logloss: 0.650577
[185]	valid_0's binary_logloss: 0.650884
[186]	valid_0's binary_logloss: 0.650398
[187]	valid_0's binary_logloss: 0.649959
[188]	valid_0's binary_logloss: 0.649537
[189]	valid_0's binary_logloss: 0.649822
[190]	valid_0's binary_logloss: 0.650062
[191]	valid_0's binary_logloss: 0.649681
[192]	valid_0's binary_logloss: 0.64933
[193]	valid_0's binary_logloss: 0.648998
[194]	valid_0's binary_logloss: 0.649232
[195]	valid_0's binary_logloss: 0.649432
[196]	valid_0's binary_logloss: 0.649043
[197]	valid_0's binary_logloss: 0.649226
[198]	valid_0's binary_logloss: 0.649443
[199]	valid_0's binary_logloss: 0.648977
[200]	valid_0's binary_logloss: 0.649233
[201]	valid_0's binary_logloss: 0.649478[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf

[202]	valid_0's binary_logloss: 0.649715
[203]	valid_0's binary_logloss: 0.64931
[204]	valid_0's binary_logloss: 0.649508
[205]	valid_0's binary_logloss: 0.649739
[206]	valid_0's binary_logloss: 0.649288
[207]	valid_0's binary_logloss: 0.649501
[208]	valid_0's binary_logloss: 0.649124
[209]	valid_0's binary_logloss: 0.649375
[210]	valid_0's binary_logloss: 0.649583
[211]	valid_0's binary_logloss: 0.649802
[212]	valid_0's binary_logloss: 0.649384
[213]	valid_0's binary_logloss: 0.649053
[214]	valid_0's binary_logloss: 0.648748
[215]	valid_0's binary_logloss: 0.648386
[216]	valid_0's binary_logloss: 0.648615
[217]	valid_0's binary_logloss: 0.64826
[218]	valid_0's binary_logloss: 0.647908
[219]	valid_0's binary_logloss: 0.648119
[220]	valid_0's binary_logloss: 0.64765
[221]	valid_0's binary_logloss: 0.64787
[222]	valid_0's binary_logloss: 0.647527
[223]	valid_0's binary_logloss: 0.647157
[224]	valid_0's binary_logloss: 0.647396
[225]	valid_0's binary_logloss: 0.647661
[226]	valid_0's binary_logloss: 0.647853
[227]	valid_0's binary_logloss: 0.648012
[228]	valid_0's binary_logloss: 0.647636
[229]	valid_0's binary_logloss: 0.647839
[230]	valid_0's binary_logloss: 0.647489
[231]	valid_0's binary_logloss: 0.647147
[232]	valid_0's binary_logloss: 0.646806
[233]	valid_0's binary_logloss: 0.647008
[234]	valid_0's binary_logloss: 0.646595
[235]	valid_0's binary_logloss: 0.646798
[236]	valid_0's binary_logloss: 0.646435
[237]	valid_0's binary_logloss: 0.646087
[238]	valid_0's binary_logloss: 0.645678
[239]	valid_0's binary_logloss: 0.645239
[240]	valid_0's binary_logloss: 0.644912
[241]	valid_0's binary_logloss: 0.64514
[242]	valid_0's binary_logloss: 0.644826
[243]	valid_0's binary_logloss: 0.645065
[244]	valid_0's binary_logloss: 0.645271
[245]	valid_0's binary_logloss: 0.64489
[246]	valid_0's binary_logloss: 0.64453
[247]	valid_0's binary_logloss: 0.644171
[248]	valid_0's binary_logloss: 0.644399
[249]	valid_0's binary_logloss: 0.644597
[250]	valid_0's binary_logloss: 0.644221
[251]	valid_0's binary_logloss: 0.64443
[252]	valid_0's binary_logloss: 0.644628
[253]	valid_0's binary_logloss: 0.644337
[254]	valid_0's binary_logloss: 0.644019
[255]	valid_0's binary_logloss: 0.643715
[256]	valid_0's binary_logloss: 0.643469
[257]	valid_0's binary_logloss: 0.643188
[258]	valid_0's binary_logloss: 0.64287
[259]	valid_0's binary_logloss: 0.643072
[260]	valid_0's binary_logloss: 0.643306
[261]	valid_0's binary_logloss: 0.643517
[262]	valid_0's binary_logloss: 0.643125
[263]	valid_0's binary_logloss: 0.642761
[264]	valid_0's binary_logloss: 0.642526
[265]	valid_0's binary_logloss: 0.642247
[266]	valid_0's binary_logloss: 0.641905
[267]	valid_0's binary_logloss: 0.642108
[268]	valid_0's binary_logloss: 0.641865
[269]	valid_0's binary_logloss: 0.642079
[270]	valid_0's binary_logloss: 0.641718
[271]	valid_0's binary_logloss: 0.641931
[272]	valid_0's binary_logloss: 0.641613
[273]	valid_0's binary_logloss: 0.641226
[274]	valid_0's binary_logloss: 0.641425
[275]	valid_0's binary_logloss: 0.641179
[276]	valid_0's binary_logloss: 0.641394
[277]	valid_0's binary_logloss: 0.6411
[278]	valid_0's binary_logloss: 0.641288
[279]	valid_0's binary_logloss: 0.641014
[280]	valid_0's binary_logloss: 0.641213
[281]	valid_0's binary_logloss: 0.641384
[282]	valid_0's binary_logloss: 0.641102
[283]	valid_0's binary_logloss: 0.641306
[284]	valid_0's binary_logloss: 0.640919
[285]	valid_0's binary_logloss: 0.640632
[286]	valid_0's binary_logloss: 0.640376
[287]	valid_0's binary_logloss: 0.640044
[288]	valid_0's binary_logloss: 0.640235
[289]	valid_0's binary_logloss: 0.640022
[290]	valid_0's binary_logloss: 0.639666
[291]	valid_0's binary_logloss: 0.639409
[292]	valid_0's binary_logloss: 0.639618
[293]	valid_0's binary_logloss: 0.639822
[294]	valid_0's binary_logloss: 0.639499
[295]	valid_0's binary_logloss: 0.639695
[296]	valid_0's binary_logloss: 0.639886
[297]	valid_0's binary_logloss: 0.639597
[298]	valid_0's binary_logloss: 0.639768
[299]	valid_0's binary_logloss: 0.639455
[300]	valid_0's binary_logloss: 0.639626
[301]	valid_0's binary_logloss: 0.639826
[302]	valid_0's binary_logloss: 0.639529
[303]	valid_0's binary_logloss: 0.639713
[304]	valid_0's binary_logloss: 0.639903
[305]	valid_0's binary_logloss: 0.640098
[306]	valid_0's binary_logloss: 0.640266
[307]	valid_0's binary_logloss: 0.640422
[308]	valid_0's binary_logloss: 0.640194
[309]	valid_0's binary_logloss: 0.640365
[310]	valid_0's binary_logloss: 0.64007
[311]	valid_0's binary_logloss: 0.639788
[312]	valid_0's binary_logloss: 0.639525
[313]	valid_0's binary_logloss: 0.639212
[314]	valid_0's binary_logloss: 0.639372
[315]	valid_0's binary_logloss: 0.639561
[316]	valid_0's binary_logloss: 0.639257
[317]	valid_0's binary_logloss: 0.639061
[318]	valid_0's binary_logloss: 0.638806
[319]	valid_0's binary_logloss: 0.638975
[320]	valid_0's binary_logloss: 0.638761
[321]	valid_0's binary_logloss: 0.638897
[322]	valid_0's binary_logloss: 0.638596
[323]	valid_0's binary_logloss: 0.638393
[324]	valid_0's binary_logloss: 0.638577
[325]	valid_0's binary_logloss: 0.63825
[326]	valid_0's binary_logloss: 0.638437
[327]	valid_0's binary_logloss: 0.638152
[328]	valid_0's binary_logloss: 0.638316
[329]	valid_0's binary_logloss: 0.638032
[330]	valid_0's binary_logloss: 0.638205
[331]	valid_0's binary_logloss: 0.638382
[332]	valid_0's binary_logloss: 0.638547
[333]	valid_0's binary_logloss: 0.638731
[334]	valid_0's binary_logloss: 0.63892
[335]	valid_0's binary_logloss: 0.638689
[336]	valid_0's binary_logloss: 0.638859
[337]	valid_0's binary_logloss: 0.638591
[338]	valid_0's binary_logloss: 0.638333
[339]	valid_0's binary_logloss: 0.638499
[340]	valid_0's binary_logloss: 0.638678
[341]	valid_0's binary_logloss: 0.638437
[342]	valid_0's binary_logloss: 0.638177
[343]	valid_0's binary_logloss: 0.6379
[344]	valid_0's binary_logloss: 0.638064
[345]	valid_0's binary_logloss: 0.637729
[346]	valid_0's binary_logloss: 0.637534
[347]	valid_0's binary_logloss: 0.637694
[348]	valid_0's binary_logloss: 0.637434
[349]	valid_0's binary_logloss: 0.637203
[350]	valid_0's binary_logloss: 0.637382
[351]	valid_0's binary_logloss: 0.637163
[352]	valid_0's binary_logloss: 0.636906
[353]	valid_0's binary_logloss: 0.636634
[354]	valid_0's binary_logloss: 0.636781
[355]	valid_0's binary_logloss: 0.636946
[356]	valid_0's binary_logloss: 0.636634
[357]	valid_0's binary_logloss: 0.636792
[358]	valid_0's binary_logloss: 0.636489
[359]	valid_0's binary_logloss: 0.636654
[360]	valid_0's binary_logloss: 0.636447
[361]	valid_0's binary_logloss: 0.636226
[362]	valid_0's binary_logloss: 0.635994
[363]	valid_0's binary_logloss: 0.636164
[364]	valid_0's binary_logloss: 0.636315
[365]	valid_0's binary_logloss: 0.636097
[366]	valid_0's binary_logloss: 0.636253
[367]	valid_0's binary_logloss: 0.636425
[368]	valid_0's binary_logloss: 0.636209
[369]	valid_0's binary_logloss: 0.636348
[370]	valid_0's binary_logloss: 0.636127
[371]	valid_0's binary_logloss: 0.63629
[372]	valid_0's binary_logloss: 0.636042
[373]	valid_0's binary_logloss: 0.635769
[374]	valid_0's binary_logloss: 0.63551
[375]	valid_0's binary_logloss: 0.635306
[376]	valid_0's binary_logloss: 0.635455
[377]	valid_0's binary_logloss: 0.635264
[378]	valid_0's binary_logloss: 0.635424
[379]	valid_0's binary_logloss: 0.635582
[380]	valid_0's binary_logloss: 0.635284
[381]	valid_0's binary_logloss: 0.635453
[382]	valid_0's binary_logloss: 0.635611
[383]	valid_0's binary_logloss: 0.635363
[384]	valid_0's binary_logloss: 0.635188
[385]	valid_0's binary_logloss: 0.635346
[386]	valid_0's binary_logloss: 0.63511
[387]	valid_0's binary_logloss: 0.634882
[388]	valid_0's binary_logloss: 0.634589
[389]	valid_0's binary_logloss: 0.634394
[390]	valid_0's binary_logloss: 0.634179
[391]	valid_0's binary_logloss: 0.634338
[392]	valid_0's binary_logloss: 0.634114
[393]	valid_0's binary_logloss: 0.633843
[394]	valid_0's binary_logloss: 0.633623
[395]	valid_0's binary_logloss: 0.633408
[396]	valid_0's binary_logloss: 0.63356
[397]	valid_0's binary_logloss: 0.633351
[398]	valid_0's binary_logloss: 0.633141
[399]	valid_0's binary_logloss: 0.632982
[400]	valid_0's binary_logloss: 0.632732
[401]	valid_0's binary_logloss: 0.632864
[402]	valid_0's binary_logloss: 0.632675[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2018-07-01 15:41:40,013 - DEBUG - lgbm.py:284 - to save validation predictions ...
2018-07-01 15:41:40,079 - DEBUG - lgbm.py:286 - ['/data/1-lgbm.model.joblib_dat']
2018-07-01 15:41:40,080 - DEBUG - lgbm.py:290 - 验证
--- Logging error ---
Traceback (most recent call last):
  File "/home/zhijiehuang/anaconda3/lib/python3.6/logging/__init__.py", line 992, in emit
    msg = self.format(record)
  File "/home/zhijiehuang/anaconda3/lib/python3.6/logging/__init__.py", line 838, in format
    return fmt.format(record)
  File "/home/zhijiehuang/anaconda3/lib/python3.6/logging/__init__.py", line 575, in format
    record.message = record.getMessage()
  File "/home/zhijiehuang/anaconda3/lib/python3.6/logging/__init__.py", line 338, in getMessage
    msg = msg % self.args
TypeError: not all arguments converted during string formatting
Call stack:
  File "lgbm.py", line 321, in <module>
    done()
  File "lgbm.py", line 293, in done
    logging.debug('log_loss', log_loss(val_y, preds_offline))
Message: 'log_loss'
Arguments: (0.6275414955546268,)
2018-07-01 15:41:49,510 - DEBUG - data_preprocessing.py:204 - data1.shape:(6865066, 5)
2018-07-01 15:41:49,510 - DEBUG - data_preprocessing.py:205 - data2.shape:(6865066, 5)
2018-07-01 15:41:49,605 - DEBUG - data_preprocessing.py:208 - 结果.shape:(6865066, 10)
2018-07-01 15:41:49,605 - DEBUG - data_preprocessing.py:209 - 耗时0.0001537799835205078
2018-07-01 15:42:09,404 - DEBUG - data_preprocessing.py:204 - data1.shape:(6865066, 10)
2018-07-01 15:42:09,404 - DEBUG - data_preprocessing.py:205 - data2.shape:(6865066, 60)
2018-07-01 15:42:12,136 - DEBUG - data_preprocessing.py:208 - 结果.shape:(6865066, 70)
2018-07-01 15:42:12,136 - DEBUG - data_preprocessing.py:209 - 耗时0.0001595020294189453
2018-07-01 15:42:16,649 - DEBUG - data_preprocessing.py:204 - data1.shape:(6865066, 70)
2018-07-01 15:42:16,649 - DEBUG - data_preprocessing.py:205 - data2.shape:(6865066, 11)
2018-07-01 15:42:23,517 - DEBUG - data_preprocessing.py:208 - 结果.shape:(6865066, 81)
2018-07-01 15:42:23,517 - DEBUG - data_preprocessing.py:209 - 耗时0.00015735626220703125
2018-07-01 15:42:42,239 - DEBUG - data_preprocessing.py:204 - data1.shape:(6865066, 81)
2018-07-01 15:42:42,239 - DEBUG - data_preprocessing.py:205 - data2.shape:(6865066, 20)
2018-07-01 15:42:50,093 - DEBUG - data_preprocessing.py:208 - 结果.shape:(6865066, 101)
2018-07-01 15:42:50,093 - DEBUG - data_preprocessing.py:209 - 耗时0.00016427040100097656
2018-07-01 15:42:50,210 - DEBUG - data_preprocessing.py:382 - Index(['C14', 'C17', 'C21', 'device_model', 'site_domain', 'one_day',
       'one_day_hour', 'day_hour_prev', 'day_hour_next', 'is_work_day',
       ...
       'exptv_C17C21', 'cnttv_C17C21', 'exptv_C17site_domain',
       'cnttv_C17site_domain', 'exptv_C21device_model',
       'cnttv_C21device_model', 'exptv_C21site_domain', 'cnttv_C21site_domain',
       'exptv_site_domaindevice_model', 'cnttv_site_domaindevice_model'],
      dtype='object', length=101)
2018-07-01 15:42:51,717 - DEBUG - data_preprocessing.py:204 - data1.shape:(4577464, 5)
2018-07-01 15:42:51,717 - DEBUG - data_preprocessing.py:205 - data2.shape:(4577464, 5)
2018-07-01 15:42:51,849 - DEBUG - data_preprocessing.py:208 - 结果.shape:(4577464, 10)
2018-07-01 15:42:51,849 - DEBUG - data_preprocessing.py:209 - 耗时0.0001544952392578125
2018-07-01 15:43:05,426 - DEBUG - data_preprocessing.py:204 - data1.shape:(4577464, 10)
2018-07-01 15:43:05,426 - DEBUG - data_preprocessing.py:205 - data2.shape:(4577464, 60)
2018-07-01 15:43:06,964 - DEBUG - data_preprocessing.py:208 - 结果.shape:(4577464, 70)
2018-07-01 15:43:06,964 - DEBUG - data_preprocessing.py:209 - 耗时0.00015306472778320312
2018-07-01 15:43:10,018 - DEBUG - data_preprocessing.py:204 - data1.shape:(4577464, 70)
2018-07-01 15:43:10,018 - DEBUG - data_preprocessing.py:205 - data2.shape:(4577464, 11)
2018-07-01 15:43:14,382 - DEBUG - data_preprocessing.py:208 - 结果.shape:(4577464, 81)
2018-07-01 15:43:14,382 - DEBUG - data_preprocessing.py:209 - 耗时0.00015735626220703125
2018-07-01 15:43:27,010 - DEBUG - data_preprocessing.py:204 - data1.shape:(4577464, 81)
2018-07-01 15:43:27,010 - DEBUG - data_preprocessing.py:205 - data2.shape:(4577464, 20)
2018-07-01 15:43:32,148 - DEBUG - data_preprocessing.py:208 - 结果.shape:(4577464, 101)
2018-07-01 15:43:32,148 - DEBUG - data_preprocessing.py:209 - 耗时0.00015926361083984375
2018-07-01 15:43:32,227 - DEBUG - data_preprocessing.py:391 - (6865066, 101)
2018-07-01 15:43:32,227 - DEBUG - data_preprocessing.py:392 - (4577464, 101)
2018-07-01 15:43:58,796 - DEBUG - data_preprocessing.py:411 -            C14   C17  C21  device_model  site_domain  one_day  one_day_hour  \
2445499  21611  2480   61          5524         6124        1             0   

         day_hour_prev  day_hour_next  is_work_day  \
2445499             -1              1            1   

                     ...                exptv_C17C21  cnttv_C17C21  \
2445499              ...                    0.239964        796075   

         exptv_C17site_domain  cnttv_C17site_domain  exptv_C21device_model  \
2445499              0.236913                501032               0.188062   

         cnttv_C21device_model  exptv_C21site_domain  cnttv_C21site_domain  \
2445499                 226216              0.163896               2897548   

         exptv_site_domaindevice_model  cnttv_site_domaindevice_model  
2445499                       0.114806                         384227  

[1 rows x 100 columns]
2018-07-01 15:43:58,813 - DEBUG - data_preprocessing.py:412 - 2445499    0
Name: click, dtype: int64
2018-07-01 15:43:58,814 - DEBUG - lgbm.py:270 - 设置参数
2018-07-01 15:43:58,855 - DEBUG - lgbm.py:299 - 预测
2018-07-01 15:45:24,243 - DEBUG - lgbm.py:302 - [0.35740834 0.51509825 0.51391905 ... 0.7301779  0.18330494 0.40767721]
2018-07-01 15:45:37,581 - DEBUG - lgbm.py:304 - ------------------------------
2018-07-01 15:45:37,831 - DEBUG - lgbm.py:306 - (4577464, 1)
2018-07-01 15:45:38,597 - DEBUG - lgbm.py:308 - (4577464,)

[403]	valid_0's binary_logloss: 0.632807
[404]	valid_0's binary_logloss: 0.632614
[405]	valid_0's binary_logloss: 0.632439
[406]	valid_0's binary_logloss: 0.632578
[407]	valid_0's binary_logloss: 0.632352
[408]	valid_0's binary_logloss: 0.6325
[409]	valid_0's binary_logloss: 0.632324
[410]	valid_0's binary_logloss: 0.63208
[411]	valid_0's binary_logloss: 0.631909
[412]	valid_0's binary_logloss: 0.632046
[413]	valid_0's binary_logloss: 0.632195
[414]	valid_0's binary_logloss: 0.632061
[415]	valid_0's binary_logloss: 0.631816
[416]	valid_0's binary_logloss: 0.631642
[417]	valid_0's binary_logloss: 0.631792
[418]	valid_0's binary_logloss: 0.63194
[419]	valid_0's binary_logloss: 0.631805
[420]	valid_0's binary_logloss: 0.631944
[421]	valid_0's binary_logloss: 0.631763
[422]	valid_0's binary_logloss: 0.631577
[423]	valid_0's binary_logloss: 0.631392
[424]	valid_0's binary_logloss: 0.631197
[425]	valid_0's binary_logloss: 0.631334
[426]	valid_0's binary_logloss: 0.631163
[427]	valid_0's binary_logloss: 0.630983
[428]	valid_0's binary_logloss: 0.63113
[429]	valid_0's binary_logloss: 0.63097
[430]	valid_0's binary_logloss: 0.631097
[431]	valid_0's binary_logloss: 0.63092
[432]	valid_0's binary_logloss: 0.630668
[433]	valid_0's binary_logloss: 0.630408
[434]	valid_0's binary_logloss: 0.63054
[435]	valid_0's binary_logloss: 0.630672
[436]	valid_0's binary_logloss: 0.630501
[437]	valid_0's binary_logloss: 0.630346
[438]	valid_0's binary_logloss: 0.63047
[439]	valid_0's binary_logloss: 0.630601
[440]	valid_0's binary_logloss: 0.630448
[441]	valid_0's binary_logloss: 0.630288
[442]	valid_0's binary_logloss: 0.630076
[443]	valid_0's binary_logloss: 0.6302
[444]	valid_0's binary_logloss: 0.63006
[445]	valid_0's binary_logloss: 0.62991
[446]	valid_0's binary_logloss: 0.630039
[447]	valid_0's binary_logloss: 0.629856
[448]	valid_0's binary_logloss: 0.629741
[449]	valid_0's binary_logloss: 0.629607
[450]	valid_0's binary_logloss: 0.629459
[451]	valid_0's binary_logloss: 0.629345
[452]	valid_0's binary_logloss: 0.629471
[453]	valid_0's binary_logloss: 0.629598
[454]	valid_0's binary_logloss: 0.629723
[455]	valid_0's binary_logloss: 0.629538
[456]	valid_0's binary_logloss: 0.629666
[457]	valid_0's binary_logloss: 0.629797
[458]	valid_0's binary_logloss: 0.62962
[459]	valid_0's binary_logloss: 0.62948
[460]	valid_0's binary_logloss: 0.629601
[461]	valid_0's binary_logloss: 0.629428
[462]	valid_0's binary_logloss: 0.629549
[463]	valid_0's binary_logloss: 0.629679
[464]	valid_0's binary_logloss: 0.629527
[465]	valid_0's binary_logloss: 0.629415
[466]	valid_0's binary_logloss: 0.629539
[467]	valid_0's binary_logloss: 0.629397
[468]	valid_0's binary_logloss: 0.62952
[469]	valid_0's binary_logloss: 0.629366
[470]	valid_0's binary_logloss: 0.629489
[471]	valid_0's binary_logloss: 0.629332
[472]	valid_0's binary_logloss: 0.62945
[473]	valid_0's binary_logloss: 0.629265
[474]	valid_0's binary_logloss: 0.629124
[475]	valid_0's binary_logloss: 0.629001
[476]	valid_0's binary_logloss: 0.629114
[477]	valid_0's binary_logloss: 0.628881
[478]	valid_0's binary_logloss: 0.629013
[479]	valid_0's binary_logloss: 0.629138
[480]	valid_0's binary_logloss: 0.628971
[481]	valid_0's binary_logloss: 0.628813
[482]	valid_0's binary_logloss: 0.628676
[483]	valid_0's binary_logloss: 0.628523
[484]	valid_0's binary_logloss: 0.628321
[485]	valid_0's binary_logloss: 0.628434
[486]	valid_0's binary_logloss: 0.628276
[487]	valid_0's binary_logloss: 0.628088
[488]	valid_0's binary_logloss: 0.627926
[489]	valid_0's binary_logloss: 0.627763
[490]	valid_0's binary_logloss: 0.627879
[491]	valid_0's binary_logloss: 0.627993
[492]	valid_0's binary_logloss: 0.628096
[493]	valid_0's binary_logloss: 0.62821
[494]	valid_0's binary_logloss: 0.628051
[495]	valid_0's binary_logloss: 0.627886
[496]	valid_0's binary_logloss: 0.627737
[497]	valid_0's binary_logloss: 0.62763
[498]	valid_0's binary_logloss: 0.62753
[499]	valid_0's binary_logloss: 0.627632
[500]	valid_0's binary_logloss: 0.627513
[501]	valid_0's binary_logloss: 0.62763
[502]	valid_0's binary_logloss: 0.62747
[503]	valid_0's binary_logloss: 0.627326
[504]	valid_0's binary_logloss: 0.627433
[505]	valid_0's binary_logloss: 0.62753
[506]	valid_0's binary_logloss: 0.627426
[507]	valid_0's binary_logloss: 0.627276
[508]	valid_0's binary_logloss: 0.627125
[509]	valid_0's binary_logloss: 0.627004
[510]	valid_0's binary_logloss: 0.62689
[511]	valid_0's binary_logloss: 0.626997
[512]	valid_0's binary_logloss: 0.626867
[513]	valid_0's binary_logloss: 0.626711
[514]	valid_0's binary_logloss: 0.62661
[515]	valid_0's binary_logloss: 0.62646
[516]	valid_0's binary_logloss: 0.626568
[517]	valid_0's binary_logloss: 0.626673
[518]	valid_0's binary_logloss: 0.62677
[519]	valid_0's binary_logloss: 0.626881
[520]	valid_0's binary_logloss: 0.626782
[521]	valid_0's binary_logloss: 0.626663
[522]	valid_0's binary_logloss: 0.626765
[523]	valid_0's binary_logloss: 0.626871
[524]	valid_0's binary_logloss: 0.626977
[525]	valid_0's binary_logloss: 0.627083
[526]	valid_0's binary_logloss: 0.626945
[527]	valid_0's binary_logloss: 0.627048
[528]	valid_0's binary_logloss: 0.626936
[529]	valid_0's binary_logloss: 0.626816
[530]	valid_0's binary_logloss: 0.626683
[531]	valid_0's binary_logloss: 0.626784
[532]	valid_0's binary_logloss: 0.626633
[533]	valid_0's binary_logloss: 0.626733
[534]	valid_0's binary_logloss: 0.62657
[535]	valid_0's binary_logloss: 0.626393
[536]	valid_0's binary_logloss: 0.626481
[537]	valid_0's binary_logloss: 0.626339
[538]	valid_0's binary_logloss: 0.626171
[539]	valid_0's binary_logloss: 0.62628
[540]	valid_0's binary_logloss: 0.626384
[541]	valid_0's binary_logloss: 0.626485
[542]	valid_0's binary_logloss: 0.626343
[543]	valid_0's binary_logloss: 0.626451
[544]	valid_0's binary_logloss: 0.626556
[545]	valid_0's binary_logloss: 0.626404
[546]	valid_0's binary_logloss: 0.62629
[547]	valid_0's binary_logloss: 0.626153
[548]	valid_0's binary_logloss: 0.626014
[549]	valid_0's binary_logloss: 0.626112
[550]	valid_0's binary_logloss: 0.625975
[551]	valid_0's binary_logloss: 0.625827
[552]	valid_0's binary_logloss: 0.625679
[553]	valid_0's binary_logloss: 0.62579
[554]	valid_0's binary_logloss: 0.625884
[555]	valid_0's binary_logloss: 0.625746
[556]	valid_0's binary_logloss: 0.625844
[557]	valid_0's binary_logloss: 0.625943
[558]	valid_0's binary_logloss: 0.625825
[559]	valid_0's binary_logloss: 0.62566
[560]	valid_0's binary_logloss: 0.625513
[561]	valid_0's binary_logloss: 0.625617
[562]	valid_0's binary_logloss: 0.625711
[563]	valid_0's binary_logloss: 0.625805
[564]	valid_0's binary_logloss: 0.625914
[565]	valid_0's binary_logloss: 0.625759
[566]	valid_0's binary_logloss: 0.625651
[567]	valid_0's binary_logloss: 0.625564
[568]	valid_0's binary_logloss: 0.625656
[569]	valid_0's binary_logloss: 0.625756
[570]	valid_0's binary_logloss: 0.625849
[571]	valid_0's binary_logloss: 0.625721
[572]	valid_0's binary_logloss: 0.625579
[573]	valid_0's binary_logloss: 0.625669
[574]	valid_0's binary_logloss: 0.625764
[575]	valid_0's binary_logloss: 0.62563
[576]	valid_0's binary_logloss: 0.625732
[577]	valid_0's binary_logloss: 0.625827
[578]	valid_0's binary_logloss: 0.625925
[579]	valid_0's binary_logloss: 0.626019
[580]	valid_0's binary_logloss: 0.626122
[581]	valid_0's binary_logloss: 0.626006
[582]	valid_0's binary_logloss: 0.62609
[583]	valid_0's binary_logloss: 0.625973
[584]	valid_0's binary_logloss: 0.626072
[585]	valid_0's binary_logloss: 0.625864
[586]	valid_0's binary_logloss: 0.625946
[587]	valid_0's binary_logloss: 0.625842
[588]	valid_0's binary_logloss: 0.625938
[589]	valid_0's binary_logloss: 0.626042
[590]	valid_0's binary_logloss: 0.62613
Early stopping, best iteration is:
[560]	valid_0's binary_logloss: 0.625513
(6865066, 101)
2018-07-01 15:50:37,558 - DEBUG - data_preprocessing.py:204 - data1.shape:(6865066, 5)
2018-07-01 15:50:37,558 - DEBUG - data_preprocessing.py:205 - data2.shape:(6865066, 5)
2018-07-01 15:50:37,863 - DEBUG - data_preprocessing.py:208 - 结果.shape:(6865066, 10)
2018-07-01 15:50:37,863 - DEBUG - data_preprocessing.py:209 - 耗时0.00014472007751464844
2018-07-01 15:51:02,589 - DEBUG - data_preprocessing.py:204 - data1.shape:(6865066, 10)
2018-07-01 15:51:02,589 - DEBUG - data_preprocessing.py:205 - data2.shape:(6865066, 60)
2018-07-01 15:51:04,775 - DEBUG - data_preprocessing.py:208 - 结果.shape:(6865066, 70)
2018-07-01 15:51:04,776 - DEBUG - data_preprocessing.py:209 - 耗时0.00015115737915039062
2018-07-01 15:51:09,126 - DEBUG - data_preprocessing.py:204 - data1.shape:(6865066, 70)
2018-07-01 15:51:09,126 - DEBUG - data_preprocessing.py:205 - data2.shape:(6865066, 11)
2018-07-01 15:51:15,788 - DEBUG - data_preprocessing.py:208 - 结果.shape:(6865066, 81)
2018-07-01 15:51:15,788 - DEBUG - data_preprocessing.py:209 - 耗时0.00015592575073242188
2018-07-01 15:51:34,578 - DEBUG - data_preprocessing.py:204 - data1.shape:(6865066, 81)
2018-07-01 15:51:34,578 - DEBUG - data_preprocessing.py:205 - data2.shape:(6865066, 20)
2018-07-01 15:51:42,302 - DEBUG - data_preprocessing.py:208 - 结果.shape:(6865066, 101)
2018-07-01 15:51:42,302 - DEBUG - data_preprocessing.py:209 - 耗时0.00015592575073242188
2018-07-01 15:51:42,411 - DEBUG - data_preprocessing.py:382 - Index(['C14', 'C17', 'C21', 'device_model', 'site_domain', 'one_day',
       'one_day_hour', 'day_hour_prev', 'day_hour_next', 'is_work_day',
       ...
       'exptv_C17C21', 'cnttv_C17C21', 'exptv_C17site_domain',
       'cnttv_C17site_domain', 'exptv_C21device_model',
       'cnttv_C21device_model', 'exptv_C21site_domain', 'cnttv_C21site_domain',
       'exptv_site_domaindevice_model', 'cnttv_site_domaindevice_model'],
      dtype='object', length=101)
2018-07-01 15:51:44,049 - DEBUG - data_preprocessing.py:204 - data1.shape:(4577464, 5)
2018-07-01 15:51:44,049 - DEBUG - data_preprocessing.py:205 - data2.shape:(4577464, 5)
2018-07-01 15:51:44,112 - DEBUG - data_preprocessing.py:208 - 结果.shape:(4577464, 10)
2018-07-01 15:51:44,112 - DEBUG - data_preprocessing.py:209 - 耗时0.00015401840209960938
2018-07-01 15:51:59,706 - DEBUG - data_preprocessing.py:204 - data1.shape:(4577464, 10)
2018-07-01 15:51:59,706 - DEBUG - data_preprocessing.py:205 - data2.shape:(4577464, 60)
2018-07-01 15:52:01,107 - DEBUG - data_preprocessing.py:208 - 结果.shape:(4577464, 70)
2018-07-01 15:52:01,107 - DEBUG - data_preprocessing.py:209 - 耗时0.0001552104949951172
2018-07-01 15:52:03,969 - DEBUG - data_preprocessing.py:204 - data1.shape:(4577464, 70)
2018-07-01 15:52:03,969 - DEBUG - data_preprocessing.py:205 - data2.shape:(4577464, 11)
2018-07-01 15:52:08,378 - DEBUG - data_preprocessing.py:208 - 结果.shape:(4577464, 81)
2018-07-01 15:52:08,379 - DEBUG - data_preprocessing.py:209 - 耗时0.00015974044799804688
2018-07-01 15:52:21,099 - DEBUG - data_preprocessing.py:204 - data1.shape:(4577464, 81)
2018-07-01 15:52:21,099 - DEBUG - data_preprocessing.py:205 - data2.shape:(4577464, 20)
2018-07-01 15:52:26,234 - DEBUG - data_preprocessing.py:208 - 结果.shape:(4577464, 101)
2018-07-01 15:52:26,234 - DEBUG - data_preprocessing.py:209 - 耗时0.00015473365783691406
2018-07-01 15:52:26,305 - DEBUG - data_preprocessing.py:391 - (6865066, 101)
2018-07-01 15:52:26,306 - DEBUG - data_preprocessing.py:392 - (4577464, 101)
/home/zhijiehuang/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.
  FutureWarning)
2018-07-01 15:52:52,253 - DEBUG - data_preprocessing.py:411 -            C14   C17  C21  device_model  site_domain  one_day  one_day_hour  \
2445499  21611  2480   61          5524         6124        1             0   

         day_hour_prev  day_hour_next  is_work_day  \
2445499             -1              1            1   

                     ...                exptv_C17C21  cnttv_C17C21  \
2445499              ...                    0.239964        796075   

         exptv_C17site_domain  cnttv_C17site_domain  exptv_C21device_model  \
2445499              0.236913                501032               0.188062   

         cnttv_C21device_model  exptv_C21site_domain  cnttv_C21site_domain  \
2445499                 226216              0.163896               2897548   

         exptv_site_domaindevice_model  cnttv_site_domaindevice_model  
2445499                       0.114806                         384227  

[1 rows x 100 columns]
2018-07-01 15:52:52,266 - DEBUG - data_preprocessing.py:412 - 2445499    0
Name: click, dtype: int64
2018-07-01 15:52:52,267 - DEBUG - lgbm.py:270 - 设置参数
2018-07-01 15:52:52,267 - DEBUG - lgbm.py:273 - CV:max_bin
2018-07-01 15:52:52,267 - DEBUG - lgbm.py:79 - 交叉验证
2018-07-01 15:52:52,267 - DEBUG - lgbm.py:124 - 调参2：降低过拟合
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Info] Number of positive: 2060105, number of negative: 2058934
[LightGBM] [Info] This is the GPU trainer!!
[LightGBM] [Info] Total Bins 484
[LightGBM] [Info] Number of data: 4119039, number of used features: 99
[LightGBM] [Info] Using requested OpenCL platform 0 device 0
[LightGBM] [Info] Using GPU Device: GeForce GTX 1070 Ti, Vendor: NVIDIA Corporation
[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...
[LightGBM] [Info] GPU programs have been built
[LightGBM] [Info] Size of histogram bin entry: 12
[LightGBM] [Info] 98 dense feature groups (204.27 MB) transfered to GPU in 0.284980 secs. 0 sparse feature groups
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Info] Number of positive: 2060105, number of negative: 2058934
[LightGBM] [Info] This is the GPU trainer!!
[LightGBM] [Info] Total Bins 484
[LightGBM] [Info] Number of data: 4119039, number of used features: 99
[LightGBM] [Info] Using requested OpenCL platform 0 device 0
[LightGBM] [Info] Using GPU Device: GeForce GTX 1070 Ti, Vendor: NVIDIA Corporation
[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...
[LightGBM] [Info] GPU programs have been built
[LightGBM] [Info] Size of histogram bin entry: 12
[LightGBM] [Info] 98 dense feature groups (204.27 MB) transfered to GPU in 0.276176 secs. 0 sparse feature groups
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Info] Number of positive: 2060106, number of negative: 2058934
[LightGBM] [Info] This is the GPU trainer!!
[LightGBM] [Info] Total Bins 484
[LightGBM] [Info] Number of data: 4119040, number of used features: 99
[LightGBM] [Info] Using requested OpenCL platform 0 device 0
[LightGBM] [Info] Using GPU Device: GeForce GTX 1070 Ti, Vendor: NVIDIA Corporation
[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...
[LightGBM] [Info] GPU programs have been built
[LightGBM] [Info] Size of histogram bin entry: 12
[LightGBM] [Info] 98 dense feature groups (204.27 MB) transfered to GPU in 0.272997 secs. 0 sparse feature groups
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500142 -> initscore=0.000569
[LightGBM] [Info] Start training from score 0.000569
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500142 -> initscore=0.000569
[LightGBM] [Info] Start training from score 0.000569
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500142 -> initscore=0.000569
[LightGBM] [Info] Start training from score 0.000569
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
lgbm.py:141: FutureWarning: 'argmin' is deprecated. Use 'idxmin' instead. The behavior of 'argmin' will be corrected to return the positional minimum in the future. Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_error-mean']).argmin()
2018-07-01 15:53:16,690 - DEBUG - lgbm.py:142 - boost_rounds=2
2018-07-01 15:53:16,691 - DEBUG - lgbm.py:143 - mean_merror=0.36285289179335756
2018-07-01 15:53:16,691 - DEBUG - lgbm.py:144 - best_params['max_bin']=7
2018-07-01 15:53:16,691 - DEBUG - lgbm.py:145 - best_params['min_data_in_leaf']=10
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Info] Number of positive: 2060105, number of negative: 2058934
[LightGBM] [Info] This is the GPU trainer!!
[LightGBM] [Info] Total Bins 484
[LightGBM] [Info] Number of data: 4119039, number of used features: 99
[LightGBM] [Info] Using requested OpenCL platform 0 device 0
[LightGBM] [Info] Using GPU Device: GeForce GTX 1070 Ti, Vendor: NVIDIA Corporation
[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...
[LightGBM] [Info] GPU programs have been built
[LightGBM] [Info] Size of histogram bin entry: 12
[LightGBM] [Info] 98 dense feature groups (204.27 MB) transfered to GPU in 0.235170 secs. 0 sparse feature groups
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Info] Number of positive: 2060105, number of negative: 2058934
[LightGBM] [Info] This is the GPU trainer!!
[LightGBM] [Info] Total Bins 484
[LightGBM] [Info] Number of data: 4119039, number of used features: 99
[LightGBM] [Info] Using requested OpenCL platform 0 device 0
[LightGBM] [Info] Using GPU Device: GeForce GTX 1070 Ti, Vendor: NVIDIA Corporation
[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...
[LightGBM] [Info] GPU programs have been built
[LightGBM] [Info] Size of histogram bin entry: 12
[LightGBM] [Info] 98 dense feature groups (204.27 MB) transfered to GPU in 0.191413 secs. 0 sparse feature groups
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Info] Number of positive: 2060106, number of negative: 2058934
[LightGBM] [Info] This is the GPU trainer!!
[LightGBM] [Info] Total Bins 484
[LightGBM] [Info] Number of data: 4119040, number of used features: 99
[LightGBM] [Info] Using requested OpenCL platform 0 device 0
[LightGBM] [Info] Using GPU Device: GeForce GTX 1070 Ti, Vendor: NVIDIA Corporation
[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...
[LightGBM] [Info] GPU programs have been built
[LightGBM] [Info] Size of histogram bin entry: 12
[LightGBM] [Info] 98 dense feature groups (204.27 MB) transfered to GPU in 0.275298 secs. 0 sparse feature groups
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500142 -> initscore=0.000569
[LightGBM] [Info] Start training from score 0.000569
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500142 -> initscore=0.000569
[LightGBM] [Info] Start training from score 0.000569
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500142 -> initscore=0.000569
[LightGBM] [Info] Start training from score 0.000569
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2018-07-01 15:53:24,608 - DEBUG - lgbm.py:142 - boost_rounds=2
2018-07-01 15:53:24,608 - DEBUG - lgbm.py:143 - mean_merror=0.36285370104340936
2018-07-01 15:53:24,608 - DEBUG - lgbm.py:144 - best_params['max_bin']=7
2018-07-01 15:53:24,608 - DEBUG - lgbm.py:145 - best_params['min_data_in_leaf']=15
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Info] Number of positive: 2060105, number of negative: 2058934
[LightGBM] [Info] This is the GPU trainer!!
[LightGBM] [Info] Total Bins 484
[LightGBM] [Info] Number of data: 4119039, number of used features: 99
[LightGBM] [Info] Using requested OpenCL platform 0 device 0
[LightGBM] [Info] Using GPU Device: GeForce GTX 1070 Ti, Vendor: NVIDIA Corporation
[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...
[LightGBM] [Info] GPU programs have been built
[LightGBM] [Info] Size of histogram bin entry: 12
[LightGBM] [Info] 98 dense feature groups (204.27 MB) transfered to GPU in 0.243499 secs. 0 sparse feature groups
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Info] Number of positive: 2060105, number of negative: 2058934
[LightGBM] [Info] This is the GPU trainer!!
[LightGBM] [Info] Total Bins 484
[LightGBM] [Info] Number of data: 4119039, number of used features: 99
[LightGBM] [Info] Using requested OpenCL platform 0 device 0
[LightGBM] [Info] Using GPU Device: GeForce GTX 1070 Ti, Vendor: NVIDIA Corporation
[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...
[LightGBM] [Info] GPU programs have been built
[LightGBM] [Info] Size of histogram bin entry: 12
[LightGBM] [Info] 98 dense feature groups (204.27 MB) transfered to GPU in 0.231729 secs. 0 sparse feature groups
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Info] Number of positive: 2060106, number of negative: 2058934
[LightGBM] [Info] This is the GPU trainer!!
[LightGBM] [Info] Total Bins 484
[LightGBM] [Info] Number of data: 4119040, number of used features: 99
[LightGBM] [Info] Using requested OpenCL platform 0 device 0
[LightGBM] [Info] Using GPU Device: GeForce GTX 1070 Ti, Vendor: NVIDIA Corporation
[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...
[LightGBM] [Info] GPU programs have been built
[LightGBM] [Info] Size of histogram bin entry: 12
[LightGBM] [Info] 98 dense feature groups (204.27 MB) transfered to GPU in 0.255029 secs. 0 sparse feature groups
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500142 -> initscore=0.000569
[LightGBM] [Info] Start training from score 0.000569
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500142 -> initscore=0.000569
[LightGBM] [Info] Start training from score 0.000569
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500142 -> initscore=0.000569
[LightGBM] [Info] Start training from score 0.000569
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2018-07-01 15:53:32,412 - DEBUG - lgbm.py:142 - boost_rounds=2
2018-07-01 15:53:32,412 - DEBUG - lgbm.py:143 - mean_merror=0.3628546721434715
2018-07-01 15:53:32,412 - DEBUG - lgbm.py:144 - best_params['max_bin']=7
2018-07-01 15:53:32,412 - DEBUG - lgbm.py:145 - best_params['min_data_in_leaf']=20
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Info] Number of positive: 2060105, number of negative: 2058934
[LightGBM] [Info] This is the GPU trainer!!
[LightGBM] [Info] Total Bins 484
[LightGBM] [Info] Number of data: 4119039, number of used features: 99
[LightGBM] [Info] Using requested OpenCL platform 0 device 0
[LightGBM] [Info] Using GPU Device: GeForce GTX 1070 Ti, Vendor: NVIDIA Corporation
[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...
[LightGBM] [Info] GPU programs have been built
[LightGBM] [Info] Size of histogram bin entry: 12
[LightGBM] [Info] 98 dense feature groups (204.27 MB) transfered to GPU in 0.232491 secs. 0 sparse feature groups
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Info] Number of positive: 2060105, number of negative: 2058934
[LightGBM] [Info] This is the GPU trainer!!
[LightGBM] [Info] Total Bins 484
[LightGBM] [Info] Number of data: 4119039, number of used features: 99
[LightGBM] [Info] Using requested OpenCL platform 0 device 0
[LightGBM] [Info] Using GPU Device: GeForce GTX 1070 Ti, Vendor: NVIDIA Corporation
[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...
[LightGBM] [Info] GPU programs have been built
[LightGBM] [Info] Size of histogram bin entry: 12
[LightGBM] [Info] 98 dense feature groups (204.27 MB) transfered to GPU in 0.239034 secs. 0 sparse feature groups
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Info] Number of positive: 2060106, number of negative: 2058934
[LightGBM] [Info] This is the GPU trainer!!
[LightGBM] [Info] Total Bins 484
[LightGBM] [Info] Number of data: 4119040, number of used features: 99
[LightGBM] [Info] Using requested OpenCL platform 0 device 0
[LightGBM] [Info] Using GPU Device: GeForce GTX 1070 Ti, Vendor: NVIDIA Corporation
[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...
[LightGBM] [Info] GPU programs have been built
[LightGBM] [Info] Size of histogram bin entry: 12
[LightGBM] [Info] 98 dense feature groups (204.27 MB) transfered to GPU in 0.270674 secs. 0 sparse feature groups
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500142 -> initscore=0.000569
[LightGBM] [Info] Start training from score 0.000569
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500142 -> initscore=0.000569
[LightGBM] [Info] Start training from score 0.000569
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500142 -> initscore=0.000569
[LightGBM] [Info] Start training from score 0.000569
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2018-07-01 15:53:40,161 - DEBUG - lgbm.py:142 - boost_rounds=2
2018-07-01 15:53:40,161 - DEBUG - lgbm.py:143 - mean_merror=0.36285531954367006
2018-07-01 15:53:40,161 - DEBUG - lgbm.py:144 - best_params['max_bin']=7
2018-07-01 15:53:40,161 - DEBUG - lgbm.py:145 - best_params['min_data_in_leaf']=25
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Info] Number of positive: 2060105, number of negative: 2058934
[LightGBM] [Info] This is the GPU trainer!!
[LightGBM] [Info] Total Bins 484
[LightGBM] [Info] Number of data: 4119039, number of used features: 99
[LightGBM] [Info] Using requested OpenCL platform 0 device 0
[LightGBM] [Info] Using GPU Device: GeForce GTX 1070 Ti, Vendor: NVIDIA Corporation
[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...
[LightGBM] [Info] GPU programs have been built
[LightGBM] [Info] Size of histogram bin entry: 12
[LightGBM] [Info] 98 dense feature groups (204.27 MB) transfered to GPU in 0.240814 secs. 0 sparse feature groups
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Info] Number of positive: 2060105, number of negative: 2058934
[LightGBM] [Info] This is the GPU trainer!!
[LightGBM] [Info] Total Bins 484
[LightGBM] [Info] Number of data: 4119039, number of used features: 99
[LightGBM] [Info] Using requested OpenCL platform 0 device 0
[LightGBM] [Info] Using GPU Device: GeForce GTX 1070 Ti, Vendor: NVIDIA Corporation
[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...
[LightGBM] [Info] GPU programs have been built
[LightGBM] [Info] Size of histogram bin entry: 12
[LightGBM] [Info] 98 dense feature groups (204.27 MB) transfered to GPU in 0.244576 secs. 0 sparse feature groups
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Info] Number of positive: 2060106, number of negative: 2058934
[LightGBM] [Info] This is the GPU trainer!!
[LightGBM] [Info] Total Bins 484
[LightGBM] [Info] Number of data: 4119040, number of used features: 99
[LightGBM] [Info] Using requested OpenCL platform 0 device 0
[LightGBM] [Info] Using GPU Device: GeForce GTX 1070 Ti, Vendor: NVIDIA Corporation
[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...
[LightGBM] [Info] GPU programs have been built
[LightGBM] [Info] Size of histogram bin entry: 12
[LightGBM] [Info] 98 dense feature groups (204.27 MB) transfered to GPU in 0.277301 secs. 0 sparse feature groups
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500142 -> initscore=0.000569
[LightGBM] [Info] Start training from score 0.000569
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500142 -> initscore=0.000569
[LightGBM] [Info] Start training from score 0.000569
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500142 -> initscore=0.000569
[LightGBM] [Info] Start training from score 0.000569
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2018-07-01 15:53:47,960 - DEBUG - lgbm.py:142 - boost_rounds=2
2018-07-01 15:53:47,960 - DEBUG - lgbm.py:143 - mean_merror=0.3628595276444895
2018-07-01 15:53:47,960 - DEBUG - lgbm.py:144 - best_params['max_bin']=7
2018-07-01 15:53:47,960 - DEBUG - lgbm.py:145 - best_params['min_data_in_leaf']=30
2018-07-01 15:53:47,960 - DEBUG - lgbm.py:261 - {'boosting_type': 'gbdt', 'objective': 'binary', 'metric': ['binary_error'], 'device': 'gpu', 'gpu_platform_id': 0, 'gpu_device_id': 0, 'boosting': 'dart', 'learning_rate': 0.01, 'num_leaves': 165, 'max_depth': 7, 'max_bin': 7, 'min_data_in_leaf': 10, 'feature_fraction': 0.6, 'bagging_fraction': 1, 'bagging_freq': 0, 'lambda_l1': 0, 'lambda_l2': 0, 'min_split_gain': 0.1, 'sparse_threshold': 1.0, 'verbose': 1}
2018-07-01 15:53:47,960 - DEBUG - lgbm.py:273 - CV:bagging_fraction
2018-07-01 15:53:47,960 - DEBUG - lgbm.py:79 - 交叉验证
2018-07-01 15:53:47,961 - DEBUG - lgbm.py:165 - 调参3：降低过拟合
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Fatal] Check failed: bagging_fraction >0.0 at /home/zhijiehuang/github/LightGBM/src/io/config_auto.cpp, line 271 .

设置参数
(6865066, 101)
[1]	cv_agg's binary_error: 0.384476 + 0.000336156
[2]	cv_agg's binary_error: 0.369473 + 0.00150022
[3]	cv_agg's binary_error: 0.362853 + 0.000544881
[4]	cv_agg's binary_error: 0.363502 + 0.000880055
[5]	cv_agg's binary_error: 0.364511 + 0.000513306
[6]	cv_agg's binary_error: 0.365555 + 0.00088717
[1]	cv_agg's binary_error: 0.384476 + 0.000336156
[2]	cv_agg's binary_error: 0.369473 + 0.00150038
[3]	cv_agg's binary_error: 0.362854 + 0.000543382
[4]	cv_agg's binary_error: 0.363502 + 0.000879338
[5]	cv_agg's binary_error: 0.364512 + 0.000512851
[6]	cv_agg's binary_error: 0.365556 + 0.00088701
[1]	cv_agg's binary_error: 0.384475 + 0.000336359
[2]	cv_agg's binary_error: 0.369473 + 0.0015007
[3]	cv_agg's binary_error: 0.362855 + 0.000544262
[4]	cv_agg's binary_error: 0.363501 + 0.000878851
[5]	cv_agg's binary_error: 0.364512 + 0.000513822
[6]	cv_agg's binary_error: 0.365555 + 0.000887456
[1]	cv_agg's binary_error: 0.384476 + 0.000336019
[2]	cv_agg's binary_error: 0.369475 + 0.00150241
[3]	cv_agg's binary_error: 0.362855 + 0.000544713
[4]	cv_agg's binary_error: 0.363504 + 0.000882284
[5]	cv_agg's binary_error: 0.364513 + 0.000513407
[6]	cv_agg's binary_error: 0.365558 + 0.000889033
[1]	cv_agg's binary_error: 0.38448 + 0.00033178
[2]	cv_agg's binary_error: 0.369485 + 0.00150752
[3]	cv_agg's binary_error: 0.36286 + 0.000548057
[4]	cv_agg's binary_error: 0.363508 + 0.000885073
[5]	cv_agg's binary_error: 0.36454 + 0.000535438
[6]	cv_agg's binary_error: 0.365593 + 0.000927444
Traceback (most recent call last):
  File "lgbm.py", line 321, in <module>
    done()
  File "lgbm.py", line 274, in done
    modelfit_cv(train_save,cv_type=oper)
  File "lgbm.py", line 180, in modelfit_cv
    verbose_eval=True
  File "/home/zhijiehuang/anaconda3/lib/python3.6/site-packages/lightgbm/engine.py", line 422, in cv
    stratified=stratified, shuffle=shuffle)
  File "/home/zhijiehuang/anaconda3/lib/python3.6/site-packages/lightgbm/engine.py", line 296, in _make_n_folds
    cvbooster = Booster(tparam, train_set)
  File "/home/zhijiehuang/anaconda3/lib/python3.6/site-packages/lightgbm/basic.py", line 1307, in __init__
    train_set.construct().handle,
  File "/home/zhijiehuang/anaconda3/lib/python3.6/site-packages/lightgbm/basic.py", line 852, in construct
    ctypes.byref(self.handle)))
  File "/home/zhijiehuang/anaconda3/lib/python3.6/site-packages/lightgbm/basic.py", line 49, in _safe_call
    raise LightGBMError(decode_string(_LIB.LGBM_GetLastError()))
lightgbm.basic.LightGBMError: Check failed: bagging_fraction >0.0 at /home/zhijiehuang/github/LightGBM/src/io/config_auto.cpp, line 271 .

2018-07-01 15:55:27,145 - DEBUG - data_preprocessing.py:204 - data1.shape:(6865066, 5)
2018-07-01 15:55:27,145 - DEBUG - data_preprocessing.py:205 - data2.shape:(6865066, 5)
2018-07-01 15:55:27,448 - DEBUG - data_preprocessing.py:208 - 结果.shape:(6865066, 10)
2018-07-01 15:55:27,448 - DEBUG - data_preprocessing.py:209 - 耗时0.0001556873321533203
2018-07-01 15:55:49,042 - DEBUG - data_preprocessing.py:204 - data1.shape:(6865066, 10)
2018-07-01 15:55:49,042 - DEBUG - data_preprocessing.py:205 - data2.shape:(6865066, 60)
2018-07-01 15:55:51,173 - DEBUG - data_preprocessing.py:208 - 结果.shape:(6865066, 70)
2018-07-01 15:55:51,173 - DEBUG - data_preprocessing.py:209 - 耗时0.0001595020294189453
2018-07-01 15:55:55,511 - DEBUG - data_preprocessing.py:204 - data1.shape:(6865066, 70)
2018-07-01 15:55:55,511 - DEBUG - data_preprocessing.py:205 - data2.shape:(6865066, 11)
2018-07-01 15:56:02,112 - DEBUG - data_preprocessing.py:208 - 结果.shape:(6865066, 81)
2018-07-01 15:56:02,112 - DEBUG - data_preprocessing.py:209 - 耗时0.00015616416931152344
2018-07-01 15:56:20,219 - DEBUG - data_preprocessing.py:204 - data1.shape:(6865066, 81)
2018-07-01 15:56:20,219 - DEBUG - data_preprocessing.py:205 - data2.shape:(6865066, 20)
2018-07-01 15:56:27,911 - DEBUG - data_preprocessing.py:208 - 结果.shape:(6865066, 101)
2018-07-01 15:56:27,911 - DEBUG - data_preprocessing.py:209 - 耗时0.00015544891357421875
2018-07-01 15:56:28,019 - DEBUG - data_preprocessing.py:382 - Index(['C14', 'C17', 'C21', 'device_model', 'site_domain', 'one_day',
       'one_day_hour', 'day_hour_prev', 'day_hour_next', 'is_work_day',
       ...
       'exptv_C17C21', 'cnttv_C17C21', 'exptv_C17site_domain',
       'cnttv_C17site_domain', 'exptv_C21device_model',
       'cnttv_C21device_model', 'exptv_C21site_domain', 'cnttv_C21site_domain',
       'exptv_site_domaindevice_model', 'cnttv_site_domaindevice_model'],
      dtype='object', length=101)
2018-07-01 15:56:29,518 - DEBUG - data_preprocessing.py:204 - data1.shape:(4577464, 5)
2018-07-01 15:56:29,518 - DEBUG - data_preprocessing.py:205 - data2.shape:(4577464, 5)
2018-07-01 15:56:29,582 - DEBUG - data_preprocessing.py:208 - 结果.shape:(4577464, 10)
2018-07-01 15:56:29,582 - DEBUG - data_preprocessing.py:209 - 耗时0.00015401840209960938
2018-07-01 15:56:42,684 - DEBUG - data_preprocessing.py:204 - data1.shape:(4577464, 10)
2018-07-01 15:56:42,684 - DEBUG - data_preprocessing.py:205 - data2.shape:(4577464, 60)
2018-07-01 15:56:44,087 - DEBUG - data_preprocessing.py:208 - 结果.shape:(4577464, 70)
2018-07-01 15:56:44,087 - DEBUG - data_preprocessing.py:209 - 耗时0.00015544891357421875
2018-07-01 15:56:46,897 - DEBUG - data_preprocessing.py:204 - data1.shape:(4577464, 70)
2018-07-01 15:56:46,897 - DEBUG - data_preprocessing.py:205 - data2.shape:(4577464, 11)
2018-07-01 15:56:51,268 - DEBUG - data_preprocessing.py:208 - 结果.shape:(4577464, 81)
2018-07-01 15:56:51,268 - DEBUG - data_preprocessing.py:209 - 耗时0.00015878677368164062
2018-07-01 15:57:03,413 - DEBUG - data_preprocessing.py:204 - data1.shape:(4577464, 81)
2018-07-01 15:57:03,413 - DEBUG - data_preprocessing.py:205 - data2.shape:(4577464, 20)
2018-07-01 15:57:08,581 - DEBUG - data_preprocessing.py:208 - 结果.shape:(4577464, 101)
2018-07-01 15:57:08,581 - DEBUG - data_preprocessing.py:209 - 耗时0.00015997886657714844
2018-07-01 15:57:08,652 - DEBUG - data_preprocessing.py:391 - (6865066, 101)
2018-07-01 15:57:08,652 - DEBUG - data_preprocessing.py:392 - (4577464, 101)
/home/zhijiehuang/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.
  FutureWarning)
2018-07-01 15:57:34,574 - DEBUG - data_preprocessing.py:411 -            C14   C17  C21  device_model  site_domain  one_day  one_day_hour  \
2445499  21611  2480   61          5524         6124        1             0   

         day_hour_prev  day_hour_next  is_work_day  \
2445499             -1              1            1   

                     ...                exptv_C17C21  cnttv_C17C21  \
2445499              ...                    0.239964        796075   

         exptv_C17site_domain  cnttv_C17site_domain  exptv_C21device_model  \
2445499              0.236913                501032               0.188062   

         cnttv_C21device_model  exptv_C21site_domain  cnttv_C21site_domain  \
2445499                 226216              0.163896               2897548   

         exptv_site_domaindevice_model  cnttv_site_domaindevice_model  
2445499                       0.114806                         384227  

[1 rows x 100 columns]
2018-07-01 15:57:34,580 - DEBUG - data_preprocessing.py:412 - 2445499    0
Name: click, dtype: int64
2018-07-01 15:57:34,581 - DEBUG - lgbm.py:270 - 设置参数
2018-07-01 15:57:34,581 - DEBUG - lgbm.py:273 - CV:max_bin
2018-07-01 15:57:34,581 - DEBUG - lgbm.py:79 - 交叉验证
2018-07-01 15:57:34,581 - DEBUG - lgbm.py:124 - 调参2：降低过拟合
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Info] Number of positive: 2060105, number of negative: 2058934
[LightGBM] [Info] This is the GPU trainer!!
[LightGBM] [Info] Total Bins 484
[LightGBM] [Info] Number of data: 4119039, number of used features: 99
[LightGBM] [Info] Using requested OpenCL platform 0 device 0
[LightGBM] [Info] Using GPU Device: GeForce GTX 1070 Ti, Vendor: NVIDIA Corporation
[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...
[LightGBM] [Info] GPU programs have been built
[LightGBM] [Info] Size of histogram bin entry: 12
[LightGBM] [Info] 98 dense feature groups (204.27 MB) transfered to GPU in 0.264849 secs. 0 sparse feature groups
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Info] Number of positive: 2060105, number of negative: 2058934
[LightGBM] [Info] This is the GPU trainer!!
[LightGBM] [Info] Total Bins 484
[LightGBM] [Info] Number of data: 4119039, number of used features: 99
[LightGBM] [Info] Using requested OpenCL platform 0 device 0
[LightGBM] [Info] Using GPU Device: GeForce GTX 1070 Ti, Vendor: NVIDIA Corporation
[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...
[LightGBM] [Info] GPU programs have been built
[LightGBM] [Info] Size of histogram bin entry: 12
[LightGBM] [Info] 98 dense feature groups (204.27 MB) transfered to GPU in 0.276638 secs. 0 sparse feature groups
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Info] Number of positive: 2060106, number of negative: 2058934
[LightGBM] [Info] This is the GPU trainer!!
[LightGBM] [Info] Total Bins 484
[LightGBM] [Info] Number of data: 4119040, number of used features: 99
[LightGBM] [Info] Using requested OpenCL platform 0 device 0
[LightGBM] [Info] Using GPU Device: GeForce GTX 1070 Ti, Vendor: NVIDIA Corporation
[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...
[LightGBM] [Info] GPU programs have been built
[LightGBM] [Info] Size of histogram bin entry: 12
[LightGBM] [Info] 98 dense feature groups (204.27 MB) transfered to GPU in 0.262111 secs. 0 sparse feature groups
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500142 -> initscore=0.000569
[LightGBM] [Info] Start training from score 0.000569
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500142 -> initscore=0.000569
[LightGBM] [Info] Start training from score 0.000569
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500142 -> initscore=0.000569
[LightGBM] [Info] Start training from score 0.000569
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
lgbm.py:141: FutureWarning: 'argmin' is deprecated. Use 'idxmin' instead. The behavior of 'argmin' will be corrected to return the positional minimum in the future. Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_error-mean']).argmin()
2018-07-01 15:57:59,232 - DEBUG - lgbm.py:142 - boost_rounds=2
2018-07-01 15:57:59,232 - DEBUG - lgbm.py:143 - mean_merror=0.36285289179335756
2018-07-01 15:57:59,232 - DEBUG - lgbm.py:144 - best_params['max_bin']=7
2018-07-01 15:57:59,232 - DEBUG - lgbm.py:145 - best_params['min_data_in_leaf']=10
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Info] Number of positive: 2060105, number of negative: 2058934
[LightGBM] [Info] This is the GPU trainer!!
[LightGBM] [Info] Total Bins 484
[LightGBM] [Info] Number of data: 4119039, number of used features: 99
[LightGBM] [Info] Using requested OpenCL platform 0 device 0
[LightGBM] [Info] Using GPU Device: GeForce GTX 1070 Ti, Vendor: NVIDIA Corporation
[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...
[LightGBM] [Info] GPU programs have been built
[LightGBM] [Info] Size of histogram bin entry: 12
[LightGBM] [Info] 98 dense feature groups (204.27 MB) transfered to GPU in 0.235064 secs. 0 sparse feature groups
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Info] Number of positive: 2060105, number of negative: 2058934
[LightGBM] [Info] This is the GPU trainer!!
[LightGBM] [Info] Total Bins 484
[LightGBM] [Info] Number of data: 4119039, number of used features: 99
[LightGBM] [Info] Using requested OpenCL platform 0 device 0
[LightGBM] [Info] Using GPU Device: GeForce GTX 1070 Ti, Vendor: NVIDIA Corporation
[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...
[LightGBM] [Info] GPU programs have been built
[LightGBM] [Info] Size of histogram bin entry: 12
[LightGBM] [Info] 98 dense feature groups (204.27 MB) transfered to GPU in 0.229944 secs. 0 sparse feature groups
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Info] Number of positive: 2060106, number of negative: 2058934
[LightGBM] [Info] This is the GPU trainer!!
[LightGBM] [Info] Total Bins 484
[LightGBM] [Info] Number of data: 4119040, number of used features: 99
[LightGBM] [Info] Using requested OpenCL platform 0 device 0
[LightGBM] [Info] Using GPU Device: GeForce GTX 1070 Ti, Vendor: NVIDIA Corporation
[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...
[LightGBM] [Info] GPU programs have been built
[LightGBM] [Info] Size of histogram bin entry: 12
[LightGBM] [Info] 98 dense feature groups (204.27 MB) transfered to GPU in 0.249450 secs. 0 sparse feature groups
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500142 -> initscore=0.000569
[LightGBM] [Info] Start training from score 0.000569
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500142 -> initscore=0.000569
[LightGBM] [Info] Start training from score 0.000569
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500142 -> initscore=0.000569
[LightGBM] [Info] Start training from score 0.000569
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2018-07-01 15:58:07,224 - DEBUG - lgbm.py:142 - boost_rounds=2
2018-07-01 15:58:07,224 - DEBUG - lgbm.py:143 - mean_merror=0.36285370104340936
2018-07-01 15:58:07,224 - DEBUG - lgbm.py:144 - best_params['max_bin']=7
2018-07-01 15:58:07,224 - DEBUG - lgbm.py:145 - best_params['min_data_in_leaf']=15
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Info] Number of positive: 2060105, number of negative: 2058934
[LightGBM] [Info] This is the GPU trainer!!
[LightGBM] [Info] Total Bins 484
[LightGBM] [Info] Number of data: 4119039, number of used features: 99
[LightGBM] [Info] Using requested OpenCL platform 0 device 0
[LightGBM] [Info] Using GPU Device: GeForce GTX 1070 Ti, Vendor: NVIDIA Corporation
[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...
[LightGBM] [Info] GPU programs have been built
[LightGBM] [Info] Size of histogram bin entry: 12
[LightGBM] [Info] 98 dense feature groups (204.27 MB) transfered to GPU in 0.229259 secs. 0 sparse feature groups
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Info] Number of positive: 2060105, number of negative: 2058934
[LightGBM] [Info] This is the GPU trainer!!
[LightGBM] [Info] Total Bins 484
[LightGBM] [Info] Number of data: 4119039, number of used features: 99
[LightGBM] [Info] Using requested OpenCL platform 0 device 0
[LightGBM] [Info] Using GPU Device: GeForce GTX 1070 Ti, Vendor: NVIDIA Corporation
[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...
[LightGBM] [Info] GPU programs have been built
[LightGBM] [Info] Size of histogram bin entry: 12
[LightGBM] [Info] 98 dense feature groups (204.27 MB) transfered to GPU in 0.229335 secs. 0 sparse feature groups
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Info] Number of positive: 2060106, number of negative: 2058934
[LightGBM] [Info] This is the GPU trainer!!
[LightGBM] [Info] Total Bins 484
[LightGBM] [Info] Number of data: 4119040, number of used features: 99
[LightGBM] [Info] Using requested OpenCL platform 0 device 0
[LightGBM] [Info] Using GPU Device: GeForce GTX 1070 Ti, Vendor: NVIDIA Corporation
[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...
[LightGBM] [Info] GPU programs have been built
[LightGBM] [Info] Size of histogram bin entry: 12
[LightGBM] [Info] 98 dense feature groups (204.27 MB) transfered to GPU in 0.273668 secs. 0 sparse feature groups
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500142 -> initscore=0.000569
[LightGBM] [Info] Start training from score 0.000569
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500142 -> initscore=0.000569
[LightGBM] [Info] Start training from score 0.000569
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500142 -> initscore=0.000569
[LightGBM] [Info] Start training from score 0.000569
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2018-07-01 15:58:15,153 - DEBUG - lgbm.py:142 - boost_rounds=2
2018-07-01 15:58:15,153 - DEBUG - lgbm.py:143 - mean_merror=0.3628546721434715
2018-07-01 15:58:15,154 - DEBUG - lgbm.py:144 - best_params['max_bin']=7
2018-07-01 15:58:15,154 - DEBUG - lgbm.py:145 - best_params['min_data_in_leaf']=20
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Info] Number of positive: 2060105, number of negative: 2058934
[LightGBM] [Info] This is the GPU trainer!!
[LightGBM] [Info] Total Bins 484
[LightGBM] [Info] Number of data: 4119039, number of used features: 99
[LightGBM] [Info] Using requested OpenCL platform 0 device 0
[LightGBM] [Info] Using GPU Device: GeForce GTX 1070 Ti, Vendor: NVIDIA Corporation
[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...
[LightGBM] [Info] GPU programs have been built
[LightGBM] [Info] Size of histogram bin entry: 12
[LightGBM] [Info] 98 dense feature groups (204.27 MB) transfered to GPU in 0.244783 secs. 0 sparse feature groups
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Info] Number of positive: 2060105, number of negative: 2058934
[LightGBM] [Info] This is the GPU trainer!!
[LightGBM] [Info] Total Bins 484
[LightGBM] [Info] Number of data: 4119039, number of used features: 99
[LightGBM] [Info] Using requested OpenCL platform 0 device 0
[LightGBM] [Info] Using GPU Device: GeForce GTX 1070 Ti, Vendor: NVIDIA Corporation
[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...
[LightGBM] [Info] GPU programs have been built
[LightGBM] [Info] Size of histogram bin entry: 12
[LightGBM] [Info] 98 dense feature groups (204.27 MB) transfered to GPU in 0.234151 secs. 0 sparse feature groups
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Info] Number of positive: 2060106, number of negative: 2058934
[LightGBM] [Info] This is the GPU trainer!!
[LightGBM] [Info] Total Bins 484
[LightGBM] [Info] Number of data: 4119040, number of used features: 99
[LightGBM] [Info] Using requested OpenCL platform 0 device 0
[LightGBM] [Info] Using GPU Device: GeForce GTX 1070 Ti, Vendor: NVIDIA Corporation
[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...
[LightGBM] [Info] GPU programs have been built
[LightGBM] [Info] Size of histogram bin entry: 12
[LightGBM] [Info] 98 dense feature groups (204.27 MB) transfered to GPU in 0.279078 secs. 0 sparse feature groups
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500142 -> initscore=0.000569
[LightGBM] [Info] Start training from score 0.000569
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500142 -> initscore=0.000569
[LightGBM] [Info] Start training from score 0.000569
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500142 -> initscore=0.000569
[LightGBM] [Info] Start training from score 0.000569
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2018-07-01 15:58:23,203 - DEBUG - lgbm.py:142 - boost_rounds=2
2018-07-01 15:58:23,203 - DEBUG - lgbm.py:143 - mean_merror=0.36285499584364933
2018-07-01 15:58:23,204 - DEBUG - lgbm.py:144 - best_params['max_bin']=7
2018-07-01 15:58:23,204 - DEBUG - lgbm.py:145 - best_params['min_data_in_leaf']=25
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Info] Number of positive: 2060105, number of negative: 2058934
[LightGBM] [Info] This is the GPU trainer!!
[LightGBM] [Info] Total Bins 484
[LightGBM] [Info] Number of data: 4119039, number of used features: 99
[LightGBM] [Info] Using requested OpenCL platform 0 device 0
[LightGBM] [Info] Using GPU Device: GeForce GTX 1070 Ti, Vendor: NVIDIA Corporation
[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...
[LightGBM] [Info] GPU programs have been built
[LightGBM] [Info] Size of histogram bin entry: 12
[LightGBM] [Info] 98 dense feature groups (204.27 MB) transfered to GPU in 0.227694 secs. 0 sparse feature groups
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Info] Number of positive: 2060105, number of negative: 2058934
[LightGBM] [Info] This is the GPU trainer!!
[LightGBM] [Info] Total Bins 484
[LightGBM] [Info] Number of data: 4119039, number of used features: 99
[LightGBM] [Info] Using requested OpenCL platform 0 device 0
[LightGBM] [Info] Using GPU Device: GeForce GTX 1070 Ti, Vendor: NVIDIA Corporation
[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...
[LightGBM] [Info] GPU programs have been built
[LightGBM] [Info] Size of histogram bin entry: 12
[LightGBM] [Info] 98 dense feature groups (204.27 MB) transfered to GPU in 0.242072 secs. 0 sparse feature groups
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Info] Number of positive: 2060106, number of negative: 2058934
[LightGBM] [Info] This is the GPU trainer!!
[LightGBM] [Info] Total Bins 484
[LightGBM] [Info] Number of data: 4119040, number of used features: 99
[LightGBM] [Info] Using requested OpenCL platform 0 device 0
[LightGBM] [Info] Using GPU Device: GeForce GTX 1070 Ti, Vendor: NVIDIA Corporation
[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...
[LightGBM] [Info] GPU programs have been built
[LightGBM] [Info] Size of histogram bin entry: 12
[LightGBM] [Info] 98 dense feature groups (204.27 MB) transfered to GPU in 0.272888 secs. 0 sparse feature groups
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500142 -> initscore=0.000569
[LightGBM] [Info] Start training from score 0.000569
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500142 -> initscore=0.000569
[LightGBM] [Info] Start training from score 0.000569
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500142 -> initscore=0.000569
[LightGBM] [Info] Start training from score 0.000569
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2018-07-01 15:58:31,123 - DEBUG - lgbm.py:142 - boost_rounds=2
2018-07-01 15:58:31,123 - DEBUG - lgbm.py:143 - mean_merror=0.3628595276444895
2018-07-01 15:58:31,123 - DEBUG - lgbm.py:144 - best_params['max_bin']=7
2018-07-01 15:58:31,123 - DEBUG - lgbm.py:145 - best_params['min_data_in_leaf']=30
2018-07-01 15:58:31,123 - DEBUG - lgbm.py:261 - {'boosting_type': 'gbdt', 'objective': 'binary', 'metric': ['binary_error'], 'device': 'gpu', 'gpu_platform_id': 0, 'gpu_device_id': 0, 'boosting': 'dart', 'learning_rate': 0.01, 'num_leaves': 165, 'max_depth': 7, 'max_bin': 7, 'min_data_in_leaf': 10, 'feature_fraction': 0.6, 'bagging_fraction': 1, 'bagging_freq': 0, 'lambda_l1': 0, 'lambda_l2': 0, 'min_split_gain': 0.1, 'sparse_threshold': 1.0, 'verbose': 1}
2018-07-01 15:58:31,129 - DEBUG - lgbm.py:273 - CV:bagging_fraction
2018-07-01 15:58:31,129 - DEBUG - lgbm.py:79 - 交叉验证
2018-07-01 15:58:31,129 - DEBUG - lgbm.py:165 - 调参3：降低过拟合
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Info] Number of positive: 2060105, number of negative: 2058934
[LightGBM] [Info] This is the GPU trainer!!
[LightGBM] [Info] Total Bins 484
[LightGBM] [Info] Number of data: 4119039, number of used features: 99
[LightGBM] [Info] Using requested OpenCL platform 0 device 0
[LightGBM] [Info] Using GPU Device: GeForce GTX 1070 Ti, Vendor: NVIDIA Corporation
[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...
[LightGBM] [Info] GPU programs have been built
[LightGBM] [Info] Size of histogram bin entry: 12
[LightGBM] [Info] 98 dense feature groups (204.27 MB) transfered to GPU in 0.226925 secs. 0 sparse feature groups
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Info] Number of positive: 2060105, number of negative: 2058934
[LightGBM] [Info] This is the GPU trainer!!
[LightGBM] [Info] Total Bins 484
[LightGBM] [Info] Number of data: 4119039, number of used features: 99
[LightGBM] [Info] Using requested OpenCL platform 0 device 0
[LightGBM] [Info] Using GPU Device: GeForce GTX 1070 Ti, Vendor: NVIDIA Corporation
[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...
[LightGBM] [Info] GPU programs have been built
[LightGBM] [Info] Size of histogram bin entry: 12
[LightGBM] [Info] 98 dense feature groups (204.27 MB) transfered to GPU in 0.245613 secs. 0 sparse feature groups
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Info] Number of positive: 2060106, number of negative: 2058934
[LightGBM] [Info] This is the GPU trainer!!
[LightGBM] [Info] Total Bins 484
[LightGBM] [Info] Number of data: 4119040, number of used features: 99
[LightGBM] [Info] Using requested OpenCL platform 0 device 0
[LightGBM] [Info] Using GPU Device: GeForce GTX 1070 Ti, Vendor: NVIDIA Corporation
[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...
[LightGBM] [Info] GPU programs have been built
[LightGBM] [Info] Size of histogram bin entry: 12
[LightGBM] [Info] 98 dense feature groups (204.27 MB) transfered to GPU in 0.278055 secs. 0 sparse feature groups
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500142 -> initscore=0.000569
[LightGBM] [Info] Start training from score 0.000569
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500142 -> initscore=0.000569
[LightGBM] [Info] Start training from score 0.000569
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500142 -> initscore=0.000569
[LightGBM] [Info] Start training from score 0.000569
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
lgbm.py:184: FutureWarning: 'argmin' is deprecated. Use 'idxmin' instead. The behavior of 'argmin' will be corrected to return the positional minimum in the future. Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_error-mean']).argmin()
2018-07-01 15:58:39,885 - DEBUG - lgbm.py:185 - boost_rounds=4
2018-07-01 15:58:39,885 - DEBUG - lgbm.py:186 - mean_merror=0.3994237168238366
2018-07-01 15:58:39,885 - DEBUG - lgbm.py:188 - best_params['feature_fraction']=0.1
2018-07-01 15:58:39,885 - DEBUG - lgbm.py:189 - best_params['bagging_fraction']=0.1
2018-07-01 15:58:39,885 - DEBUG - lgbm.py:190 - best_params['bagging_freq']=0
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Info] Number of positive: 2060105, number of negative: 2058934
[LightGBM] [Info] This is the GPU trainer!!
[LightGBM] [Info] Total Bins 484
[LightGBM] [Info] Number of data: 4119039, number of used features: 99
[LightGBM] [Info] Using requested OpenCL platform 0 device 0
[LightGBM] [Info] Using GPU Device: GeForce GTX 1070 Ti, Vendor: NVIDIA Corporation
[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...
[LightGBM] [Info] GPU programs have been built
[LightGBM] [Info] Size of histogram bin entry: 12
[LightGBM] [Info] 98 dense feature groups (204.27 MB) transfered to GPU in 0.237143 secs. 0 sparse feature groups
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Info] Number of positive: 2060105, number of negative: 2058934
[LightGBM] [Info] This is the GPU trainer!!
[LightGBM] [Info] Total Bins 484
[LightGBM] [Info] Number of data: 4119039, number of used features: 99
[LightGBM] [Info] Using requested OpenCL platform 0 device 0
[LightGBM] [Info] Using GPU Device: GeForce GTX 1070 Ti, Vendor: NVIDIA Corporation
[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...
[LightGBM] [Info] GPU programs have been built
[LightGBM] [Info] Size of histogram bin entry: 12
[LightGBM] [Info] 98 dense feature groups (204.27 MB) transfered to GPU in 0.245981 secs. 0 sparse feature groups
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Info] Number of positive: 2060106, number of negative: 2058934
[LightGBM] [Info] This is the GPU trainer!!
[LightGBM] [Info] Total Bins 484
[LightGBM] [Info] Number of data: 4119040, number of used features: 99
[LightGBM] [Info] Using requested OpenCL platform 0 device 0
[LightGBM] [Info] Using GPU Device: GeForce GTX 1070 Ti, Vendor: NVIDIA Corporation
[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...
[LightGBM] [Info] GPU programs have been built
[LightGBM] [Info] Size of histogram bin entry: 12
[LightGBM] [Info] 98 dense feature groups (204.27 MB) transfered to GPU in 0.272385 secs. 0 sparse feature groups
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500142 -> initscore=0.000569
[LightGBM] [Info] Start training from score 0.000569
[LightGBM] [Info] Size of histogram bin entry: 12
[LightGBM] [Info] 98 dense feature groups (20.43 MB) transfered to GPU in 0.092731 secs. 0 sparse feature groups
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500142 -> initscore=0.000569
[LightGBM] [Info] Start training from score 0.000569
[LightGBM] [Info] Size of histogram bin entry: 12
[LightGBM] [Info] 98 dense feature groups (20.43 MB) transfered to GPU in 0.031180 secs. 0 sparse feature groups
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500142 -> initscore=0.000569
[LightGBM] [Info] Start training from score 0.000569
[LightGBM] [Info] Size of histogram bin entry: 12
[LightGBM] [Info] 98 dense feature groups (20.43 MB) transfered to GPU in 0.030842 secs. 0 sparse feature groups
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Info] Size of histogram bin entry: 12
[LightGBM] [Info] 98 dense feature groups (20.43 MB) transfered to GPU in 0.027813 secs. 0 sparse feature groups
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Info] Size of histogram bin entry: 12
[LightGBM] [Info] 98 dense feature groups (20.43 MB) transfered to GPU in 0.029085 secs. 0 sparse feature groups
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Info] Size of histogram bin entry: 12
[LightGBM] [Info] 98 dense feature groups (20.43 MB) transfered to GPU in 0.083437 secs. 0 sparse feature groups
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2018-07-01 15:58:49,519 - DEBUG - lgbm.py:185 - boost_rounds=4
2018-07-01 15:58:49,519 - DEBUG - lgbm.py:186 - mean_merror=0.3997064688543303
2018-07-01 15:58:49,519 - DEBUG - lgbm.py:188 - best_params['feature_fraction']=0.1
2018-07-01 15:58:49,519 - DEBUG - lgbm.py:189 - best_params['bagging_fraction']=0.1
2018-07-01 15:58:49,519 - DEBUG - lgbm.py:190 - best_params['bagging_freq']=5
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Info] Number of positive: 2060105, number of negative: 2058934
[LightGBM] [Info] This is the GPU trainer!!
[LightGBM] [Info] Total Bins 484
[LightGBM] [Info] Number of data: 4119039, number of used features: 99
[LightGBM] [Info] Using requested OpenCL platform 0 device 0
[LightGBM] [Info] Using GPU Device: GeForce GTX 1070 Ti, Vendor: NVIDIA Corporation
[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...
[LightGBM] [Info] GPU programs have been built
[LightGBM] [Info] Size of histogram bin entry: 12
[LightGBM] [Info] 98 dense feature groups (204.27 MB) transfered to GPU in 0.196732 secs. 0 sparse feature groups
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Info] Number of positive: 2060105, number of negative: 2058934
[LightGBM] [Info] This is the GPU trainer!!
[LightGBM] [Info] Total Bins 484
[LightGBM] [Info] Number of data: 4119039, number of used features: 99
[LightGBM] [Info] Using requested OpenCL platform 0 device 0
[LightGBM] [Info] Using GPU Device: GeForce GTX 1070 Ti, Vendor: NVIDIA Corporation
[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...
[LightGBM] [Info] GPU programs have been built
[LightGBM] [Info] Size of histogram bin entry: 12
[LightGBM] [Info] 98 dense feature groups (204.27 MB) transfered to GPU in 0.247482 secs. 0 sparse feature groups
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Info] Number of positive: 2060106, number of negative: 2058934
[LightGBM] [Info] This is the GPU trainer!!
[LightGBM] [Info] Total Bins 484
[LightGBM] [Info] Number of data: 4119040, number of used features: 99
[LightGBM] [Info] Using requested OpenCL platform 0 device 0
[LightGBM] [Info] Using GPU Device: GeForce GTX 1070 Ti, Vendor: NVIDIA Corporation
[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...
[LightGBM] [Info] GPU programs have been built
[LightGBM] [Info] Size of histogram bin entry: 12
[LightGBM] [Info] 98 dense feature groups (204.27 MB) transfered to GPU in 0.232848 secs. 0 sparse feature groups
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500142 -> initscore=0.000569
[LightGBM] [Info] Start training from score 0.000569
[LightGBM] [Info] Size of histogram bin entry: 12
[LightGBM] [Info] 98 dense feature groups (20.43 MB) transfered to GPU in 0.032351 secs. 0 sparse feature groups
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500142 -> initscore=0.000569
[LightGBM] [Info] Start training from score 0.000569
[LightGBM] [Info] Size of histogram bin entry: 12
[LightGBM] [Info] 98 dense feature groups (20.43 MB) transfered to GPU in 0.031710 secs. 0 sparse feature groups
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500142 -> initscore=0.000569
[LightGBM] [Info] Start training from score 0.000569
[LightGBM] [Info] Size of histogram bin entry: 12
[LightGBM] [Info] 98 dense feature groups (20.43 MB) transfered to GPU in 0.052133 secs. 0 sparse feature groups
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2018-07-01 15:58:58,003 - DEBUG - lgbm.py:185 - boost_rounds=4
2018-07-01 15:58:58,003 - DEBUG - lgbm.py:186 - mean_merror=0.3997064688543303
2018-07-01 15:58:58,003 - DEBUG - lgbm.py:188 - best_params['feature_fraction']=0.1
2018-07-01 15:58:58,003 - DEBUG - lgbm.py:189 - best_params['bagging_fraction']=0.1
2018-07-01 15:58:58,003 - DEBUG - lgbm.py:190 - best_params['bagging_freq']=10
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Info] Number of positive: 2060105, number of negative: 2058934
[LightGBM] [Info] This is the GPU trainer!!
[LightGBM] [Info] Total Bins 484
[LightGBM] [Info] Number of data: 4119039, number of used features: 99
[LightGBM] [Info] Using requested OpenCL platform 0 device 0
[LightGBM] [Info] Using GPU Device: GeForce GTX 1070 Ti, Vendor: NVIDIA Corporation
[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...
[LightGBM] [Info] GPU programs have been built
[LightGBM] [Info] Size of histogram bin entry: 12
[LightGBM] [Info] 98 dense feature groups (204.27 MB) transfered to GPU in 0.233457 secs. 0 sparse feature groups
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Info] Number of positive: 2060105, number of negative: 2058934
[LightGBM] [Info] This is the GPU trainer!!
[LightGBM] [Info] Total Bins 484
[LightGBM] [Info] Number of data: 4119039, number of used features: 99
[LightGBM] [Info] Using requested OpenCL platform 0 device 0
[LightGBM] [Info] Using GPU Device: GeForce GTX 1070 Ti, Vendor: NVIDIA Corporation
[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...
[LightGBM] [Info] GPU programs have been built
[LightGBM] [Info] Size of histogram bin entry: 12
[LightGBM] [Info] 98 dense feature groups (204.27 MB) transfered to GPU in 0.236942 secs. 0 sparse feature groups
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Info] Number of positive: 2060106, number of negative: 2058934
[LightGBM] [Info] This is the GPU trainer!!
[LightGBM] [Info] Total Bins 484
[LightGBM] [Info] Number of data: 4119040, number of used features: 99
[LightGBM] [Info] Using requested OpenCL platform 0 device 0
[LightGBM] [Info] Using GPU Device: GeForce GTX 1070 Ti, Vendor: NVIDIA Corporation
[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...
[LightGBM] [Info] GPU programs have been built
[LightGBM] [Info] Size of histogram bin entry: 12
[LightGBM] [Info] 98 dense feature groups (204.27 MB) transfered to GPU in 0.240648 secs. 0 sparse feature groups
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500142 -> initscore=0.000569
[LightGBM] [Info] Start training from score 0.000569
[LightGBM] [Info] Size of histogram bin entry: 12
[LightGBM] [Info] 98 dense feature groups (20.43 MB) transfered to GPU in 0.031738 secs. 0 sparse feature groups
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500142 -> initscore=0.000569
[LightGBM] [Info] Start training from score 0.000569
[LightGBM] [Info] Size of histogram bin entry: 12
[LightGBM] [Info] 98 dense feature groups (20.43 MB) transfered to GPU in 0.091925 secs. 0 sparse feature groups
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500142 -> initscore=0.000569
[LightGBM] [Info] Start training from score 0.000569
[LightGBM] [Info] Size of histogram bin entry: 12
[LightGBM] [Info] 98 dense feature groups (20.43 MB) transfered to GPU in 0.031130 secs. 0 sparse feature groups
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2018-07-01 15:59:06,843 - DEBUG - lgbm.py:185 - boost_rounds=4
2018-07-01 15:59:06,844 - DEBUG - lgbm.py:186 - mean_merror=0.3997064688543303
2018-07-01 15:59:06,844 - DEBUG - lgbm.py:188 - best_params['feature_fraction']=0.1
2018-07-01 15:59:06,844 - DEBUG - lgbm.py:189 - best_params['bagging_fraction']=0.1
2018-07-01 15:59:06,844 - DEBUG - lgbm.py:190 - best_params['bagging_freq']=15
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Info] Number of positive: 2060105, number of negative: 2058934
[LightGBM] [Info] This is the GPU trainer!!
[LightGBM] [Info] Total Bins 484
[LightGBM] [Info] Number of data: 4119039, number of used features: 99
[LightGBM] [Info] Using requested OpenCL platform 0 device 0
[LightGBM] [Info] Using GPU Device: GeForce GTX 1070 Ti, Vendor: NVIDIA Corporation
[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...
[LightGBM] [Info] GPU programs have been built
[LightGBM] [Info] Size of histogram bin entry: 12
[LightGBM] [Info] 98 dense feature groups (204.27 MB) transfered to GPU in 0.241492 secs. 0 sparse feature groups
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Info] Number of positive: 2060105, number of negative: 2058934
[LightGBM] [Info] This is the GPU trainer!!
[LightGBM] [Info] Total Bins 484
[LightGBM] [Info] Number of data: 4119039, number of used features: 99
[LightGBM] [Info] Using requested OpenCL platform 0 device 0
[LightGBM] [Info] Using GPU Device: GeForce GTX 1070 Ti, Vendor: NVIDIA Corporation
[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...
[LightGBM] [Info] GPU programs have been built
[LightGBM] [Info] Size of histogram bin entry: 12
[LightGBM] [Info] 98 dense feature groups (204.27 MB) transfered to GPU in 0.217640 secs. 0 sparse feature groups
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Info] Number of positive: 2060106, number of negative: 2058934
[LightGBM] [Info] This is the GPU trainer!!
[LightGBM] [Info] Total Bins 484
[LightGBM] [Info] Number of data: 4119040, number of used features: 99
[LightGBM] [Info] Using requested OpenCL platform 0 device 0
[LightGBM] [Info] Using GPU Device: GeForce GTX 1070 Ti, Vendor: NVIDIA Corporation
[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...
[LightGBM] [Info] GPU programs have been built
[LightGBM] [Info] Size of histogram bin entry: 12
[LightGBM] [Info] 98 dense feature groups (204.27 MB) transfered to GPU in 0.191753 secs. 0 sparse feature groups
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500142 -> initscore=0.000569
[LightGBM] [Info] Start training from score 0.000569
[LightGBM] [Info] Size of histogram bin entry: 12
[LightGBM] [Info] 98 dense feature groups (20.43 MB) transfered to GPU in 0.032123 secs. 0 sparse feature groups
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500142 -> initscore=0.000569
[LightGBM] [Info] Start training from score 0.000569
[LightGBM] [Info] Size of histogram bin entry: 12
[LightGBM] [Info] 98 dense feature groups (20.43 MB) transfered to GPU in 0.038652 secs. 0 sparse feature groups
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500142 -> initscore=0.000569
[LightGBM] [Info] Start training from score 0.000569
[LightGBM] [Info] Size of histogram bin entry: 12
[LightGBM] [Info] 98 dense feature groups (20.43 MB) transfered to GPU in 0.031399 secs. 0 sparse feature groups
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2018-07-01 15:59:15,247 - DEBUG - lgbm.py:185 - boost_rounds=4
2018-07-01 15:59:15,247 - DEBUG - lgbm.py:186 - mean_merror=0.3997064688543303
2018-07-01 15:59:15,247 - DEBUG - lgbm.py:188 - best_params['feature_fraction']=0.1
2018-07-01 15:59:15,247 - DEBUG - lgbm.py:189 - best_params['bagging_fraction']=0.1
2018-07-01 15:59:15,247 - DEBUG - lgbm.py:190 - best_params['bagging_freq']=20
2018-07-01 15:59:15,247 - DEBUG - lgbm.py:261 - {'boosting_type': 'gbdt', 'objective': 'binary', 'metric': ['binary_error'], 'device': 'gpu', 'gpu_platform_id': 0, 'gpu_device_id': 0, 'boosting': 'dart', 'learning_rate': 0.01, 'num_leaves': 165, 'max_depth': 7, 'max_bin': 7, 'min_data_in_leaf': 10, 'feature_fraction': 0.1, 'bagging_fraction': 0.1, 'bagging_freq': 0, 'lambda_l1': 0, 'lambda_l2': 0, 'min_split_gain': 0.1, 'sparse_threshold': 1.0, 'verbose': 1}
2018-07-01 15:59:15,252 - DEBUG - lgbm.py:273 - CV:lambda
2018-07-01 15:59:15,252 - DEBUG - lgbm.py:79 - 交叉验证
2018-07-01 15:59:15,252 - DEBUG - lgbm.py:214 - 调参4：降低过拟合
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Info] Number of positive: 2060105, number of negative: 2058934
[LightGBM] [Info] This is the GPU trainer!!
[LightGBM] [Info] Total Bins 484
[LightGBM] [Info] Number of data: 4119039, number of used features: 99
[LightGBM] [Info] Using requested OpenCL platform 0 device 0
[LightGBM] [Info] Using GPU Device: GeForce GTX 1070 Ti, Vendor: NVIDIA Corporation
[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...
[LightGBM] [Info] GPU programs have been built
[LightGBM] [Info] Size of histogram bin entry: 12
[LightGBM] [Info] 98 dense feature groups (204.27 MB) transfered to GPU in 0.240134 secs. 0 sparse feature groups
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Info] Number of positive: 2060105, number of negative: 2058934
[LightGBM] [Info] This is the GPU trainer!!
[LightGBM] [Info] Total Bins 484
[LightGBM] [Info] Number of data: 4119039, number of used features: 99
[LightGBM] [Info] Using requested OpenCL platform 0 device 0
[LightGBM] [Info] Using GPU Device: GeForce GTX 1070 Ti, Vendor: NVIDIA Corporation
[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...
[LightGBM] [Info] GPU programs have been built
[LightGBM] [Info] Size of histogram bin entry: 12
[LightGBM] [Info] 98 dense feature groups (204.27 MB) transfered to GPU in 0.250062 secs. 0 sparse feature groups
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Info] Number of positive: 2060106, number of negative: 2058934
[LightGBM] [Info] This is the GPU trainer!!
[LightGBM] [Info] Total Bins 484
[LightGBM] [Info] Number of data: 4119040, number of used features: 99
[LightGBM] [Info] Using requested OpenCL platform 0 device 0
[LightGBM] [Info] Using GPU Device: GeForce GTX 1070 Ti, Vendor: NVIDIA Corporation
[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...
[LightGBM] [Info] GPU programs have been built
[LightGBM] [Info] Size of histogram bin entry: 12
[LightGBM] [Info] 98 dense feature groups (204.27 MB) transfered to GPU in 0.238233 secs. 0 sparse feature groups
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500142 -> initscore=0.000569
[LightGBM] [Info] Start training from score 0.000569
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500142 -> initscore=0.000569
[LightGBM] [Info] Start training from score 0.000569
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500142 -> initscore=0.000569
[LightGBM] [Info] Start training from score 0.000569
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
lgbm.py:233: FutureWarning: 'argmin' is deprecated. Use 'idxmin' instead. The behavior of 'argmin' will be corrected to return the positional minimum in the future. Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_error-mean']).argmin()
2018-07-01 15:59:23,942 - DEBUG - lgbm.py:234 - boost_rounds=4
2018-07-01 15:59:23,942 - DEBUG - lgbm.py:235 - mean_merror=0.39942468792539193
2018-07-01 15:59:23,942 - DEBUG - lgbm.py:237 - best_params['lambda_l1']=0.1
2018-07-01 15:59:23,942 - DEBUG - lgbm.py:238 - best_params['lambda_l2']=0.1
2018-07-01 15:59:23,942 - DEBUG - lgbm.py:239 - best_params['min_split_gain']=0.1
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Info] Number of positive: 2060105, number of negative: 2058934
[LightGBM] [Info] This is the GPU trainer!!
[LightGBM] [Info] Total Bins 484
[LightGBM] [Info] Number of data: 4119039, number of used features: 99
[LightGBM] [Info] Using requested OpenCL platform 0 device 0
[LightGBM] [Info] Using GPU Device: GeForce GTX 1070 Ti, Vendor: NVIDIA Corporation
[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...
[LightGBM] [Info] GPU programs have been built
[LightGBM] [Info] Size of histogram bin entry: 12
[LightGBM] [Info] 98 dense feature groups (204.27 MB) transfered to GPU in 0.243486 secs. 0 sparse feature groups
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Info] Number of positive: 2060105, number of negative: 2058934
[LightGBM] [Info] This is the GPU trainer!!
[LightGBM] [Info] Total Bins 484
[LightGBM] [Info] Number of data: 4119039, number of used features: 99
[LightGBM] [Info] Using requested OpenCL platform 0 device 0
[LightGBM] [Info] Using GPU Device: GeForce GTX 1070 Ti, Vendor: NVIDIA Corporation
[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...
[LightGBM] [Info] GPU programs have been built
[LightGBM] [Info] Size of histogram bin entry: 12
[LightGBM] [Info] 98 dense feature groups (204.27 MB) transfered to GPU in 0.243244 secs. 0 sparse feature groups
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Info] Number of positive: 2060106, number of negative: 2058934
[LightGBM] [Info] This is the GPU trainer!!
[LightGBM] [Info] Total Bins 484
[LightGBM] [Info] Number of data: 4119040, number of used features: 99
[LightGBM] [Info] Using requested OpenCL platform 0 device 0
[LightGBM] [Info] Using GPU Device: GeForce GTX 1070 Ti, Vendor: NVIDIA Corporation
[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...
[LightGBM] [Info] GPU programs have been built
[LightGBM] [Info] Size of histogram bin entry: 12
[LightGBM] [Info] 98 dense feature groups (204.27 MB) transfered to GPU in 0.194803 secs. 0 sparse feature groups
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500142 -> initscore=0.000569
[LightGBM] [Info] Start training from score 0.000569
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500142 -> initscore=0.000569
[LightGBM] [Info] Start training from score 0.000569
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500142 -> initscore=0.000569
[LightGBM] [Info] Start training from score 0.000569
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2018-07-01 15:59:32,682 - DEBUG - lgbm.py:234 - boost_rounds=4
2018-07-01 15:59:32,682 - DEBUG - lgbm.py:235 - mean_merror=0.3994345607733518
2018-07-01 15:59:32,683 - DEBUG - lgbm.py:237 - best_params['lambda_l1']=0.1
2018-07-01 15:59:32,683 - DEBUG - lgbm.py:238 - best_params['lambda_l2']=0.1
2018-07-01 15:59:32,683 - DEBUG - lgbm.py:239 - best_params['min_split_gain']=0.2
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Info] Number of positive: 2060105, number of negative: 2058934
[LightGBM] [Info] This is the GPU trainer!!
[LightGBM] [Info] Total Bins 484
[LightGBM] [Info] Number of data: 4119039, number of used features: 99
[LightGBM] [Info] Using requested OpenCL platform 0 device 0
[LightGBM] [Info] Using GPU Device: GeForce GTX 1070 Ti, Vendor: NVIDIA Corporation
[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...
[LightGBM] [Info] GPU programs have been built
[LightGBM] [Info] Size of histogram bin entry: 12
[LightGBM] [Info] 98 dense feature groups (204.27 MB) transfered to GPU in 0.231289 secs. 0 sparse feature groups
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Info] Number of positive: 2060105, number of negative: 2058934
[LightGBM] [Info] This is the GPU trainer!!
[LightGBM] [Info] Total Bins 484
[LightGBM] [Info] Number of data: 4119039, number of used features: 99
[LightGBM] [Info] Using requested OpenCL platform 0 device 0
[LightGBM] [Info] Using GPU Device: GeForce GTX 1070 Ti, Vendor: NVIDIA Corporation
[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...
[LightGBM] [Info] GPU programs have been built
[LightGBM] [Info] Size of histogram bin entry: 12
[LightGBM] [Info] 98 dense feature groups (204.27 MB) transfered to GPU in 0.240586 secs. 0 sparse feature groups
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Info] Number of positive: 2060106, number of negative: 2058934
[LightGBM] [Info] This is the GPU trainer!!
[LightGBM] [Info] Total Bins 484
[LightGBM] [Info] Number of data: 4119040, number of used features: 99
[LightGBM] [Info] Using requested OpenCL platform 0 device 0
[LightGBM] [Info] Using GPU Device: GeForce GTX 1070 Ti, Vendor: NVIDIA Corporation
[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...
[LightGBM] [Info] GPU programs have been built
[LightGBM] [Info] Size of histogram bin entry: 12
[LightGBM] [Info] 98 dense feature groups (204.27 MB) transfered to GPU in 0.251317 secs. 0 sparse feature groups
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500142 -> initscore=0.000569
[LightGBM] [Info] Start training from score 0.000569
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500142 -> initscore=0.000569
[LightGBM] [Info] Start training from score 0.000569
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500142 -> initscore=0.000569
[LightGBM] [Info] Start training from score 0.000569
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2018-07-01 15:59:41,402 - DEBUG - lgbm.py:234 - boost_rounds=4
2018-07-01 15:59:41,402 - DEBUG - lgbm.py:235 - mean_merror=0.39943747407196656
2018-07-01 15:59:41,402 - DEBUG - lgbm.py:237 - best_params['lambda_l1']=0.1
2018-07-01 15:59:41,402 - DEBUG - lgbm.py:238 - best_params['lambda_l2']=0.1
2018-07-01 15:59:41,402 - DEBUG - lgbm.py:239 - best_params['min_split_gain']=0.3
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Info] Number of positive: 2060105, number of negative: 2058934
[LightGBM] [Info] This is the GPU trainer!!
[LightGBM] [Info] Total Bins 484
[LightGBM] [Info] Number of data: 4119039, number of used features: 99
[LightGBM] [Info] Using requested OpenCL platform 0 device 0
[LightGBM] [Info] Using GPU Device: GeForce GTX 1070 Ti, Vendor: NVIDIA Corporation
[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...
[LightGBM] [Info] GPU programs have been built
[LightGBM] [Info] Size of histogram bin entry: 12
[LightGBM] [Info] 98 dense feature groups (204.27 MB) transfered to GPU in 0.241832 secs. 0 sparse feature groups
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Info] Number of positive: 2060105, number of negative: 2058934
[LightGBM] [Info] This is the GPU trainer!!
[LightGBM] [Info] Total Bins 484
[LightGBM] [Info] Number of data: 4119039, number of used features: 99
[LightGBM] [Info] Using requested OpenCL platform 0 device 0
[LightGBM] [Info] Using GPU Device: GeForce GTX 1070 Ti, Vendor: NVIDIA Corporation
[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...
[LightGBM] [Info] GPU programs have been built
[LightGBM] [Info] Size of histogram bin entry: 12
[LightGBM] [Info] 98 dense feature groups (204.27 MB) transfered to GPU in 0.243630 secs. 0 sparse feature groups
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Info] Number of positive: 2060106, number of negative: 2058934
[LightGBM] [Info] This is the GPU trainer!!
[LightGBM] [Info] Total Bins 484
[LightGBM] [Info] Number of data: 4119040, number of used features: 99
[LightGBM] [Info] Using requested OpenCL platform 0 device 0
[LightGBM] [Info] Using GPU Device: GeForce GTX 1070 Ti, Vendor: NVIDIA Corporation
[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...
[LightGBM] [Info] GPU programs have been built
[LightGBM] [Info] Size of histogram bin entry: 12
[LightGBM] [Info] 98 dense feature groups (204.27 MB) transfered to GPU in 0.225632 secs. 0 sparse feature groups
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500142 -> initscore=0.000569
[LightGBM] [Info] Start training from score 0.000569
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500142 -> initscore=0.000569
[LightGBM] [Info] Start training from score 0.000569
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500142 -> initscore=0.000569
[LightGBM] [Info] Start training from score 0.000569
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2018-07-01 15:59:50,259 - DEBUG - lgbm.py:234 - boost_rounds=4
2018-07-01 15:59:50,260 - DEBUG - lgbm.py:235 - mean_merror=0.3994580290284688
2018-07-01 15:59:50,260 - DEBUG - lgbm.py:237 - best_params['lambda_l1']=0.1
2018-07-01 15:59:50,260 - DEBUG - lgbm.py:238 - best_params['lambda_l2']=0.1
2018-07-01 15:59:50,260 - DEBUG - lgbm.py:239 - best_params['min_split_gain']=0.4
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Info] Number of positive: 2060105, number of negative: 2058934
[LightGBM] [Info] This is the GPU trainer!!
[LightGBM] [Info] Total Bins 484
[LightGBM] [Info] Number of data: 4119039, number of used features: 99
[LightGBM] [Info] Using requested OpenCL platform 0 device 0
[LightGBM] [Info] Using GPU Device: GeForce GTX 1070 Ti, Vendor: NVIDIA Corporation
[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...
[LightGBM] [Info] GPU programs have been built
[LightGBM] [Info] Size of histogram bin entry: 12
[LightGBM] [Info] 98 dense feature groups (204.27 MB) transfered to GPU in 0.193175 secs. 0 sparse feature groups
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Info] Number of positive: 2060105, number of negative: 2058934
[LightGBM] [Info] This is the GPU trainer!!
[LightGBM] [Info] Total Bins 484
[LightGBM] [Info] Number of data: 4119039, number of used features: 99
[LightGBM] [Info] Using requested OpenCL platform 0 device 0
[LightGBM] [Info] Using GPU Device: GeForce GTX 1070 Ti, Vendor: NVIDIA Corporation
[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...
[LightGBM] [Info] GPU programs have been built
[LightGBM] [Info] Size of histogram bin entry: 12
[LightGBM] [Info] 98 dense feature groups (204.27 MB) transfered to GPU in 0.232089 secs. 0 sparse feature groups
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Info] Number of positive: 2060106, number of negative: 2058934
[LightGBM] [Info] This is the GPU trainer!!
[LightGBM] [Info] Total Bins 484
[LightGBM] [Info] Number of data: 4119040, number of used features: 99
[LightGBM] [Info] Using requested OpenCL platform 0 device 0
[LightGBM] [Info] Using GPU Device: GeForce GTX 1070 Ti, Vendor: NVIDIA Corporation
[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...
[LightGBM] [Info] GPU programs have been built
[LightGBM] [Info] Size of histogram bin entry: 12
[LightGBM] [Info] 98 dense feature groups (204.27 MB) transfered to GPU in 0.250172 secs. 0 sparse feature groups
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500142 -> initscore=0.000569
[LightGBM] [Info] Start training from score 0.000569
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500142 -> initscore=0.000569
[LightGBM] [Info] Start training from score 0.000569
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500142 -> initscore=0.000569
[LightGBM] [Info] Start training from score 0.000569
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2018-07-01 15:59:58,766 - DEBUG - lgbm.py:234 - boost_rounds=4
2018-07-01 15:59:58,766 - DEBUG - lgbm.py:235 - mean_merror=0.3994641793305913
2018-07-01 15:59:58,766 - DEBUG - lgbm.py:237 - best_params['lambda_l1']=0.1
2018-07-01 15:59:58,766 - DEBUG - lgbm.py:238 - best_params['lambda_l2']=0.1
2018-07-01 15:59:58,766 - DEBUG - lgbm.py:239 - best_params['min_split_gain']=0.5
2018-07-01 15:59:58,766 - DEBUG - lgbm.py:261 - {'boosting_type': 'gbdt', 'objective': 'binary', 'metric': ['binary_error'], 'device': 'gpu', 'gpu_platform_id': 0, 'gpu_device_id': 0, 'boosting': 'dart', 'learning_rate': 0.01, 'num_leaves': 165, 'max_depth': 7, 'max_bin': 7, 'min_data_in_leaf': 10, 'feature_fraction': 0.1, 'bagging_fraction': 0.1, 'bagging_freq': 0, 'lambda_l1': 0.1, 'lambda_l2': 0.1, 'min_split_gain': 0.1, 'sparse_threshold': 1.0, 'verbose': 1}
2018-07-01 15:59:58,767 - DEBUG - lgbm.py:276 - 开始训练
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Info] Number of positive: 3090158, number of negative: 3088401
[LightGBM] [Info] This is the GPU trainer!!
[LightGBM] [Info] Total Bins 484
[LightGBM] [Info] Number of data: 6178559, number of used features: 99
[LightGBM] [Info] Using requested OpenCL platform 0 device 0
[LightGBM] [Info] Using GPU Device: GeForce GTX 1070 Ti, Vendor: NVIDIA Corporation
[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...
[LightGBM] [Info] GPU programs have been built
[LightGBM] [Info] Size of histogram bin entry: 12
[LightGBM] [Info] 98 dense feature groups (306.40 MB) transfered to GPU in 0.316949 secs. 0 sparse feature groups
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500142 -> initscore=0.000569
[LightGBM] [Info] Start training from score 0.000569
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2018-07-01 16:00:14,566 - DEBUG - lgbm.py:284 - to save validation predictions ...
2018-07-01 16:00:14,574 - DEBUG - lgbm.py:286 - ['/data/1-lgbm.model.joblib_dat']
2018-07-01 16:00:14,574 - DEBUG - lgbm.py:290 - 验证
--- Logging error ---
Traceback (most recent call last):
  File "/home/zhijiehuang/anaconda3/lib/python3.6/logging/__init__.py", line 992, in emit
    msg = self.format(record)
  File "/home/zhijiehuang/anaconda3/lib/python3.6/logging/__init__.py", line 838, in format
    return fmt.format(record)
  File "/home/zhijiehuang/anaconda3/lib/python3.6/logging/__init__.py", line 575, in format
    record.message = record.getMessage()
  File "/home/zhijiehuang/anaconda3/lib/python3.6/logging/__init__.py", line 338, in getMessage
    msg = msg % self.args
TypeError: not all arguments converted during string formatting
Call stack:
  File "lgbm.py", line 321, in <module>
    done()
  File "lgbm.py", line 293, in done
    logging.debug('log_loss', str(log_loss(val_y, preds_offline)))
Message: 'log_loss'
Arguments: ('0.687724124734746',)
2018-07-01 16:00:18,419 - DEBUG - data_preprocessing.py:204 - data1.shape:(6865066, 5)
2018-07-01 16:00:18,420 - DEBUG - data_preprocessing.py:205 - data2.shape:(6865066, 5)
2018-07-01 16:00:18,517 - DEBUG - data_preprocessing.py:208 - 结果.shape:(6865066, 10)
2018-07-01 16:00:18,517 - DEBUG - data_preprocessing.py:209 - 耗时0.00016117095947265625
2018-07-01 16:00:37,422 - DEBUG - data_preprocessing.py:204 - data1.shape:(6865066, 10)
2018-07-01 16:00:37,422 - DEBUG - data_preprocessing.py:205 - data2.shape:(6865066, 60)
2018-07-01 16:00:39,974 - DEBUG - data_preprocessing.py:208 - 结果.shape:(6865066, 70)
2018-07-01 16:00:39,974 - DEBUG - data_preprocessing.py:209 - 耗时0.00015234947204589844
2018-07-01 16:00:44,509 - DEBUG - data_preprocessing.py:204 - data1.shape:(6865066, 70)
2018-07-01 16:00:44,509 - DEBUG - data_preprocessing.py:205 - data2.shape:(6865066, 11)
2018-07-01 16:00:51,348 - DEBUG - data_preprocessing.py:208 - 结果.shape:(6865066, 81)
2018-07-01 16:00:51,348 - DEBUG - data_preprocessing.py:209 - 耗时0.00015234947204589844
2018-07-01 16:01:09,828 - DEBUG - data_preprocessing.py:204 - data1.shape:(6865066, 81)
2018-07-01 16:01:09,828 - DEBUG - data_preprocessing.py:205 - data2.shape:(6865066, 20)
2018-07-01 16:01:17,554 - DEBUG - data_preprocessing.py:208 - 结果.shape:(6865066, 101)
2018-07-01 16:01:17,559 - DEBUG - data_preprocessing.py:209 - 耗时0.004698991775512695
2018-07-01 16:01:17,687 - DEBUG - data_preprocessing.py:382 - Index(['C14', 'C17', 'C21', 'device_model', 'site_domain', 'one_day',
       'one_day_hour', 'day_hour_prev', 'day_hour_next', 'is_work_day',
       ...
       'exptv_C17C21', 'cnttv_C17C21', 'exptv_C17site_domain',
       'cnttv_C17site_domain', 'exptv_C21device_model',
       'cnttv_C21device_model', 'exptv_C21site_domain', 'cnttv_C21site_domain',
       'exptv_site_domaindevice_model', 'cnttv_site_domaindevice_model'],
      dtype='object', length=101)
2018-07-01 16:01:19,224 - DEBUG - data_preprocessing.py:204 - data1.shape:(4577464, 5)
2018-07-01 16:01:19,224 - DEBUG - data_preprocessing.py:205 - data2.shape:(4577464, 5)
2018-07-01 16:01:19,291 - DEBUG - data_preprocessing.py:208 - 结果.shape:(4577464, 10)
2018-07-01 16:01:19,291 - DEBUG - data_preprocessing.py:209 - 耗时0.00015854835510253906
2018-07-01 16:01:32,053 - DEBUG - data_preprocessing.py:204 - data1.shape:(4577464, 10)
2018-07-01 16:01:32,053 - DEBUG - data_preprocessing.py:205 - data2.shape:(4577464, 60)
2018-07-01 16:01:33,609 - DEBUG - data_preprocessing.py:208 - 结果.shape:(4577464, 70)
2018-07-01 16:01:33,609 - DEBUG - data_preprocessing.py:209 - 耗时0.00014829635620117188
2018-07-01 16:01:36,430 - DEBUG - data_preprocessing.py:204 - data1.shape:(4577464, 70)
2018-07-01 16:01:36,430 - DEBUG - data_preprocessing.py:205 - data2.shape:(4577464, 11)
2018-07-01 16:01:40,828 - DEBUG - data_preprocessing.py:208 - 结果.shape:(4577464, 81)
2018-07-01 16:01:40,828 - DEBUG - data_preprocessing.py:209 - 耗时0.00015807151794433594
2018-07-01 16:01:52,890 - DEBUG - data_preprocessing.py:204 - data1.shape:(4577464, 81)
2018-07-01 16:01:52,890 - DEBUG - data_preprocessing.py:205 - data2.shape:(4577464, 20)
2018-07-01 16:01:58,140 - DEBUG - data_preprocessing.py:208 - 结果.shape:(4577464, 101)
2018-07-01 16:01:58,140 - DEBUG - data_preprocessing.py:209 - 耗时0.0001678466796875
2018-07-01 16:01:58,203 - DEBUG - data_preprocessing.py:391 - (6865066, 101)
2018-07-01 16:01:58,203 - DEBUG - data_preprocessing.py:392 - (4577464, 101)
2018-07-01 16:02:24,820 - DEBUG - data_preprocessing.py:411 -            C14   C17  C21  device_model  site_domain  one_day  one_day_hour  \
2445499  21611  2480   61          5524         6124        1             0   

         day_hour_prev  day_hour_next  is_work_day  \
2445499             -1              1            1   

                     ...                exptv_C17C21  cnttv_C17C21  \
2445499              ...                    0.239964        796075   

         exptv_C17site_domain  cnttv_C17site_domain  exptv_C21device_model  \
2445499              0.236913                501032               0.188062   

         cnttv_C21device_model  exptv_C21site_domain  cnttv_C21site_domain  \
2445499                 226216              0.163896               2897548   

         exptv_site_domaindevice_model  cnttv_site_domaindevice_model  
2445499                       0.114806                         384227  

[1 rows x 100 columns]
2018-07-01 16:02:24,830 - DEBUG - data_preprocessing.py:412 - 2445499    0
Name: click, dtype: int64
2018-07-01 16:02:24,830 - DEBUG - lgbm.py:270 - 设置参数
2018-07-01 16:02:24,838 - DEBUG - lgbm.py:299 - 预测
2018-07-01 16:03:44,125 - DEBUG - lgbm.py:302 - [0.49411722 0.50130159 0.50100139 ... 0.52224181 0.47336415 0.49855063]
2018-07-01 16:03:57,552 - DEBUG - lgbm.py:304 - ------------------------------
2018-07-01 16:03:57,795 - DEBUG - lgbm.py:306 - (4577464, 1)
2018-07-01 16:03:58,715 - DEBUG - lgbm.py:308 - (4577464,)
设置参数
(6865066, 101)
[1]	cv_agg's binary_error: 0.384476 + 0.000336156
[2]	cv_agg's binary_error: 0.369473 + 0.00150022
[3]	cv_agg's binary_error: 0.362853 + 0.000544881
[4]	cv_agg's binary_error: 0.363502 + 0.000880055
[5]	cv_agg's binary_error: 0.364511 + 0.000513306
[6]	cv_agg's binary_error: 0.365555 + 0.00088717
[1]	cv_agg's binary_error: 0.384476 + 0.000336156
[2]	cv_agg's binary_error: 0.369473 + 0.00150038
[3]	cv_agg's binary_error: 0.362854 + 0.000543382
[4]	cv_agg's binary_error: 0.363502 + 0.000879338
[5]	cv_agg's binary_error: 0.364512 + 0.000512944
[6]	cv_agg's binary_error: 0.365556 + 0.00088701
[1]	cv_agg's binary_error: 0.384475 + 0.000336359
[2]	cv_agg's binary_error: 0.369473 + 0.0015007
[3]	cv_agg's binary_error: 0.362855 + 0.000544262
[4]	cv_agg's binary_error: 0.363501 + 0.000878851
[5]	cv_agg's binary_error: 0.364512 + 0.000513822
[6]	cv_agg's binary_error: 0.365555 + 0.000887456
[1]	cv_agg's binary_error: 0.384476 + 0.000336019
[2]	cv_agg's binary_error: 0.369475 + 0.00150241
[3]	cv_agg's binary_error: 0.362855 + 0.000544419
[4]	cv_agg's binary_error: 0.363504 + 0.000882284
[5]	cv_agg's binary_error: 0.364512 + 0.000513219
[6]	cv_agg's binary_error: 0.365557 + 0.000889697
[1]	cv_agg's binary_error: 0.38448 + 0.00033178
[2]	cv_agg's binary_error: 0.369485 + 0.00150752
[3]	cv_agg's binary_error: 0.36286 + 0.000548057
[4]	cv_agg's binary_error: 0.363508 + 0.000885073
[5]	cv_agg's binary_error: 0.36454 + 0.000535438
[6]	cv_agg's binary_error: 0.365593 + 0.000927444
[1]	cv_agg's binary_error: 0.420584 + 0.000371052
[2]	cv_agg's binary_error: 0.409746 + 0.000137779
[3]	cv_agg's binary_error: 0.405325 + 0.000182313
[4]	cv_agg's binary_error: 0.400896 + 0.000293729
[5]	cv_agg's binary_error: 0.399424 + 0.00033271
[6]	cv_agg's binary_error: 0.404482 + 0.000186901
[7]	cv_agg's binary_error: 0.404463 + 0.000326803
[8]	cv_agg's binary_error: 0.401847 + 0.000236196
[1]	cv_agg's binary_error: 0.422043 + 0.00118335
[2]	cv_agg's binary_error: 0.410498 + 5.9346e-05
[3]	cv_agg's binary_error: 0.405767 + 0.00019488
[4]	cv_agg's binary_error: 0.401898 + 0.000178393
[5]	cv_agg's binary_error: 0.399706 + 0.000353225
[6]	cv_agg's binary_error: 0.404819 + 0.000236249
[7]	cv_agg's binary_error: 0.404707 + 0.000683493
[8]	cv_agg's binary_error: 0.402247 + 0.000452389
[1]	cv_agg's binary_error: 0.422043 + 0.00118335
[2]	cv_agg's binary_error: 0.410498 + 5.9346e-05
[3]	cv_agg's binary_error: 0.405767 + 0.00019488
[4]	cv_agg's binary_error: 0.401898 + 0.000178393
[5]	cv_agg's binary_error: 0.399706 + 0.000353225
[6]	cv_agg's binary_error: 0.40486 + 0.000311817
[7]	cv_agg's binary_error: 0.404668 + 0.000821714
[8]	cv_agg's binary_error: 0.402103 + 0.000612008
[1]	cv_agg's binary_error: 0.422043 + 0.00118335
[2]	cv_agg's binary_error: 0.410498 + 5.9346e-05
[3]	cv_agg's binary_error: 0.405767 + 0.00019488
[4]	cv_agg's binary_error: 0.401898 + 0.000178614
[5]	cv_agg's binary_error: 0.399706 + 0.000353225
[6]	cv_agg's binary_error: 0.40486 + 0.000311817
[7]	cv_agg's binary_error: 0.404668 + 0.000821714
[8]	cv_agg's binary_error: 0.402103 + 0.000612008
[1]	cv_agg's binary_error: 0.422043 + 0.00118335
[2]	cv_agg's binary_error: 0.410498 + 5.9346e-05
[3]	cv_agg's binary_error: 0.405767 + 0.00019488
[4]	cv_agg's binary_error: 0.401898 + 0.000178393
[5]	cv_agg's binary_error: 0.399706 + 0.000353225
[6]	cv_agg's binary_error: 0.40486 + 0.000311997
[7]	cv_agg's binary_error: 0.404668 + 0.000821714
[8]	cv_agg's binary_error: 0.402103 + 0.000612008
[1]	cv_agg's binary_error: 0.420572 + 0.000360353
[2]	cv_agg's binary_error: 0.40975 + 0.000135169
[3]	cv_agg's binary_error: 0.405324 + 0.000182077
[4]	cv_agg's binary_error: 0.400893 + 0.000298012
[5]	cv_agg's binary_error: 0.399425 + 0.000339657
[6]	cv_agg's binary_error: 0.404484 + 0.000187737
[7]	cv_agg's binary_error: 0.404462 + 0.000326304
[8]	cv_agg's binary_error: 0.401851 + 0.00024282
[1]	cv_agg's binary_error: 0.420532 + 0.000342822
[2]	cv_agg's binary_error: 0.409769 + 0.00016235
[3]	cv_agg's binary_error: 0.405361 + 0.00019747
[4]	cv_agg's binary_error: 0.400874 + 0.000275615
[5]	cv_agg's binary_error: 0.399435 + 0.000310327
[6]	cv_agg's binary_error: 0.404481 + 0.0001751
[7]	cv_agg's binary_error: 0.404459 + 0.000332311
[8]	cv_agg's binary_error: 0.401853 + 0.000259905
[1]	cv_agg's binary_error: 0.420542 + 0.000331028
[2]	cv_agg's binary_error: 0.409782 + 0.000148426
[3]	cv_agg's binary_error: 0.405405 + 0.000266839
[4]	cv_agg's binary_error: 0.400853 + 0.000302737
[5]	cv_agg's binary_error: 0.399437 + 0.000305419
[6]	cv_agg's binary_error: 0.404493 + 0.00016107
[7]	cv_agg's binary_error: 0.404466 + 0.000360313
[8]	cv_agg's binary_error: 0.401878 + 0.000236653
[1]	cv_agg's binary_error: 0.420542 + 0.000331028
[2]	cv_agg's binary_error: 0.409781 + 0.000148812
[3]	cv_agg's binary_error: 0.405353 + 0.000205268
[4]	cv_agg's binary_error: 0.400808 + 0.000289055
[5]	cv_agg's binary_error: 0.399458 + 0.000315788
[6]	cv_agg's binary_error: 0.404532 + 0.000141109
[7]	cv_agg's binary_error: 0.404474 + 0.00038484
[8]	cv_agg's binary_error: 0.401782 + 0.000233805
[1]	cv_agg's binary_error: 0.420537 + 0.00032773
[2]	cv_agg's binary_error: 0.409784 + 0.000146404
[3]	cv_agg's binary_error: 0.405342 + 0.000192766
[4]	cv_agg's binary_error: 0.400837 + 0.00029704
[5]	cv_agg's binary_error: 0.399464 + 0.000314528
[6]	cv_agg's binary_error: 0.404541 + 0.000141577
[7]	cv_agg's binary_error: 0.404482 + 0.000387822
[8]	cv_agg's binary_error: 0.401769 + 0.0002334
[1]	valid_0's binary_error: 0.420651
Training until validation scores don't improve for 30 rounds.
[2]	valid_0's binary_error: 0.408994
[3]	valid_0's binary_error: 0.404606
[4]	valid_0's binary_error: 0.400404
[5]	valid_0's binary_error: 0.398883
[6]	valid_0's binary_error: 0.40438
[7]	valid_0's binary_error: 0.403761
[8]	valid_0's binary_error: 0.401045
[9]	valid_0's binary_error: 0.399649
[10]	valid_0's binary_error: 0.397565
[11]	valid_0's binary_error: 0.396057
[12]	valid_0's binary_error: 0.397556
[13]	valid_0's binary_error: 0.399504
[14]	valid_0's binary_error: 0.393115
[15]	valid_0's binary_error: 0.392874
[16]	valid_0's binary_error: 0.392487
[17]	valid_0's binary_error: 0.39606
[18]	valid_0's binary_error: 0.395658
[19]	valid_0's binary_error: 0.389989
[20]	valid_0's binary_error: 0.388925
[21]	valid_0's binary_error: 0.389949
[22]	valid_0's binary_error: 0.388646
[23]	valid_0's binary_error: 0.389007
[24]	valid_0's binary_error: 0.38649
[25]	valid_0's binary_error: 0.384404
[26]	valid_0's binary_error: 0.384456
[27]	valid_0's binary_error: 0.385708
[28]	valid_0's binary_error: 0.385846
[29]	valid_0's binary_error: 0.385496
[30]	valid_0's binary_error: 0.38822
[31]	valid_0's binary_error: 0.388487
[32]	valid_0's binary_error: 0.391211
[33]	valid_0's binary_error: 0.392571
[34]	valid_0's binary_error: 0.3948
[35]	valid_0's binary_error: 0.393974
[36]	valid_0's binary_error: 0.394328
[37]	valid_0's binary_error: 0.394289
[38]	valid_0's binary_error: 0.394373
[39]	valid_0's binary_error: 0.393727
[40]	valid_0's binary_error: 0.393843
[41]	valid_0's binary_error: 0.393788
[42]	valid_0's binary_error: 0.394487
[43]	valid_0's binary_error: 0.394114
[44]	valid_0's binary_error: 0.393962
[45]	valid_0's binary_error: 0.392382
[46]	valid_0's binary_error: 0.391445
[47]	valid_0's binary_error: 0.391084
[48]	valid_0's binary_error: 0.391211
[49]	valid_0's binary_error: 0.391071
[50]	valid_0's binary_error: 0.391141
[51]	valid_0's binary_error: 0.390162
[52]	valid_0's binary_error: 0.392115
[53]	valid_0's binary_error: 0.391558
[54]	valid_0's binary_error: 0.390918
[55]	valid_0's binary_error: 0.389798
Early stopping, best iteration is:
[25]	valid_0's binary_error: 0.384404
(6865066, 101)
2018-07-01 16:10:21,049 - DEBUG - data_preprocessing.py:204 - data1.shape:(6865066, 5)
2018-07-01 16:10:21,049 - DEBUG - data_preprocessing.py:205 - data2.shape:(6865066, 5)
2018-07-01 16:10:21,356 - DEBUG - data_preprocessing.py:208 - 结果.shape:(6865066, 10)
2018-07-01 16:10:21,356 - DEBUG - data_preprocessing.py:209 - 耗时0.00016307830810546875
2018-07-01 16:10:45,756 - DEBUG - data_preprocessing.py:204 - data1.shape:(6865066, 10)
2018-07-01 16:10:45,756 - DEBUG - data_preprocessing.py:205 - data2.shape:(6865066, 60)
2018-07-01 16:10:47,889 - DEBUG - data_preprocessing.py:208 - 结果.shape:(6865066, 70)
2018-07-01 16:10:47,889 - DEBUG - data_preprocessing.py:209 - 耗时0.00015306472778320312
2018-07-01 16:10:52,304 - DEBUG - data_preprocessing.py:204 - data1.shape:(6865066, 70)
2018-07-01 16:10:52,304 - DEBUG - data_preprocessing.py:205 - data2.shape:(6865066, 11)
2018-07-01 16:10:58,913 - DEBUG - data_preprocessing.py:208 - 结果.shape:(6865066, 81)
2018-07-01 16:10:58,913 - DEBUG - data_preprocessing.py:209 - 耗时0.00016736984252929688
2018-07-01 16:11:17,275 - DEBUG - data_preprocessing.py:204 - data1.shape:(6865066, 81)
2018-07-01 16:11:17,275 - DEBUG - data_preprocessing.py:205 - data2.shape:(6865066, 20)
2018-07-01 16:11:24,980 - DEBUG - data_preprocessing.py:208 - 结果.shape:(6865066, 101)
2018-07-01 16:11:24,980 - DEBUG - data_preprocessing.py:209 - 耗时0.00015783309936523438
2018-07-01 16:11:25,088 - DEBUG - data_preprocessing.py:382 - Index(['C14', 'C17', 'C21', 'device_model', 'site_domain', 'one_day',
       'one_day_hour', 'day_hour_prev', 'day_hour_next', 'is_work_day',
       ...
       'exptv_C17C21', 'cnttv_C17C21', 'exptv_C17site_domain',
       'cnttv_C17site_domain', 'exptv_C21device_model',
       'cnttv_C21device_model', 'exptv_C21site_domain', 'cnttv_C21site_domain',
       'exptv_site_domaindevice_model', 'cnttv_site_domaindevice_model'],
      dtype='object', length=101)
2018-07-01 16:11:26,727 - DEBUG - data_preprocessing.py:204 - data1.shape:(4577464, 5)
2018-07-01 16:11:26,727 - DEBUG - data_preprocessing.py:205 - data2.shape:(4577464, 5)
2018-07-01 16:11:26,792 - DEBUG - data_preprocessing.py:208 - 结果.shape:(4577464, 10)
2018-07-01 16:11:26,792 - DEBUG - data_preprocessing.py:209 - 耗时0.00014901161193847656
2018-07-01 16:11:42,225 - DEBUG - data_preprocessing.py:204 - data1.shape:(4577464, 10)
2018-07-01 16:11:42,225 - DEBUG - data_preprocessing.py:205 - data2.shape:(4577464, 60)
2018-07-01 16:11:43,643 - DEBUG - data_preprocessing.py:208 - 结果.shape:(4577464, 70)
2018-07-01 16:11:43,643 - DEBUG - data_preprocessing.py:209 - 耗时0.00015354156494140625
2018-07-01 16:11:46,528 - DEBUG - data_preprocessing.py:204 - data1.shape:(4577464, 70)
2018-07-01 16:11:46,528 - DEBUG - data_preprocessing.py:205 - data2.shape:(4577464, 11)
2018-07-01 16:11:50,900 - DEBUG - data_preprocessing.py:208 - 结果.shape:(4577464, 81)
2018-07-01 16:11:50,900 - DEBUG - data_preprocessing.py:209 - 耗时0.0001556873321533203
2018-07-01 16:12:03,332 - DEBUG - data_preprocessing.py:204 - data1.shape:(4577464, 81)
2018-07-01 16:12:03,332 - DEBUG - data_preprocessing.py:205 - data2.shape:(4577464, 20)
2018-07-01 16:12:08,461 - DEBUG - data_preprocessing.py:208 - 结果.shape:(4577464, 101)
2018-07-01 16:12:08,461 - DEBUG - data_preprocessing.py:209 - 耗时0.00015735626220703125
2018-07-01 16:12:08,533 - DEBUG - data_preprocessing.py:391 - (6865066, 101)
2018-07-01 16:12:08,533 - DEBUG - data_preprocessing.py:392 - (4577464, 101)
/home/zhijiehuang/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.
  FutureWarning)
2018-07-01 16:12:34,385 - DEBUG - data_preprocessing.py:411 -            C14   C17  C21  device_model  site_domain  one_day  one_day_hour  \
2445499  21611  2480   61          5524         6124        1             0   

         day_hour_prev  day_hour_next  is_work_day  \
2445499             -1              1            1   

                     ...                exptv_C17C21  cnttv_C17C21  \
2445499              ...                    0.239964        796075   

         exptv_C17site_domain  cnttv_C17site_domain  exptv_C21device_model  \
2445499              0.236913                501032               0.188062   

         cnttv_C21device_model  exptv_C21site_domain  cnttv_C21site_domain  \
2445499                 226216              0.163896               2897548   

         exptv_site_domaindevice_model  cnttv_site_domaindevice_model  
2445499                       0.114806                         384227  

[1 rows x 100 columns]
2018-07-01 16:12:34,391 - DEBUG - data_preprocessing.py:412 - 2445499    0
Name: click, dtype: int64
2018-07-01 16:12:34,392 - DEBUG - lgbm.py:270 - 设置参数
2018-07-01 16:12:34,392 - DEBUG - lgbm.py:273 - CV:max_bin
2018-07-01 16:12:34,392 - DEBUG - lgbm.py:79 - 交叉验证
2018-07-01 16:12:34,392 - DEBUG - lgbm.py:124 - 调参2：降低过拟合
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Info] Number of positive: 2060105, number of negative: 2058934
[LightGBM] [Info] This is the GPU trainer!!
[LightGBM] [Info] Total Bins 484
[LightGBM] [Info] Number of data: 4119039, number of used features: 99
[LightGBM] [Info] Using requested OpenCL platform 0 device 0
[LightGBM] [Info] Using GPU Device: GeForce GTX 1070 Ti, Vendor: NVIDIA Corporation
[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...
[LightGBM] [Info] GPU programs have been built
[LightGBM] [Info] Size of histogram bin entry: 12
[LightGBM] [Info] 98 dense feature groups (204.27 MB) transfered to GPU in 0.280152 secs. 0 sparse feature groups
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Info] Number of positive: 2060105, number of negative: 2058934
[LightGBM] [Info] This is the GPU trainer!!
[LightGBM] [Info] Total Bins 484
[LightGBM] [Info] Number of data: 4119039, number of used features: 99
[LightGBM] [Info] Using requested OpenCL platform 0 device 0
[LightGBM] [Info] Using GPU Device: GeForce GTX 1070 Ti, Vendor: NVIDIA Corporation
[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...
[LightGBM] [Info] GPU programs have been built
[LightGBM] [Info] Size of histogram bin entry: 12
[LightGBM] [Info] 98 dense feature groups (204.27 MB) transfered to GPU in 0.288618 secs. 0 sparse feature groups
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Info] Number of positive: 2060106, number of negative: 2058934
[LightGBM] [Info] This is the GPU trainer!!
[LightGBM] [Info] Total Bins 484
[LightGBM] [Info] Number of data: 4119040, number of used features: 99
[LightGBM] [Info] Using requested OpenCL platform 0 device 0
[LightGBM] [Info] Using GPU Device: GeForce GTX 1070 Ti, Vendor: NVIDIA Corporation
[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...
[LightGBM] [Info] GPU programs have been built
[LightGBM] [Info] Size of histogram bin entry: 12
[LightGBM] [Info] 98 dense feature groups (204.27 MB) transfered to GPU in 0.273422 secs. 0 sparse feature groups
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500142 -> initscore=0.000569
[LightGBM] [Info] Start training from score 0.000569
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500142 -> initscore=0.000569
[LightGBM] [Info] Start training from score 0.000569
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500142 -> initscore=0.000569
[LightGBM] [Info] Start training from score 0.000569
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
lgbm.py:141: FutureWarning: 'argmin' is deprecated. Use 'idxmin' instead. The behavior of 'argmin' will be corrected to return the positional minimum in the future. Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_error-mean']).argmin()
2018-07-01 16:12:58,915 - DEBUG - lgbm.py:142 - boost_rounds=2
2018-07-01 16:12:58,915 - DEBUG - lgbm.py:143 - mean_merror=0.36285289179335756
2018-07-01 16:12:58,915 - DEBUG - lgbm.py:144 - best_params['max_bin']=7
2018-07-01 16:12:58,915 - DEBUG - lgbm.py:145 - best_params['min_data_in_leaf']=10
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Info] Number of positive: 2060105, number of negative: 2058934
[LightGBM] [Info] This is the GPU trainer!!
[LightGBM] [Info] Total Bins 484
[LightGBM] [Info] Number of data: 4119039, number of used features: 99
[LightGBM] [Info] Using requested OpenCL platform 0 device 0
[LightGBM] [Info] Using GPU Device: GeForce GTX 1070 Ti, Vendor: NVIDIA Corporation
[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...
[LightGBM] [Info] GPU programs have been built
[LightGBM] [Info] Size of histogram bin entry: 12
[LightGBM] [Info] 98 dense feature groups (204.27 MB) transfered to GPU in 0.240317 secs. 0 sparse feature groups
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Info] Number of positive: 2060105, number of negative: 2058934
[LightGBM] [Info] This is the GPU trainer!!
[LightGBM] [Info] Total Bins 484
[LightGBM] [Info] Number of data: 4119039, number of used features: 99
[LightGBM] [Info] Using requested OpenCL platform 0 device 0
[LightGBM] [Info] Using GPU Device: GeForce GTX 1070 Ti, Vendor: NVIDIA Corporation
[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...
[LightGBM] [Info] GPU programs have been built
[LightGBM] [Info] Size of histogram bin entry: 12
[LightGBM] [Info] 98 dense feature groups (204.27 MB) transfered to GPU in 0.231930 secs. 0 sparse feature groups
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Info] Number of positive: 2060106, number of negative: 2058934
[LightGBM] [Info] This is the GPU trainer!!
[LightGBM] [Info] Total Bins 484
[LightGBM] [Info] Number of data: 4119040, number of used features: 99
[LightGBM] [Info] Using requested OpenCL platform 0 device 0
[LightGBM] [Info] Using GPU Device: GeForce GTX 1070 Ti, Vendor: NVIDIA Corporation
[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...
[LightGBM] [Info] GPU programs have been built
[LightGBM] [Info] Size of histogram bin entry: 12
[LightGBM] [Info] 98 dense feature groups (204.27 MB) transfered to GPU in 0.274369 secs. 0 sparse feature groups
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500142 -> initscore=0.000569
[LightGBM] [Info] Start training from score 0.000569
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500142 -> initscore=0.000569
[LightGBM] [Info] Start training from score 0.000569
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500142 -> initscore=0.000569
[LightGBM] [Info] Start training from score 0.000569
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2018-07-01 16:13:06,631 - DEBUG - lgbm.py:142 - boost_rounds=2
2018-07-01 16:13:06,631 - DEBUG - lgbm.py:143 - mean_merror=0.36285370104340936
2018-07-01 16:13:06,631 - DEBUG - lgbm.py:144 - best_params['max_bin']=7
2018-07-01 16:13:06,631 - DEBUG - lgbm.py:145 - best_params['min_data_in_leaf']=15
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Info] Number of positive: 2060105, number of negative: 2058934
[LightGBM] [Info] This is the GPU trainer!!
[LightGBM] [Info] Total Bins 484
[LightGBM] [Info] Number of data: 4119039, number of used features: 99
[LightGBM] [Info] Using requested OpenCL platform 0 device 0
[LightGBM] [Info] Using GPU Device: GeForce GTX 1070 Ti, Vendor: NVIDIA Corporation
[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...
[LightGBM] [Info] GPU programs have been built
[LightGBM] [Info] Size of histogram bin entry: 12
[LightGBM] [Info] 98 dense feature groups (204.27 MB) transfered to GPU in 0.238586 secs. 0 sparse feature groups
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Info] Number of positive: 2060105, number of negative: 2058934
[LightGBM] [Info] This is the GPU trainer!!
[LightGBM] [Info] Total Bins 484
[LightGBM] [Info] Number of data: 4119039, number of used features: 99
[LightGBM] [Info] Using requested OpenCL platform 0 device 0
[LightGBM] [Info] Using GPU Device: GeForce GTX 1070 Ti, Vendor: NVIDIA Corporation
[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...
[LightGBM] [Info] GPU programs have been built
[LightGBM] [Info] Size of histogram bin entry: 12
[LightGBM] [Info] 98 dense feature groups (204.27 MB) transfered to GPU in 0.228905 secs. 0 sparse feature groups
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Info] Number of positive: 2060106, number of negative: 2058934
[LightGBM] [Info] This is the GPU trainer!!
[LightGBM] [Info] Total Bins 484
[LightGBM] [Info] Number of data: 4119040, number of used features: 99
[LightGBM] [Info] Using requested OpenCL platform 0 device 0
[LightGBM] [Info] Using GPU Device: GeForce GTX 1070 Ti, Vendor: NVIDIA Corporation
[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...
[LightGBM] [Info] GPU programs have been built
[LightGBM] [Info] Size of histogram bin entry: 12
[LightGBM] [Info] 98 dense feature groups (204.27 MB) transfered to GPU in 0.268590 secs. 0 sparse feature groups
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500142 -> initscore=0.000569
[LightGBM] [Info] Start training from score 0.000569
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500142 -> initscore=0.000569
[LightGBM] [Info] Start training from score 0.000569
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500142 -> initscore=0.000569
[LightGBM] [Info] Start training from score 0.000569
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2018-07-01 16:13:14,475 - DEBUG - lgbm.py:142 - boost_rounds=2
2018-07-01 16:13:14,476 - DEBUG - lgbm.py:143 - mean_merror=0.3628546721434715
2018-07-01 16:13:14,476 - DEBUG - lgbm.py:144 - best_params['max_bin']=7
2018-07-01 16:13:14,476 - DEBUG - lgbm.py:145 - best_params['min_data_in_leaf']=20
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Info] Number of positive: 2060105, number of negative: 2058934
[LightGBM] [Info] This is the GPU trainer!!
[LightGBM] [Info] Total Bins 484
[LightGBM] [Info] Number of data: 4119039, number of used features: 99
[LightGBM] [Info] Using requested OpenCL platform 0 device 0
[LightGBM] [Info] Using GPU Device: GeForce GTX 1070 Ti, Vendor: NVIDIA Corporation
[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...
[LightGBM] [Info] GPU programs have been built
[LightGBM] [Info] Size of histogram bin entry: 12
[LightGBM] [Info] 98 dense feature groups (204.27 MB) transfered to GPU in 0.245292 secs. 0 sparse feature groups
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Info] Number of positive: 2060105, number of negative: 2058934
[LightGBM] [Info] This is the GPU trainer!!
[LightGBM] [Info] Total Bins 484
[LightGBM] [Info] Number of data: 4119039, number of used features: 99
[LightGBM] [Info] Using requested OpenCL platform 0 device 0
[LightGBM] [Info] Using GPU Device: GeForce GTX 1070 Ti, Vendor: NVIDIA Corporation
[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...
[LightGBM] [Info] GPU programs have been built
[LightGBM] [Info] Size of histogram bin entry: 12
[LightGBM] [Info] 98 dense feature groups (204.27 MB) transfered to GPU in 0.249077 secs. 0 sparse feature groups
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Info] Number of positive: 2060106, number of negative: 2058934
[LightGBM] [Info] This is the GPU trainer!!
[LightGBM] [Info] Total Bins 484
[LightGBM] [Info] Number of data: 4119040, number of used features: 99
[LightGBM] [Info] Using requested OpenCL platform 0 device 0
[LightGBM] [Info] Using GPU Device: GeForce GTX 1070 Ti, Vendor: NVIDIA Corporation
[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...
[LightGBM] [Info] GPU programs have been built
[LightGBM] [Info] Size of histogram bin entry: 12
[LightGBM] [Info] 98 dense feature groups (204.27 MB) transfered to GPU in 0.273848 secs. 0 sparse feature groups
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500142 -> initscore=0.000569
[LightGBM] [Info] Start training from score 0.000569
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500142 -> initscore=0.000569
[LightGBM] [Info] Start training from score 0.000569
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500142 -> initscore=0.000569
[LightGBM] [Info] Start training from score 0.000569
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2018-07-01 16:13:22,403 - DEBUG - lgbm.py:142 - boost_rounds=2
2018-07-01 16:13:22,403 - DEBUG - lgbm.py:143 - mean_merror=0.36285531954367006
2018-07-01 16:13:22,403 - DEBUG - lgbm.py:144 - best_params['max_bin']=7
2018-07-01 16:13:22,403 - DEBUG - lgbm.py:145 - best_params['min_data_in_leaf']=25
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Info] Number of positive: 2060105, number of negative: 2058934
[LightGBM] [Info] This is the GPU trainer!!
[LightGBM] [Info] Total Bins 484
[LightGBM] [Info] Number of data: 4119039, number of used features: 99
[LightGBM] [Info] Using requested OpenCL platform 0 device 0
[LightGBM] [Info] Using GPU Device: GeForce GTX 1070 Ti, Vendor: NVIDIA Corporation
[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...
[LightGBM] [Info] GPU programs have been built
[LightGBM] [Info] Size of histogram bin entry: 12
[LightGBM] [Info] 98 dense feature groups (204.27 MB) transfered to GPU in 0.216403 secs. 0 sparse feature groups
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Info] Number of positive: 2060105, number of negative: 2058934
[LightGBM] [Info] This is the GPU trainer!!
[LightGBM] [Info] Total Bins 484
[LightGBM] [Info] Number of data: 4119039, number of used features: 99
[LightGBM] [Info] Using requested OpenCL platform 0 device 0
[LightGBM] [Info] Using GPU Device: GeForce GTX 1070 Ti, Vendor: NVIDIA Corporation
[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...
[LightGBM] [Info] GPU programs have been built
[LightGBM] [Info] Size of histogram bin entry: 12
[LightGBM] [Info] 98 dense feature groups (204.27 MB) transfered to GPU in 0.241064 secs. 0 sparse feature groups
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Info] Number of positive: 2060106, number of negative: 2058934
[LightGBM] [Info] This is the GPU trainer!!
[LightGBM] [Info] Total Bins 484
[LightGBM] [Info] Number of data: 4119040, number of used features: 99
[LightGBM] [Info] Using requested OpenCL platform 0 device 0
[LightGBM] [Info] Using GPU Device: GeForce GTX 1070 Ti, Vendor: NVIDIA Corporation
[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...
[LightGBM] [Info] GPU programs have been built
[LightGBM] [Info] Size of histogram bin entry: 12
[LightGBM] [Info] 98 dense feature groups (204.27 MB) transfered to GPU in 0.243066 secs. 0 sparse feature groups
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500142 -> initscore=0.000569
[LightGBM] [Info] Start training from score 0.000569
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500142 -> initscore=0.000569
[LightGBM] [Info] Start training from score 0.000569
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500142 -> initscore=0.000569
[LightGBM] [Info] Start training from score 0.000569
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2018-07-01 16:13:30,197 - DEBUG - lgbm.py:142 - boost_rounds=2
2018-07-01 16:13:30,197 - DEBUG - lgbm.py:143 - mean_merror=0.3628595276444895
2018-07-01 16:13:30,197 - DEBUG - lgbm.py:144 - best_params['max_bin']=7
2018-07-01 16:13:30,197 - DEBUG - lgbm.py:145 - best_params['min_data_in_leaf']=30
2018-07-01 16:13:30,197 - DEBUG - lgbm.py:261 - {'boosting_type': 'gbdt', 'objective': 'binary', 'metric': ['binary_error'], 'device': 'gpu', 'gpu_platform_id': 0, 'gpu_device_id': 0, 'boosting': 'dart', 'learning_rate': 0.01, 'num_leaves': 165, 'max_depth': 7, 'max_bin': 7, 'min_data_in_leaf': 10, 'feature_fraction': 0.6, 'bagging_fraction': 1, 'bagging_freq': 0, 'lambda_l1': 0, 'lambda_l2': 0, 'min_split_gain': 0.1, 'sparse_threshold': 1.0, 'verbose': 1}
2018-07-01 16:13:30,197 - DEBUG - lgbm.py:273 - CV:bagging_fraction
2018-07-01 16:13:30,197 - DEBUG - lgbm.py:79 - 交叉验证
2018-07-01 16:13:30,198 - DEBUG - lgbm.py:165 - 调参3：降低过拟合
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Info] Number of positive: 2060105, number of negative: 2058934
[LightGBM] [Info] This is the GPU trainer!!
[LightGBM] [Info] Total Bins 484
[LightGBM] [Info] Number of data: 4119039, number of used features: 99
[LightGBM] [Info] Using requested OpenCL platform 0 device 0
[LightGBM] [Info] Using GPU Device: GeForce GTX 1070 Ti, Vendor: NVIDIA Corporation
[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...
[LightGBM] [Info] GPU programs have been built
[LightGBM] [Info] Size of histogram bin entry: 12
[LightGBM] [Info] 98 dense feature groups (204.27 MB) transfered to GPU in 0.243554 secs. 0 sparse feature groups
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Info] Number of positive: 2060105, number of negative: 2058934
[LightGBM] [Info] This is the GPU trainer!!
[LightGBM] [Info] Total Bins 484
[LightGBM] [Info] Number of data: 4119039, number of used features: 99
[LightGBM] [Info] Using requested OpenCL platform 0 device 0
[LightGBM] [Info] Using GPU Device: GeForce GTX 1070 Ti, Vendor: NVIDIA Corporation
[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...
[LightGBM] [Info] GPU programs have been built
[LightGBM] [Info] Size of histogram bin entry: 12
[LightGBM] [Info] 98 dense feature groups (204.27 MB) transfered to GPU in 0.237102 secs. 0 sparse feature groups
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Info] Number of positive: 2060106, number of negative: 2058934
[LightGBM] [Info] This is the GPU trainer!!
[LightGBM] [Info] Total Bins 484
[LightGBM] [Info] Number of data: 4119040, number of used features: 99
[LightGBM] [Info] Using requested OpenCL platform 0 device 0
[LightGBM] [Info] Using GPU Device: GeForce GTX 1070 Ti, Vendor: NVIDIA Corporation
[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...
[LightGBM] [Info] GPU programs have been built
[LightGBM] [Info] Size of histogram bin entry: 12
[LightGBM] [Info] 98 dense feature groups (204.27 MB) transfered to GPU in 0.265668 secs. 0 sparse feature groups
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500142 -> initscore=0.000569
[LightGBM] [Info] Start training from score 0.000569
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500142 -> initscore=0.000569
[LightGBM] [Info] Start training from score 0.000569
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500142 -> initscore=0.000569
[LightGBM] [Info] Start training from score 0.000569
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
lgbm.py:184: FutureWarning: 'argmin' is deprecated. Use 'idxmin' instead. The behavior of 'argmin' will be corrected to return the positional minimum in the future. Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_error-mean']).argmin()
2018-07-01 16:13:39,034 - DEBUG - lgbm.py:185 - boost_rounds=4
2018-07-01 16:13:39,034 - DEBUG - lgbm.py:186 - mean_merror=0.39942387867384693
2018-07-01 16:13:39,034 - DEBUG - lgbm.py:188 - best_params['feature_fraction']=0.1
2018-07-01 16:13:39,034 - DEBUG - lgbm.py:189 - best_params['bagging_fraction']=0.1
2018-07-01 16:13:39,034 - DEBUG - lgbm.py:190 - best_params['bagging_freq']=0
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Info] Number of positive: 2060105, number of negative: 2058934
[LightGBM] [Info] This is the GPU trainer!!
[LightGBM] [Info] Total Bins 484
[LightGBM] [Info] Number of data: 4119039, number of used features: 99
[LightGBM] [Info] Using requested OpenCL platform 0 device 0
[LightGBM] [Info] Using GPU Device: GeForce GTX 1070 Ti, Vendor: NVIDIA Corporation
[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...
[LightGBM] [Info] GPU programs have been built
[LightGBM] [Info] Size of histogram bin entry: 12
[LightGBM] [Info] 98 dense feature groups (204.27 MB) transfered to GPU in 0.238687 secs. 0 sparse feature groups
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Info] Number of positive: 2060105, number of negative: 2058934
[LightGBM] [Info] This is the GPU trainer!!
[LightGBM] [Info] Total Bins 484
[LightGBM] [Info] Number of data: 4119039, number of used features: 99
[LightGBM] [Info] Using requested OpenCL platform 0 device 0
[LightGBM] [Info] Using GPU Device: GeForce GTX 1070 Ti, Vendor: NVIDIA Corporation
[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...
[LightGBM] [Info] GPU programs have been built
[LightGBM] [Info] Size of histogram bin entry: 12
[LightGBM] [Info] 98 dense feature groups (204.27 MB) transfered to GPU in 0.246003 secs. 0 sparse feature groups
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Info] Number of positive: 2060106, number of negative: 2058934
[LightGBM] [Info] This is the GPU trainer!!
[LightGBM] [Info] Total Bins 484
[LightGBM] [Info] Number of data: 4119040, number of used features: 99
[LightGBM] [Info] Using requested OpenCL platform 0 device 0
[LightGBM] [Info] Using GPU Device: GeForce GTX 1070 Ti, Vendor: NVIDIA Corporation
[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...
[LightGBM] [Info] GPU programs have been built
[LightGBM] [Info] Size of histogram bin entry: 12
[LightGBM] [Info] 98 dense feature groups (204.27 MB) transfered to GPU in 0.263784 secs. 0 sparse feature groups
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500142 -> initscore=0.000569
[LightGBM] [Info] Start training from score 0.000569
[LightGBM] [Info] Size of histogram bin entry: 12
[LightGBM] [Info] 98 dense feature groups (20.43 MB) transfered to GPU in 0.031451 secs. 0 sparse feature groups
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500142 -> initscore=0.000569
[LightGBM] [Info] Start training from score 0.000569
[LightGBM] [Info] Size of histogram bin entry: 12
[LightGBM] [Info] 98 dense feature groups (20.43 MB) transfered to GPU in 0.032566 secs. 0 sparse feature groups
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500142 -> initscore=0.000569
[LightGBM] [Info] Start training from score 0.000569
[LightGBM] [Info] Size of histogram bin entry: 12
[LightGBM] [Info] 98 dense feature groups (20.43 MB) transfered to GPU in 0.041237 secs. 0 sparse feature groups
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Info] Size of histogram bin entry: 12
[LightGBM] [Info] 98 dense feature groups (20.43 MB) transfered to GPU in 0.027979 secs. 0 sparse feature groups
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Info] Size of histogram bin entry: 12
[LightGBM] [Info] 98 dense feature groups (20.43 MB) transfered to GPU in 0.096891 secs. 0 sparse feature groups
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Info] Size of histogram bin entry: 12
[LightGBM] [Info] 98 dense feature groups (20.43 MB) transfered to GPU in 0.109858 secs. 0 sparse feature groups
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2018-07-01 16:13:48,539 - DEBUG - lgbm.py:185 - boost_rounds=4
2018-07-01 16:13:48,539 - DEBUG - lgbm.py:186 - mean_merror=0.3997064688543303
2018-07-01 16:13:48,539 - DEBUG - lgbm.py:188 - best_params['feature_fraction']=0.1
2018-07-01 16:13:48,539 - DEBUG - lgbm.py:189 - best_params['bagging_fraction']=0.1
2018-07-01 16:13:48,539 - DEBUG - lgbm.py:190 - best_params['bagging_freq']=5
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Info] Number of positive: 2060105, number of negative: 2058934
[LightGBM] [Info] This is the GPU trainer!!
[LightGBM] [Info] Total Bins 484
[LightGBM] [Info] Number of data: 4119039, number of used features: 99
[LightGBM] [Info] Using requested OpenCL platform 0 device 0
[LightGBM] [Info] Using GPU Device: GeForce GTX 1070 Ti, Vendor: NVIDIA Corporation
[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...
[LightGBM] [Info] GPU programs have been built
[LightGBM] [Info] Size of histogram bin entry: 12
[LightGBM] [Info] 98 dense feature groups (204.27 MB) transfered to GPU in 0.221944 secs. 0 sparse feature groups
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Info] Number of positive: 2060105, number of negative: 2058934
[LightGBM] [Info] This is the GPU trainer!!
[LightGBM] [Info] Total Bins 484
[LightGBM] [Info] Number of data: 4119039, number of used features: 99
[LightGBM] [Info] Using requested OpenCL platform 0 device 0
[LightGBM] [Info] Using GPU Device: GeForce GTX 1070 Ti, Vendor: NVIDIA Corporation
[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...
[LightGBM] [Info] GPU programs have been built
[LightGBM] [Info] Size of histogram bin entry: 12
[LightGBM] [Info] 98 dense feature groups (204.27 MB) transfered to GPU in 0.238166 secs. 0 sparse feature groups
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Info] Number of positive: 2060106, number of negative: 2058934
[LightGBM] [Info] This is the GPU trainer!!
[LightGBM] [Info] Total Bins 484
[LightGBM] [Info] Number of data: 4119040, number of used features: 99
[LightGBM] [Info] Using requested OpenCL platform 0 device 0
[LightGBM] [Info] Using GPU Device: GeForce GTX 1070 Ti, Vendor: NVIDIA Corporation
[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...
[LightGBM] [Info] GPU programs have been built
[LightGBM] [Info] Size of histogram bin entry: 12
[LightGBM] [Info] 98 dense feature groups (204.27 MB) transfered to GPU in 0.238353 secs. 0 sparse feature groups
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500142 -> initscore=0.000569
[LightGBM] [Info] Start training from score 0.000569
[LightGBM] [Info] Size of histogram bin entry: 12
[LightGBM] [Info] 98 dense feature groups (20.43 MB) transfered to GPU in 0.031364 secs. 0 sparse feature groups
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500142 -> initscore=0.000569
[LightGBM] [Info] Start training from score 0.000569
[LightGBM] [Info] Size of histogram bin entry: 12
[LightGBM] [Info] 98 dense feature groups (20.43 MB) transfered to GPU in 0.035649 secs. 0 sparse feature groups
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500142 -> initscore=0.000569
[LightGBM] [Info] Start training from score 0.000569
[LightGBM] [Info] Size of histogram bin entry: 12
[LightGBM] [Info] 98 dense feature groups (20.43 MB) transfered to GPU in 0.037117 secs. 0 sparse feature groups
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2018-07-01 16:13:56,911 - DEBUG - lgbm.py:185 - boost_rounds=4
2018-07-01 16:13:56,911 - DEBUG - lgbm.py:186 - mean_merror=0.3997064688543303
2018-07-01 16:13:56,911 - DEBUG - lgbm.py:188 - best_params['feature_fraction']=0.1
2018-07-01 16:13:56,911 - DEBUG - lgbm.py:189 - best_params['bagging_fraction']=0.1
2018-07-01 16:13:56,911 - DEBUG - lgbm.py:190 - best_params['bagging_freq']=10
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Info] Number of positive: 2060105, number of negative: 2058934
[LightGBM] [Info] This is the GPU trainer!!
[LightGBM] [Info] Total Bins 484
[LightGBM] [Info] Number of data: 4119039, number of used features: 99
[LightGBM] [Info] Using requested OpenCL platform 0 device 0
[LightGBM] [Info] Using GPU Device: GeForce GTX 1070 Ti, Vendor: NVIDIA Corporation
[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...
[LightGBM] [Info] GPU programs have been built
[LightGBM] [Info] Size of histogram bin entry: 12
[LightGBM] [Info] 98 dense feature groups (204.27 MB) transfered to GPU in 0.236807 secs. 0 sparse feature groups
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Info] Number of positive: 2060105, number of negative: 2058934
[LightGBM] [Info] This is the GPU trainer!!
[LightGBM] [Info] Total Bins 484
[LightGBM] [Info] Number of data: 4119039, number of used features: 99
[LightGBM] [Info] Using requested OpenCL platform 0 device 0
[LightGBM] [Info] Using GPU Device: GeForce GTX 1070 Ti, Vendor: NVIDIA Corporation
[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...
[LightGBM] [Info] GPU programs have been built
[LightGBM] [Info] Size of histogram bin entry: 12
[LightGBM] [Info] 98 dense feature groups (204.27 MB) transfered to GPU in 0.234982 secs. 0 sparse feature groups
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Info] Number of positive: 2060106, number of negative: 2058934
[LightGBM] [Info] This is the GPU trainer!!
[LightGBM] [Info] Total Bins 484
[LightGBM] [Info] Number of data: 4119040, number of used features: 99
[LightGBM] [Info] Using requested OpenCL platform 0 device 0
[LightGBM] [Info] Using GPU Device: GeForce GTX 1070 Ti, Vendor: NVIDIA Corporation
[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...
[LightGBM] [Info] GPU programs have been built
[LightGBM] [Info] Size of histogram bin entry: 12
[LightGBM] [Info] 98 dense feature groups (204.27 MB) transfered to GPU in 0.246339 secs. 0 sparse feature groups
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500142 -> initscore=0.000569
[LightGBM] [Info] Start training from score 0.000569
[LightGBM] [Info] Size of histogram bin entry: 12
[LightGBM] [Info] 98 dense feature groups (20.43 MB) transfered to GPU in 0.030631 secs. 0 sparse feature groups
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500142 -> initscore=0.000569
[LightGBM] [Info] Start training from score 0.000569
[LightGBM] [Info] Size of histogram bin entry: 12
[LightGBM] [Info] 98 dense feature groups (20.43 MB) transfered to GPU in 0.040139 secs. 0 sparse feature groups
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500142 -> initscore=0.000569
[LightGBM] [Info] Start training from score 0.000569
[LightGBM] [Info] Size of histogram bin entry: 12
[LightGBM] [Info] 98 dense feature groups (20.43 MB) transfered to GPU in 0.031611 secs. 0 sparse feature groups
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2018-07-01 16:14:05,354 - DEBUG - lgbm.py:185 - boost_rounds=4
2018-07-01 16:14:05,354 - DEBUG - lgbm.py:186 - mean_merror=0.3997064688543303
2018-07-01 16:14:05,355 - DEBUG - lgbm.py:188 - best_params['feature_fraction']=0.1
2018-07-01 16:14:05,355 - DEBUG - lgbm.py:189 - best_params['bagging_fraction']=0.1
2018-07-01 16:14:05,355 - DEBUG - lgbm.py:190 - best_params['bagging_freq']=15
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Info] Number of positive: 2060105, number of negative: 2058934
[LightGBM] [Info] This is the GPU trainer!!
[LightGBM] [Info] Total Bins 484
[LightGBM] [Info] Number of data: 4119039, number of used features: 99
[LightGBM] [Info] Using requested OpenCL platform 0 device 0
[LightGBM] [Info] Using GPU Device: GeForce GTX 1070 Ti, Vendor: NVIDIA Corporation
[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...
[LightGBM] [Info] GPU programs have been built
[LightGBM] [Info] Size of histogram bin entry: 12
[LightGBM] [Info] 98 dense feature groups (204.27 MB) transfered to GPU in 0.244061 secs. 0 sparse feature groups
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Info] Number of positive: 2060105, number of negative: 2058934
[LightGBM] [Info] This is the GPU trainer!!
[LightGBM] [Info] Total Bins 484
[LightGBM] [Info] Number of data: 4119039, number of used features: 99
[LightGBM] [Info] Using requested OpenCL platform 0 device 0
[LightGBM] [Info] Using GPU Device: GeForce GTX 1070 Ti, Vendor: NVIDIA Corporation
[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...
[LightGBM] [Info] GPU programs have been built
[LightGBM] [Info] Size of histogram bin entry: 12
[LightGBM] [Info] 98 dense feature groups (204.27 MB) transfered to GPU in 0.241781 secs. 0 sparse feature groups
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Info] Number of positive: 2060106, number of negative: 2058934
[LightGBM] [Info] This is the GPU trainer!!
[LightGBM] [Info] Total Bins 484
[LightGBM] [Info] Number of data: 4119040, number of used features: 99
[LightGBM] [Info] Using requested OpenCL platform 0 device 0
[LightGBM] [Info] Using GPU Device: GeForce GTX 1070 Ti, Vendor: NVIDIA Corporation
[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...
[LightGBM] [Info] GPU programs have been built
[LightGBM] [Info] Size of histogram bin entry: 12
[LightGBM] [Info] 98 dense feature groups (204.27 MB) transfered to GPU in 0.241634 secs. 0 sparse feature groups
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500142 -> initscore=0.000569
[LightGBM] [Info] Start training from score 0.000569
[LightGBM] [Info] Size of histogram bin entry: 12
[LightGBM] [Info] 98 dense feature groups (20.43 MB) transfered to GPU in 0.031967 secs. 0 sparse feature groups
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500142 -> initscore=0.000569
[LightGBM] [Info] Start training from score 0.000569
[LightGBM] [Info] Size of histogram bin entry: 12
[LightGBM] [Info] 98 dense feature groups (20.43 MB) transfered to GPU in 0.031500 secs. 0 sparse feature groups
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500142 -> initscore=0.000569
[LightGBM] [Info] Start training from score 0.000569
[LightGBM] [Info] Size of histogram bin entry: 12
[LightGBM] [Info] 98 dense feature groups (20.43 MB) transfered to GPU in 0.033537 secs. 0 sparse feature groups
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2018-07-01 16:14:13,922 - DEBUG - lgbm.py:185 - boost_rounds=4
2018-07-01 16:14:13,922 - DEBUG - lgbm.py:186 - mean_merror=0.3997064688543303
2018-07-01 16:14:13,923 - DEBUG - lgbm.py:188 - best_params['feature_fraction']=0.1
2018-07-01 16:14:13,923 - DEBUG - lgbm.py:189 - best_params['bagging_fraction']=0.1
2018-07-01 16:14:13,923 - DEBUG - lgbm.py:190 - best_params['bagging_freq']=20
2018-07-01 16:14:13,923 - DEBUG - lgbm.py:261 - {'boosting_type': 'gbdt', 'objective': 'binary', 'metric': ['binary_error'], 'device': 'gpu', 'gpu_platform_id': 0, 'gpu_device_id': 0, 'boosting': 'dart', 'learning_rate': 0.01, 'num_leaves': 165, 'max_depth': 7, 'max_bin': 7, 'min_data_in_leaf': 10, 'feature_fraction': 0.1, 'bagging_fraction': 0.1, 'bagging_freq': 0, 'lambda_l1': 0, 'lambda_l2': 0, 'min_split_gain': 0.1, 'sparse_threshold': 1.0, 'verbose': 1}
2018-07-01 16:14:13,923 - DEBUG - lgbm.py:273 - CV:lambda
2018-07-01 16:14:13,923 - DEBUG - lgbm.py:79 - 交叉验证
2018-07-01 16:14:13,923 - DEBUG - lgbm.py:214 - 调参4：降低过拟合
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Info] Number of positive: 2060105, number of negative: 2058934
[LightGBM] [Info] This is the GPU trainer!!
[LightGBM] [Info] Total Bins 484
[LightGBM] [Info] Number of data: 4119039, number of used features: 99
[LightGBM] [Info] Using requested OpenCL platform 0 device 0
[LightGBM] [Info] Using GPU Device: GeForce GTX 1070 Ti, Vendor: NVIDIA Corporation
[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...
[LightGBM] [Info] GPU programs have been built
[LightGBM] [Info] Size of histogram bin entry: 12
[LightGBM] [Info] 98 dense feature groups (204.27 MB) transfered to GPU in 0.232587 secs. 0 sparse feature groups
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Info] Number of positive: 2060105, number of negative: 2058934
[LightGBM] [Info] This is the GPU trainer!!
[LightGBM] [Info] Total Bins 484
[LightGBM] [Info] Number of data: 4119039, number of used features: 99
[LightGBM] [Info] Using requested OpenCL platform 0 device 0
[LightGBM] [Info] Using GPU Device: GeForce GTX 1070 Ti, Vendor: NVIDIA Corporation
[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...
[LightGBM] [Info] GPU programs have been built
[LightGBM] [Info] Size of histogram bin entry: 12
[LightGBM] [Info] 98 dense feature groups (204.27 MB) transfered to GPU in 0.240966 secs. 0 sparse feature groups
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Info] Number of positive: 2060106, number of negative: 2058934
[LightGBM] [Info] This is the GPU trainer!!
[LightGBM] [Info] Total Bins 484
[LightGBM] [Info] Number of data: 4119040, number of used features: 99
[LightGBM] [Info] Using requested OpenCL platform 0 device 0
[LightGBM] [Info] Using GPU Device: GeForce GTX 1070 Ti, Vendor: NVIDIA Corporation
[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...
[LightGBM] [Info] GPU programs have been built
[LightGBM] [Info] Size of histogram bin entry: 12
[LightGBM] [Info] 98 dense feature groups (204.27 MB) transfered to GPU in 0.238579 secs. 0 sparse feature groups
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500142 -> initscore=0.000569
[LightGBM] [Info] Start training from score 0.000569
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500142 -> initscore=0.000569
[LightGBM] [Info] Start training from score 0.000569
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500142 -> initscore=0.000569
[LightGBM] [Info] Start training from score 0.000569
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
lgbm.py:233: FutureWarning: 'argmin' is deprecated. Use 'idxmin' instead. The behavior of 'argmin' will be corrected to return the positional minimum in the future. Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_error-mean']).argmin()
2018-07-01 16:14:22,607 - DEBUG - lgbm.py:234 - boost_rounds=4
2018-07-01 16:14:22,607 - DEBUG - lgbm.py:235 - mean_merror=0.3994248497754809
2018-07-01 16:14:22,607 - DEBUG - lgbm.py:237 - best_params['lambda_l1']=0.1
2018-07-01 16:14:22,607 - DEBUG - lgbm.py:238 - best_params['lambda_l2']=0.1
2018-07-01 16:14:22,607 - DEBUG - lgbm.py:239 - best_params['min_split_gain']=0.1
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Info] Number of positive: 2060105, number of negative: 2058934
[LightGBM] [Info] This is the GPU trainer!!
[LightGBM] [Info] Total Bins 484
[LightGBM] [Info] Number of data: 4119039, number of used features: 99
[LightGBM] [Info] Using requested OpenCL platform 0 device 0
[LightGBM] [Info] Using GPU Device: GeForce GTX 1070 Ti, Vendor: NVIDIA Corporation
[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...
[LightGBM] [Info] GPU programs have been built
[LightGBM] [Info] Size of histogram bin entry: 12
[LightGBM] [Info] 98 dense feature groups (204.27 MB) transfered to GPU in 0.225864 secs. 0 sparse feature groups
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Info] Number of positive: 2060105, number of negative: 2058934
[LightGBM] [Info] This is the GPU trainer!!
[LightGBM] [Info] Total Bins 484
[LightGBM] [Info] Number of data: 4119039, number of used features: 99
[LightGBM] [Info] Using requested OpenCL platform 0 device 0
[LightGBM] [Info] Using GPU Device: GeForce GTX 1070 Ti, Vendor: NVIDIA Corporation
[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...
[LightGBM] [Info] GPU programs have been built
[LightGBM] [Info] Size of histogram bin entry: 12
[LightGBM] [Info] 98 dense feature groups (204.27 MB) transfered to GPU in 0.242862 secs. 0 sparse feature groups
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Info] Number of positive: 2060106, number of negative: 2058934
[LightGBM] [Info] This is the GPU trainer!!
[LightGBM] [Info] Total Bins 484
[LightGBM] [Info] Number of data: 4119040, number of used features: 99
[LightGBM] [Info] Using requested OpenCL platform 0 device 0
[LightGBM] [Info] Using GPU Device: GeForce GTX 1070 Ti, Vendor: NVIDIA Corporation
[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...
[LightGBM] [Info] GPU programs have been built
[LightGBM] [Info] Size of histogram bin entry: 12
[LightGBM] [Info] 98 dense feature groups (204.27 MB) transfered to GPU in 0.248147 secs. 0 sparse feature groups
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500142 -> initscore=0.000569
[LightGBM] [Info] Start training from score 0.000569
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500142 -> initscore=0.000569
[LightGBM] [Info] Start training from score 0.000569
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500142 -> initscore=0.000569
[LightGBM] [Info] Start training from score 0.000569
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2018-07-01 16:14:31,269 - DEBUG - lgbm.py:234 - boost_rounds=4
2018-07-01 16:14:31,270 - DEBUG - lgbm.py:235 - mean_merror=0.3994345607733518
2018-07-01 16:14:31,270 - DEBUG - lgbm.py:237 - best_params['lambda_l1']=0.1
2018-07-01 16:14:31,270 - DEBUG - lgbm.py:238 - best_params['lambda_l2']=0.1
2018-07-01 16:14:31,270 - DEBUG - lgbm.py:239 - best_params['min_split_gain']=0.2
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Info] Number of positive: 2060105, number of negative: 2058934
[LightGBM] [Info] This is the GPU trainer!!
[LightGBM] [Info] Total Bins 484
[LightGBM] [Info] Number of data: 4119039, number of used features: 99
[LightGBM] [Info] Using requested OpenCL platform 0 device 0
[LightGBM] [Info] Using GPU Device: GeForce GTX 1070 Ti, Vendor: NVIDIA Corporation
[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...
[LightGBM] [Info] GPU programs have been built
[LightGBM] [Info] Size of histogram bin entry: 12
[LightGBM] [Info] 98 dense feature groups (204.27 MB) transfered to GPU in 0.242079 secs. 0 sparse feature groups
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Info] Number of positive: 2060105, number of negative: 2058934
[LightGBM] [Info] This is the GPU trainer!!
[LightGBM] [Info] Total Bins 484
[LightGBM] [Info] Number of data: 4119039, number of used features: 99
[LightGBM] [Info] Using requested OpenCL platform 0 device 0
[LightGBM] [Info] Using GPU Device: GeForce GTX 1070 Ti, Vendor: NVIDIA Corporation
[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...
[LightGBM] [Info] GPU programs have been built
[LightGBM] [Info] Size of histogram bin entry: 12
[LightGBM] [Info] 98 dense feature groups (204.27 MB) transfered to GPU in 0.237146 secs. 0 sparse feature groups
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Info] Number of positive: 2060106, number of negative: 2058934
[LightGBM] [Info] This is the GPU trainer!!
[LightGBM] [Info] Total Bins 484
[LightGBM] [Info] Number of data: 4119040, number of used features: 99
[LightGBM] [Info] Using requested OpenCL platform 0 device 0
[LightGBM] [Info] Using GPU Device: GeForce GTX 1070 Ti, Vendor: NVIDIA Corporation
[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...
[LightGBM] [Info] GPU programs have been built
[LightGBM] [Info] Size of histogram bin entry: 12
[LightGBM] [Info] 98 dense feature groups (204.27 MB) transfered to GPU in 0.231301 secs. 0 sparse feature groups
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500142 -> initscore=0.000569
[LightGBM] [Info] Start training from score 0.000569
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500142 -> initscore=0.000569
[LightGBM] [Info] Start training from score 0.000569
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500142 -> initscore=0.000569
[LightGBM] [Info] Start training from score 0.000569
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2018-07-01 16:14:39,731 - DEBUG - lgbm.py:234 - boost_rounds=4
2018-07-01 16:14:39,731 - DEBUG - lgbm.py:235 - mean_merror=0.39943747407196656
2018-07-01 16:14:39,731 - DEBUG - lgbm.py:237 - best_params['lambda_l1']=0.1
2018-07-01 16:14:39,731 - DEBUG - lgbm.py:238 - best_params['lambda_l2']=0.1
2018-07-01 16:14:39,731 - DEBUG - lgbm.py:239 - best_params['min_split_gain']=0.3
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Info] Number of positive: 2060105, number of negative: 2058934
[LightGBM] [Info] This is the GPU trainer!!
[LightGBM] [Info] Total Bins 484
[LightGBM] [Info] Number of data: 4119039, number of used features: 99
[LightGBM] [Info] Using requested OpenCL platform 0 device 0
[LightGBM] [Info] Using GPU Device: GeForce GTX 1070 Ti, Vendor: NVIDIA Corporation
[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...
[LightGBM] [Info] GPU programs have been built
[LightGBM] [Info] Size of histogram bin entry: 12
[LightGBM] [Info] 98 dense feature groups (204.27 MB) transfered to GPU in 0.236897 secs. 0 sparse feature groups
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Info] Number of positive: 2060105, number of negative: 2058934
[LightGBM] [Info] This is the GPU trainer!!
[LightGBM] [Info] Total Bins 484
[LightGBM] [Info] Number of data: 4119039, number of used features: 99
[LightGBM] [Info] Using requested OpenCL platform 0 device 0
[LightGBM] [Info] Using GPU Device: GeForce GTX 1070 Ti, Vendor: NVIDIA Corporation
[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...
[LightGBM] [Info] GPU programs have been built
[LightGBM] [Info] Size of histogram bin entry: 12
[LightGBM] [Info] 98 dense feature groups (204.27 MB) transfered to GPU in 0.223789 secs. 0 sparse feature groups
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Info] Number of positive: 2060106, number of negative: 2058934
[LightGBM] [Info] This is the GPU trainer!!
[LightGBM] [Info] Total Bins 484
[LightGBM] [Info] Number of data: 4119040, number of used features: 99
[LightGBM] [Info] Using requested OpenCL platform 0 device 0
[LightGBM] [Info] Using GPU Device: GeForce GTX 1070 Ti, Vendor: NVIDIA Corporation
[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...
[LightGBM] [Info] GPU programs have been built
[LightGBM] [Info] Size of histogram bin entry: 12
[LightGBM] [Info] 98 dense feature groups (204.27 MB) transfered to GPU in 0.240863 secs. 0 sparse feature groups
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500142 -> initscore=0.000569
[LightGBM] [Info] Start training from score 0.000569
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500142 -> initscore=0.000569
[LightGBM] [Info] Start training from score 0.000569
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500142 -> initscore=0.000569
[LightGBM] [Info] Start training from score 0.000569
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2018-07-01 16:14:48,138 - DEBUG - lgbm.py:234 - boost_rounds=4
2018-07-01 16:14:48,138 - DEBUG - lgbm.py:235 - mean_merror=0.3994580290284688
2018-07-01 16:14:48,138 - DEBUG - lgbm.py:237 - best_params['lambda_l1']=0.1
2018-07-01 16:14:48,138 - DEBUG - lgbm.py:238 - best_params['lambda_l2']=0.1
2018-07-01 16:14:48,138 - DEBUG - lgbm.py:239 - best_params['min_split_gain']=0.4
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Info] Number of positive: 2060105, number of negative: 2058934
[LightGBM] [Info] This is the GPU trainer!!
[LightGBM] [Info] Total Bins 484
[LightGBM] [Info] Number of data: 4119039, number of used features: 99
[LightGBM] [Info] Using requested OpenCL platform 0 device 0
[LightGBM] [Info] Using GPU Device: GeForce GTX 1070 Ti, Vendor: NVIDIA Corporation
[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...
[LightGBM] [Info] GPU programs have been built
[LightGBM] [Info] Size of histogram bin entry: 12
[LightGBM] [Info] 98 dense feature groups (204.27 MB) transfered to GPU in 0.244256 secs. 0 sparse feature groups
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Info] Number of positive: 2060105, number of negative: 2058934
[LightGBM] [Info] This is the GPU trainer!!
[LightGBM] [Info] Total Bins 484
[LightGBM] [Info] Number of data: 4119039, number of used features: 99
[LightGBM] [Info] Using requested OpenCL platform 0 device 0
[LightGBM] [Info] Using GPU Device: GeForce GTX 1070 Ti, Vendor: NVIDIA Corporation
[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...
[LightGBM] [Info] GPU programs have been built
[LightGBM] [Info] Size of histogram bin entry: 12
[LightGBM] [Info] 98 dense feature groups (204.27 MB) transfered to GPU in 0.226959 secs. 0 sparse feature groups
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Info] Number of positive: 2060106, number of negative: 2058934
[LightGBM] [Info] This is the GPU trainer!!
[LightGBM] [Info] Total Bins 484
[LightGBM] [Info] Number of data: 4119040, number of used features: 99
[LightGBM] [Info] Using requested OpenCL platform 0 device 0
[LightGBM] [Info] Using GPU Device: GeForce GTX 1070 Ti, Vendor: NVIDIA Corporation
[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...
[LightGBM] [Info] GPU programs have been built
[LightGBM] [Info] Size of histogram bin entry: 12
[LightGBM] [Info] 98 dense feature groups (204.27 MB) transfered to GPU in 0.232177 secs. 0 sparse feature groups
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500142 -> initscore=0.000569
[LightGBM] [Info] Start training from score 0.000569
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500142 -> initscore=0.000569
[LightGBM] [Info] Start training from score 0.000569
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500142 -> initscore=0.000569
[LightGBM] [Info] Start training from score 0.000569
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2018-07-01 16:14:56,675 - DEBUG - lgbm.py:234 - boost_rounds=4
2018-07-01 16:14:56,676 - DEBUG - lgbm.py:235 - mean_merror=0.3994641793305913
2018-07-01 16:14:56,676 - DEBUG - lgbm.py:237 - best_params['lambda_l1']=0.1
2018-07-01 16:14:56,676 - DEBUG - lgbm.py:238 - best_params['lambda_l2']=0.1
2018-07-01 16:14:56,676 - DEBUG - lgbm.py:239 - best_params['min_split_gain']=0.5
2018-07-01 16:14:56,676 - DEBUG - lgbm.py:261 - {'boosting_type': 'gbdt', 'objective': 'binary', 'metric': ['binary_error'], 'device': 'gpu', 'gpu_platform_id': 0, 'gpu_device_id': 0, 'boosting': 'dart', 'learning_rate': 0.01, 'num_leaves': 165, 'max_depth': 7, 'max_bin': 7, 'min_data_in_leaf': 10, 'feature_fraction': 0.1, 'bagging_fraction': 0.1, 'bagging_freq': 0, 'lambda_l1': 0.1, 'lambda_l2': 0.1, 'min_split_gain': 0.1, 'sparse_threshold': 1.0, 'verbose': 1}
2018-07-01 16:14:56,676 - DEBUG - lgbm.py:276 - 开始训练
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Info] Number of positive: 3090158, number of negative: 3088401
[LightGBM] [Info] This is the GPU trainer!!
[LightGBM] [Info] Total Bins 484
[LightGBM] [Info] Number of data: 6178559, number of used features: 99
[LightGBM] [Info] Using requested OpenCL platform 0 device 0
[LightGBM] [Info] Using GPU Device: GeForce GTX 1070 Ti, Vendor: NVIDIA Corporation
[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...
[LightGBM] [Info] GPU programs have been built
[LightGBM] [Info] Size of histogram bin entry: 12
[LightGBM] [Info] 98 dense feature groups (306.40 MB) transfered to GPU in 0.314775 secs. 0 sparse feature groups
[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500142 -> initscore=0.000569
[LightGBM] [Info] Start training from score 0.000569
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2018-07-01 16:15:13,208 - DEBUG - lgbm.py:284 - to save validation predictions ...
2018-07-01 16:15:13,211 - DEBUG - lgbm.py:286 - ['/data/1-lgbm.model.joblib_dat']
2018-07-01 16:15:13,212 - DEBUG - lgbm.py:290 - 验证
2018-07-01 16:15:14,492 - DEBUG - lgbm.py:293 - log_loss:
2018-07-01 16:15:14,647 - DEBUG - lgbm.py:294 - 0.6877241324656044
2018-07-01 16:15:17,275 - DEBUG - data_preprocessing.py:204 - data1.shape:(6865066, 5)
2018-07-01 16:15:17,275 - DEBUG - data_preprocessing.py:205 - data2.shape:(6865066, 5)
2018-07-01 16:15:17,371 - DEBUG - data_preprocessing.py:208 - 结果.shape:(6865066, 10)
2018-07-01 16:15:17,371 - DEBUG - data_preprocessing.py:209 - 耗时0.00015687942504882812
2018-07-01 16:15:40,323 - DEBUG - data_preprocessing.py:204 - data1.shape:(6865066, 10)
2018-07-01 16:15:40,323 - DEBUG - data_preprocessing.py:205 - data2.shape:(6865066, 60)
2018-07-01 16:15:42,645 - DEBUG - data_preprocessing.py:208 - 结果.shape:(6865066, 70)
2018-07-01 16:15:42,645 - DEBUG - data_preprocessing.py:209 - 耗时0.00015115737915039062
2018-07-01 16:15:47,246 - DEBUG - data_preprocessing.py:204 - data1.shape:(6865066, 70)
2018-07-01 16:15:47,246 - DEBUG - data_preprocessing.py:205 - data2.shape:(6865066, 11)
2018-07-01 16:15:54,096 - DEBUG - data_preprocessing.py:208 - 结果.shape:(6865066, 81)
2018-07-01 16:15:54,096 - DEBUG - data_preprocessing.py:209 - 耗时0.00015735626220703125
2018-07-01 16:16:12,174 - DEBUG - data_preprocessing.py:204 - data1.shape:(6865066, 81)
2018-07-01 16:16:12,174 - DEBUG - data_preprocessing.py:205 - data2.shape:(6865066, 20)
2018-07-01 16:16:19,889 - DEBUG - data_preprocessing.py:208 - 结果.shape:(6865066, 101)
2018-07-01 16:16:19,889 - DEBUG - data_preprocessing.py:209 - 耗时0.0001728534698486328
2018-07-01 16:16:19,998 - DEBUG - data_preprocessing.py:382 - Index(['C14', 'C17', 'C21', 'device_model', 'site_domain', 'one_day',
       'one_day_hour', 'day_hour_prev', 'day_hour_next', 'is_work_day',
       ...
       'exptv_C17C21', 'cnttv_C17C21', 'exptv_C17site_domain',
       'cnttv_C17site_domain', 'exptv_C21device_model',
       'cnttv_C21device_model', 'exptv_C21site_domain', 'cnttv_C21site_domain',
       'exptv_site_domaindevice_model', 'cnttv_site_domaindevice_model'],
      dtype='object', length=101)
2018-07-01 16:16:21,658 - DEBUG - data_preprocessing.py:204 - data1.shape:(4577464, 5)
2018-07-01 16:16:21,658 - DEBUG - data_preprocessing.py:205 - data2.shape:(4577464, 5)
2018-07-01 16:16:21,723 - DEBUG - data_preprocessing.py:208 - 结果.shape:(4577464, 10)
2018-07-01 16:16:21,723 - DEBUG - data_preprocessing.py:209 - 耗时0.00014543533325195312
2018-07-01 16:16:36,937 - DEBUG - data_preprocessing.py:204 - data1.shape:(4577464, 10)
2018-07-01 16:16:36,937 - DEBUG - data_preprocessing.py:205 - data2.shape:(4577464, 60)
2018-07-01 16:16:38,488 - DEBUG - data_preprocessing.py:208 - 结果.shape:(4577464, 70)
2018-07-01 16:16:38,488 - DEBUG - data_preprocessing.py:209 - 耗时0.0001537799835205078
2018-07-01 16:16:41,348 - DEBUG - data_preprocessing.py:204 - data1.shape:(4577464, 70)
2018-07-01 16:16:41,348 - DEBUG - data_preprocessing.py:205 - data2.shape:(4577464, 11)
2018-07-01 16:16:45,770 - DEBUG - data_preprocessing.py:208 - 结果.shape:(4577464, 81)
2018-07-01 16:16:45,770 - DEBUG - data_preprocessing.py:209 - 耗时0.00016450881958007812
2018-07-01 16:16:57,906 - DEBUG - data_preprocessing.py:204 - data1.shape:(4577464, 81)
2018-07-01 16:16:57,906 - DEBUG - data_preprocessing.py:205 - data2.shape:(4577464, 20)
2018-07-01 16:17:03,077 - DEBUG - data_preprocessing.py:208 - 结果.shape:(4577464, 101)
2018-07-01 16:17:03,077 - DEBUG - data_preprocessing.py:209 - 耗时0.0001595020294189453
2018-07-01 16:17:03,139 - DEBUG - data_preprocessing.py:391 - (6865066, 101)
2018-07-01 16:17:03,139 - DEBUG - data_preprocessing.py:392 - (4577464, 101)
2018-07-01 16:17:29,491 - DEBUG - data_preprocessing.py:411 -            C14   C17  C21  device_model  site_domain  one_day  one_day_hour  \
2445499  21611  2480   61          5524         6124        1             0   

         day_hour_prev  day_hour_next  is_work_day  \
2445499             -1              1            1   

                     ...                exptv_C17C21  cnttv_C17C21  \
2445499              ...                    0.239964        796075   

         exptv_C17site_domain  cnttv_C17site_domain  exptv_C21device_model  \
2445499              0.236913                501032               0.188062   

         cnttv_C21device_model  exptv_C21site_domain  cnttv_C21site_domain  \
2445499                 226216              0.163896               2897548   

         exptv_site_domaindevice_model  cnttv_site_domaindevice_model  
2445499                       0.114806                         384227  

[1 rows x 100 columns]
2018-07-01 16:17:29,509 - DEBUG - data_preprocessing.py:412 - 2445499    0
Name: click, dtype: int64
2018-07-01 16:17:29,511 - DEBUG - lgbm.py:270 - 设置参数
2018-07-01 16:17:29,520 - DEBUG - lgbm.py:300 - 预测
2018-07-01 16:18:16,966 - DEBUG - lgbm.py:303 - [0.49411723 0.50130159 0.50100139 ... 0.5222418  0.47336415 0.49855063]
2018-07-01 16:18:30,128 - DEBUG - lgbm.py:305 - ------------------------------
2018-07-01 16:18:30,369 - DEBUG - lgbm.py:307 - (4577464, 1)
2018-07-01 16:18:31,031 - DEBUG - lgbm.py:309 - (4577464,)
设置参数
(6865066, 101)
[1]	cv_agg's binary_error: 0.384476 + 0.000336156
[2]	cv_agg's binary_error: 0.369473 + 0.00150022
[3]	cv_agg's binary_error: 0.362853 + 0.000544881
[4]	cv_agg's binary_error: 0.363502 + 0.000880055
[5]	cv_agg's binary_error: 0.364512 + 0.000513399
[6]	cv_agg's binary_error: 0.365555 + 0.00088717
[1]	cv_agg's binary_error: 0.384476 + 0.000336156
[2]	cv_agg's binary_error: 0.369473 + 0.00150038
[3]	cv_agg's binary_error: 0.362854 + 0.000543382
[4]	cv_agg's binary_error: 0.363502 + 0.000879338
[5]	cv_agg's binary_error: 0.364512 + 0.000512944
[6]	cv_agg's binary_error: 0.365556 + 0.00088701
[1]	cv_agg's binary_error: 0.384475 + 0.000336359
[2]	cv_agg's binary_error: 0.369473 + 0.0015007
[3]	cv_agg's binary_error: 0.362855 + 0.000544262
[4]	cv_agg's binary_error: 0.363501 + 0.000878851
[5]	cv_agg's binary_error: 0.364512 + 0.000513822
[6]	cv_agg's binary_error: 0.365555 + 0.000887456
[1]	cv_agg's binary_error: 0.384476 + 0.000336019
[2]	cv_agg's binary_error: 0.369475 + 0.00150241
[3]	cv_agg's binary_error: 0.362855 + 0.000544713
[4]	cv_agg's binary_error: 0.363504 + 0.000882284
[5]	cv_agg's binary_error: 0.364513 + 0.000513407
[6]	cv_agg's binary_error: 0.365558 + 0.000889033
[1]	cv_agg's binary_error: 0.38448 + 0.00033178
[2]	cv_agg's binary_error: 0.369485 + 0.00150752
[3]	cv_agg's binary_error: 0.36286 + 0.000548057
[4]	cv_agg's binary_error: 0.363508 + 0.000885073
[5]	cv_agg's binary_error: 0.36454 + 0.000535438
[6]	cv_agg's binary_error: 0.365593 + 0.000927444
[1]	cv_agg's binary_error: 0.420584 + 0.000371052
[2]	cv_agg's binary_error: 0.409746 + 0.000137779
[3]	cv_agg's binary_error: 0.405325 + 0.000182313
[4]	cv_agg's binary_error: 0.400897 + 0.000294518
[5]	cv_agg's binary_error: 0.399424 + 0.000332722
[6]	cv_agg's binary_error: 0.404482 + 0.000187119
[7]	cv_agg's binary_error: 0.404464 + 0.000327239
[8]	cv_agg's binary_error: 0.401847 + 0.000236196
[1]	cv_agg's binary_error: 0.422043 + 0.00118335
[2]	cv_agg's binary_error: 0.410498 + 5.9346e-05
[3]	cv_agg's binary_error: 0.405767 + 0.00019488
[4]	cv_agg's binary_error: 0.401898 + 0.000178393
[5]	cv_agg's binary_error: 0.399706 + 0.000353225
[6]	cv_agg's binary_error: 0.404819 + 0.000236249
[7]	cv_agg's binary_error: 0.404707 + 0.000683493
[8]	cv_agg's binary_error: 0.402247 + 0.000452389
[1]	cv_agg's binary_error: 0.422043 + 0.00118335
[2]	cv_agg's binary_error: 0.410498 + 5.9346e-05
[3]	cv_agg's binary_error: 0.405767 + 0.00019488
[4]	cv_agg's binary_error: 0.401898 + 0.000178393
[5]	cv_agg's binary_error: 0.399706 + 0.000353225
[6]	cv_agg's binary_error: 0.40486 + 0.000311817
[7]	cv_agg's binary_error: 0.404668 + 0.000821714
[8]	cv_agg's binary_error: 0.402103 + 0.000612008
[1]	cv_agg's binary_error: 0.422043 + 0.00118335
[2]	cv_agg's binary_error: 0.410498 + 5.9346e-05
[3]	cv_agg's binary_error: 0.405767 + 0.00019488
[4]	cv_agg's binary_error: 0.401898 + 0.000178393
[5]	cv_agg's binary_error: 0.399706 + 0.000353225
[6]	cv_agg's binary_error: 0.40486 + 0.000311817
[7]	cv_agg's binary_error: 0.404668 + 0.000821714
[8]	cv_agg's binary_error: 0.402103 + 0.000612008
[1]	cv_agg's binary_error: 0.422043 + 0.00118335
[2]	cv_agg's binary_error: 0.410498 + 5.9346e-05
[3]	cv_agg's binary_error: 0.405767 + 0.00019488
[4]	cv_agg's binary_error: 0.401898 + 0.000178614
[5]	cv_agg's binary_error: 0.399706 + 0.000353225
[6]	cv_agg's binary_error: 0.40486 + 0.000311817
[7]	cv_agg's binary_error: 0.404668 + 0.000821714
[8]	cv_agg's binary_error: 0.402103 + 0.000612008
[1]	cv_agg's binary_error: 0.420572 + 0.000360353
[2]	cv_agg's binary_error: 0.40975 + 0.000135169
[3]	cv_agg's binary_error: 0.405324 + 0.000182077
[4]	cv_agg's binary_error: 0.400893 + 0.000298012
[5]	cv_agg's binary_error: 0.399425 + 0.000339849
[6]	cv_agg's binary_error: 0.404484 + 0.000187851
[7]	cv_agg's binary_error: 0.404462 + 0.000326304
[8]	cv_agg's binary_error: 0.401851 + 0.00024282
[1]	cv_agg's binary_error: 0.420532 + 0.000342822
[2]	cv_agg's binary_error: 0.409769 + 0.00016235
[3]	cv_agg's binary_error: 0.405361 + 0.00019747
[4]	cv_agg's binary_error: 0.400874 + 0.000275615
[5]	cv_agg's binary_error: 0.399435 + 0.000310327
[6]	cv_agg's binary_error: 0.40448 + 0.000176141
[7]	cv_agg's binary_error: 0.404459 + 0.000332311
[8]	cv_agg's binary_error: 0.401853 + 0.000259905
[1]	cv_agg's binary_error: 0.420542 + 0.000331028
[2]	cv_agg's binary_error: 0.409782 + 0.000148426
[3]	cv_agg's binary_error: 0.405405 + 0.000266839
[4]	cv_agg's binary_error: 0.400853 + 0.000302737
[5]	cv_agg's binary_error: 0.399437 + 0.000305419
[6]	cv_agg's binary_error: 0.404493 + 0.000161201
[7]	cv_agg's binary_error: 0.404466 + 0.000360313
[8]	cv_agg's binary_error: 0.401878 + 0.000236653
[1]	cv_agg's binary_error: 0.420542 + 0.000331028
[2]	cv_agg's binary_error: 0.409781 + 0.000148812
[3]	cv_agg's binary_error: 0.405353 + 0.000205268
[4]	cv_agg's binary_error: 0.400808 + 0.000289055
[5]	cv_agg's binary_error: 0.399458 + 0.000315788
[6]	cv_agg's binary_error: 0.404532 + 0.000140884
[7]	cv_agg's binary_error: 0.404474 + 0.000384709
[8]	cv_agg's binary_error: 0.401782 + 0.000233864
[1]	cv_agg's binary_error: 0.420537 + 0.00032773
[2]	cv_agg's binary_error: 0.409784 + 0.000146404
[3]	cv_agg's binary_error: 0.405342 + 0.000192766
[4]	cv_agg's binary_error: 0.400837 + 0.00029704
[5]	cv_agg's binary_error: 0.399464 + 0.000314528
[6]	cv_agg's binary_error: 0.404541 + 0.000141577
[7]	cv_agg's binary_error: 0.404482 + 0.000387822
[8]	cv_agg's binary_error: 0.401769 + 0.0002334
[1]	valid_0's binary_error: 0.420651
Training until validation scores don't improve for 30 rounds.
[2]	valid_0's binary_error: 0.408994
[3]	valid_0's binary_error: 0.404606
[4]	valid_0's binary_error: 0.400404
[5]	valid_0's binary_error: 0.398883
[6]	valid_0's binary_error: 0.40438
[7]	valid_0's binary_error: 0.403761
[8]	valid_0's binary_error: 0.401046
[9]	valid_0's binary_error: 0.399649
[10]	valid_0's binary_error: 0.397565
[11]	valid_0's binary_error: 0.396057
[12]	valid_0's binary_error: 0.397556
[13]	valid_0's binary_error: 0.399504
[14]	valid_0's binary_error: 0.393115
[15]	valid_0's binary_error: 0.392874
[16]	valid_0's binary_error: 0.392487
[17]	valid_0's binary_error: 0.39606
[18]	valid_0's binary_error: 0.395655
[19]	valid_0's binary_error: 0.389989
[20]	valid_0's binary_error: 0.388925
[21]	valid_0's binary_error: 0.389949
[22]	valid_0's binary_error: 0.388646
[23]	valid_0's binary_error: 0.389007
[24]	valid_0's binary_error: 0.38649
[25]	valid_0's binary_error: 0.384404
[26]	valid_0's binary_error: 0.384459
[27]	valid_0's binary_error: 0.385705
[28]	valid_0's binary_error: 0.385843
[29]	valid_0's binary_error: 0.385496
[30]	valid_0's binary_error: 0.388219
[31]	valid_0's binary_error: 0.388488
[32]	valid_0's binary_error: 0.391212
[33]	valid_0's binary_error: 0.392573
[34]	valid_0's binary_error: 0.394799
[35]	valid_0's binary_error: 0.393971
[36]	valid_0's binary_error: 0.394327
[37]	valid_0's binary_error: 0.394289
[38]	valid_0's binary_error: 0.394375
[39]	valid_0's binary_error: 0.393727
[40]	valid_0's binary_error: 0.393842
[41]	valid_0's binary_error: 0.393785
[42]	valid_0's binary_error: 0.394487
[43]	valid_0's binary_error: 0.394111
[44]	valid_0's binary_error: 0.393961
[45]	valid_0's binary_error: 0.392383
[46]	valid_0's binary_error: 0.391445
[47]	valid_0's binary_error: 0.391083
[48]	valid_0's binary_error: 0.391211
[49]	valid_0's binary_error: 0.391071
[50]	valid_0's binary_error: 0.391142
[51]	valid_0's binary_error: 0.390161
[52]	valid_0's binary_error: 0.392115
[53]	valid_0's binary_error: 0.391558
[54]	valid_0's binary_error: 0.390915
[55]	valid_0's binary_error: 0.389798
Early stopping, best iteration is:
[25]	valid_0's binary_error: 0.384404
(6865066, 101)
2018-07-01 16:19:56,902 - DEBUG - data_preprocessing.py:204 - data1.shape:(6865066, 5)
2018-07-01 16:19:56,902 - DEBUG - data_preprocessing.py:205 - data2.shape:(6865066, 5)
2018-07-01 16:19:57,210 - DEBUG - data_preprocessing.py:208 - 结果.shape:(6865066, 10)
2018-07-01 16:19:57,210 - DEBUG - data_preprocessing.py:209 - 耗时0.0001621246337890625
2018-07-01 16:20:18,076 - DEBUG - data_preprocessing.py:204 - data1.shape:(6865066, 10)
2018-07-01 16:20:18,076 - DEBUG - data_preprocessing.py:205 - data2.shape:(6865066, 60)
2018-07-01 16:20:20,202 - DEBUG - data_preprocessing.py:208 - 结果.shape:(6865066, 70)
2018-07-01 16:20:20,202 - DEBUG - data_preprocessing.py:209 - 耗时0.000152587890625
2018-07-01 16:20:24,548 - DEBUG - data_preprocessing.py:204 - data1.shape:(6865066, 70)
2018-07-01 16:20:24,548 - DEBUG - data_preprocessing.py:205 - data2.shape:(6865066, 11)
2018-07-01 16:20:31,164 - DEBUG - data_preprocessing.py:208 - 结果.shape:(6865066, 81)
2018-07-01 16:20:31,164 - DEBUG - data_preprocessing.py:209 - 耗时0.0001583099365234375
2018-07-01 16:20:49,634 - DEBUG - data_preprocessing.py:204 - data1.shape:(6865066, 81)
2018-07-01 16:20:49,634 - DEBUG - data_preprocessing.py:205 - data2.shape:(6865066, 20)
2018-07-01 16:20:57,317 - DEBUG - data_preprocessing.py:208 - 结果.shape:(6865066, 101)
2018-07-01 16:20:57,318 - DEBUG - data_preprocessing.py:209 - 耗时0.0001571178436279297
2018-07-01 16:20:57,428 - DEBUG - data_preprocessing.py:382 - Index(['C14', 'C17', 'C21', 'device_model', 'site_domain', 'one_day',
       'one_day_hour', 'day_hour_prev', 'day_hour_next', 'is_work_day',
       ...
       'exptv_C17C21', 'cnttv_C17C21', 'exptv_C17site_domain',
       'cnttv_C17site_domain', 'exptv_C21device_model',
       'cnttv_C21device_model', 'exptv_C21site_domain', 'cnttv_C21site_domain',
       'exptv_site_domaindevice_model', 'cnttv_site_domaindevice_model'],
      dtype='object', length=101)
2018-07-01 16:20:58,955 - DEBUG - data_preprocessing.py:204 - data1.shape:(4577464, 5)
2018-07-01 16:20:58,955 - DEBUG - data_preprocessing.py:205 - data2.shape:(4577464, 5)
2018-07-01 16:20:59,020 - DEBUG - data_preprocessing.py:208 - 结果.shape:(4577464, 10)
2018-07-01 16:20:59,020 - DEBUG - data_preprocessing.py:209 - 耗时0.0001552104949951172
2018-07-01 16:21:12,151 - DEBUG - data_preprocessing.py:204 - data1.shape:(4577464, 10)
2018-07-01 16:21:12,151 - DEBUG - data_preprocessing.py:205 - data2.shape:(4577464, 60)
2018-07-01 16:21:13,592 - DEBUG - data_preprocessing.py:208 - 结果.shape:(4577464, 70)
2018-07-01 16:21:13,592 - DEBUG - data_preprocessing.py:209 - 耗时0.00015497207641601562
2018-07-01 16:21:16,469 - DEBUG - data_preprocessing.py:204 - data1.shape:(4577464, 70)
2018-07-01 16:21:16,469 - DEBUG - data_preprocessing.py:205 - data2.shape:(4577464, 11)
2018-07-01 16:21:20,871 - DEBUG - data_preprocessing.py:208 - 结果.shape:(4577464, 81)
2018-07-01 16:21:20,871 - DEBUG - data_preprocessing.py:209 - 耗时0.0001533031463623047
2018-07-01 16:21:33,309 - DEBUG - data_preprocessing.py:204 - data1.shape:(4577464, 81)
2018-07-01 16:21:33,309 - DEBUG - data_preprocessing.py:205 - data2.shape:(4577464, 20)
2018-07-01 16:21:38,447 - DEBUG - data_preprocessing.py:208 - 结果.shape:(4577464, 101)
2018-07-01 16:21:38,447 - DEBUG - data_preprocessing.py:209 - 耗时0.0001556873321533203
2018-07-01 16:21:38,519 - DEBUG - data_preprocessing.py:391 - (6865066, 101)
2018-07-01 16:21:38,519 - DEBUG - data_preprocessing.py:392 - (4577464, 101)
/home/zhijiehuang/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.
  FutureWarning)
2018-07-01 16:22:04,438 - DEBUG - data_preprocessing.py:411 -            C14   C17  C21  device_model  site_domain  one_day  one_day_hour  \
2445499  21611  2480   61          5524         6124        1             0   

         day_hour_prev  day_hour_next  is_work_day  \
2445499             -1              1            1   

                     ...                exptv_C17C21  cnttv_C17C21  \
2445499              ...                    0.239964        796075   

         exptv_C17site_domain  cnttv_C17site_domain  exptv_C21device_model  \
2445499              0.236913                501032               0.188062   

         cnttv_C21device_model  exptv_C21site_domain  cnttv_C21site_domain  \
2445499                 226216              0.163896               2897548   

         exptv_site_domaindevice_model  cnttv_site_domaindevice_model  
2445499                       0.114806                         384227  

[1 rows x 100 columns]
2018-07-01 16:22:04,444 - DEBUG - data_preprocessing.py:412 - 2445499    0
Name: click, dtype: int64
2018-07-01 16:22:04,444 - DEBUG - lgbm.py:270 - 设置参数
2018-07-01 16:22:04,459 - DEBUG - lgbm.py:300 - 预测
2018-07-01 16:22:16,139 - DEBUG - lgbm.py:303 - [0.49411723 0.50130159 0.50100139 ... 0.5222418  0.47336415 0.49855063]
2018-07-01 16:22:19,932 - DEBUG - lgbm.py:305 - ------------------------------
2018-07-01 16:22:20,168 - DEBUG - lgbm.py:307 - (4577464, 1)
2018-07-01 16:22:20,772 - DEBUG - lgbm.py:309 - (4577464,)
设置参数
(6865066, 101)
2018-07-01 16:29:20,089 - DEBUG - data_preprocessing.py:204 - data1.shape:(6865066, 5)
2018-07-01 16:29:20,089 - DEBUG - data_preprocessing.py:205 - data2.shape:(6865066, 5)
2018-07-01 16:29:20,389 - DEBUG - data_preprocessing.py:208 - 结果.shape:(6865066, 10)
2018-07-01 16:29:20,389 - DEBUG - data_preprocessing.py:209 - 耗时0.00015425682067871094
2018-07-01 16:29:42,433 - DEBUG - data_preprocessing.py:204 - data1.shape:(6865066, 10)
2018-07-01 16:29:42,433 - DEBUG - data_preprocessing.py:205 - data2.shape:(6865066, 60)
2018-07-01 16:29:44,559 - DEBUG - data_preprocessing.py:208 - 结果.shape:(6865066, 70)
2018-07-01 16:29:44,560 - DEBUG - data_preprocessing.py:209 - 耗时0.00014901161193847656
2018-07-01 16:29:48,937 - DEBUG - data_preprocessing.py:204 - data1.shape:(6865066, 70)
2018-07-01 16:29:48,938 - DEBUG - data_preprocessing.py:205 - data2.shape:(6865066, 11)
2018-07-01 16:29:55,542 - DEBUG - data_preprocessing.py:208 - 结果.shape:(6865066, 81)
2018-07-01 16:29:55,542 - DEBUG - data_preprocessing.py:209 - 耗时0.0001506805419921875
2018-07-01 16:30:13,877 - DEBUG - data_preprocessing.py:204 - data1.shape:(6865066, 81)
2018-07-01 16:30:13,877 - DEBUG - data_preprocessing.py:205 - data2.shape:(6865066, 20)
2018-07-01 16:30:21,596 - DEBUG - data_preprocessing.py:208 - 结果.shape:(6865066, 101)
2018-07-01 16:30:21,596 - DEBUG - data_preprocessing.py:209 - 耗时0.0001575946807861328
2018-07-01 16:30:21,705 - DEBUG - data_preprocessing.py:320 - Index(['C14', 'C17', 'C21', 'device_model', 'site_domain', 'one_day',
       'one_day_hour', 'day_hour_prev', 'day_hour_next', 'is_work_day',
       ...
       'exptv_C17C21', 'cnttv_C17C21', 'exptv_C17site_domain',
       'cnttv_C17site_domain', 'exptv_C21device_model',
       'cnttv_C21device_model', 'exptv_C21site_domain', 'cnttv_C21site_domain',
       'exptv_site_domaindevice_model', 'cnttv_site_domaindevice_model'],
      dtype='object', length=101)
2018-07-01 16:30:23,200 - DEBUG - data_preprocessing.py:204 - data1.shape:(4577464, 5)
2018-07-01 16:30:23,201 - DEBUG - data_preprocessing.py:205 - data2.shape:(4577464, 5)
2018-07-01 16:30:23,268 - DEBUG - data_preprocessing.py:208 - 结果.shape:(4577464, 10)
2018-07-01 16:30:23,268 - DEBUG - data_preprocessing.py:209 - 耗时0.000148773193359375
2018-07-01 16:30:36,215 - DEBUG - data_preprocessing.py:204 - data1.shape:(4577464, 10)
2018-07-01 16:30:36,215 - DEBUG - data_preprocessing.py:205 - data2.shape:(4577464, 60)
2018-07-01 16:30:37,620 - DEBUG - data_preprocessing.py:208 - 结果.shape:(4577464, 70)
2018-07-01 16:30:37,621 - DEBUG - data_preprocessing.py:209 - 耗时0.00015473365783691406
2018-07-01 16:30:40,467 - DEBUG - data_preprocessing.py:204 - data1.shape:(4577464, 70)
2018-07-01 16:30:40,467 - DEBUG - data_preprocessing.py:205 - data2.shape:(4577464, 11)
2018-07-01 16:30:44,861 - DEBUG - data_preprocessing.py:208 - 结果.shape:(4577464, 81)
2018-07-01 16:30:44,861 - DEBUG - data_preprocessing.py:209 - 耗时0.00015306472778320312
2018-07-01 16:30:57,067 - DEBUG - data_preprocessing.py:204 - data1.shape:(4577464, 81)
2018-07-01 16:30:57,067 - DEBUG - data_preprocessing.py:205 - data2.shape:(4577464, 20)
2018-07-01 16:31:02,223 - DEBUG - data_preprocessing.py:208 - 结果.shape:(4577464, 101)
2018-07-01 16:31:02,223 - DEBUG - data_preprocessing.py:209 - 耗时0.00014972686767578125
2018-07-01 16:31:02,294 - DEBUG - data_preprocessing.py:328 - (6865066, 101)
2018-07-01 16:31:02,295 - DEBUG - data_preprocessing.py:329 - (4577464, 101)
(6865066, 101)
Traceback (most recent call last):
  File "gbdt.py", line 188, in <module>
    done()
  File "gbdt.py", line 148, in done
    test_save.drop('click',axis=1,inplace=True)
  File "/home/zhijiehuang/anaconda3/lib/python3.6/site-packages/pandas/core/generic.py", line 2530, in drop
    obj = obj._drop_axis(labels, axis, level=level, errors=errors)
  File "/home/zhijiehuang/anaconda3/lib/python3.6/site-packages/pandas/core/generic.py", line 2562, in _drop_axis
    new_axis = axis.drop(labels, errors=errors)
  File "/home/zhijiehuang/anaconda3/lib/python3.6/site-packages/pandas/core/indexes/base.py", line 3744, in drop
    labels[mask])
ValueError: labels ['click'] not contained in axis
2018-07-01 16:32:27,458 - DEBUG - data_preprocessing.py:204 - data1.shape:(6865066, 5)
2018-07-01 16:32:27,458 - DEBUG - data_preprocessing.py:205 - data2.shape:(6865066, 5)
2018-07-01 16:32:27,760 - DEBUG - data_preprocessing.py:208 - 结果.shape:(6865066, 10)
2018-07-01 16:32:27,760 - DEBUG - data_preprocessing.py:209 - 耗时0.000148773193359375
2018-07-01 16:32:49,639 - DEBUG - data_preprocessing.py:204 - data1.shape:(6865066, 10)
2018-07-01 16:32:49,639 - DEBUG - data_preprocessing.py:205 - data2.shape:(6865066, 60)
2018-07-01 16:32:51,760 - DEBUG - data_preprocessing.py:208 - 结果.shape:(6865066, 70)
2018-07-01 16:32:51,760 - DEBUG - data_preprocessing.py:209 - 耗时0.0001494884490966797
2018-07-01 16:32:55,970 - DEBUG - data_preprocessing.py:204 - data1.shape:(6865066, 70)
2018-07-01 16:32:55,970 - DEBUG - data_preprocessing.py:205 - data2.shape:(6865066, 11)
2018-07-01 16:33:02,528 - DEBUG - data_preprocessing.py:208 - 结果.shape:(6865066, 81)
2018-07-01 16:33:02,528 - DEBUG - data_preprocessing.py:209 - 耗时0.00015687942504882812
2018-07-01 16:33:20,489 - DEBUG - data_preprocessing.py:204 - data1.shape:(6865066, 81)
2018-07-01 16:33:20,489 - DEBUG - data_preprocessing.py:205 - data2.shape:(6865066, 20)
2018-07-01 16:33:28,186 - DEBUG - data_preprocessing.py:208 - 结果.shape:(6865066, 101)
2018-07-01 16:33:28,186 - DEBUG - data_preprocessing.py:209 - 耗时0.00015425682067871094
2018-07-01 16:33:28,293 - DEBUG - data_preprocessing.py:320 - Index(['C14', 'C17', 'C21', 'device_model', 'site_domain', 'one_day',
       'one_day_hour', 'day_hour_prev', 'day_hour_next', 'is_work_day',
       ...
       'exptv_C17C21', 'cnttv_C17C21', 'exptv_C17site_domain',
       'cnttv_C17site_domain', 'exptv_C21device_model',
       'cnttv_C21device_model', 'exptv_C21site_domain', 'cnttv_C21site_domain',
       'exptv_site_domaindevice_model', 'cnttv_site_domaindevice_model'],
      dtype='object', length=101)
2018-07-01 16:33:29,763 - DEBUG - data_preprocessing.py:204 - data1.shape:(4577464, 5)
2018-07-01 16:33:29,763 - DEBUG - data_preprocessing.py:205 - data2.shape:(4577464, 5)
2018-07-01 16:33:29,826 - DEBUG - data_preprocessing.py:208 - 结果.shape:(4577464, 10)
2018-07-01 16:33:29,826 - DEBUG - data_preprocessing.py:209 - 耗时0.00015306472778320312
2018-07-01 16:33:42,566 - DEBUG - data_preprocessing.py:204 - data1.shape:(4577464, 10)
2018-07-01 16:33:42,566 - DEBUG - data_preprocessing.py:205 - data2.shape:(4577464, 60)
2018-07-01 16:33:43,973 - DEBUG - data_preprocessing.py:208 - 结果.shape:(4577464, 70)
2018-07-01 16:33:43,973 - DEBUG - data_preprocessing.py:209 - 耗时0.000156402587890625
2018-07-01 16:33:46,748 - DEBUG - data_preprocessing.py:204 - data1.shape:(4577464, 70)
2018-07-01 16:33:46,748 - DEBUG - data_preprocessing.py:205 - data2.shape:(4577464, 11)
2018-07-01 16:33:51,125 - DEBUG - data_preprocessing.py:208 - 结果.shape:(4577464, 81)
2018-07-01 16:33:51,125 - DEBUG - data_preprocessing.py:209 - 耗时0.00015854835510253906
2018-07-01 16:34:03,044 - DEBUG - data_preprocessing.py:204 - data1.shape:(4577464, 81)
2018-07-01 16:34:03,044 - DEBUG - data_preprocessing.py:205 - data2.shape:(4577464, 20)
2018-07-01 16:34:08,189 - DEBUG - data_preprocessing.py:208 - 结果.shape:(4577464, 101)
2018-07-01 16:34:08,189 - DEBUG - data_preprocessing.py:209 - 耗时0.0001544952392578125
2018-07-01 16:34:08,252 - DEBUG - data_preprocessing.py:328 - (6865066, 101)
2018-07-01 16:34:08,252 - DEBUG - data_preprocessing.py:329 - (4577464, 101)
[16:36:38] Tree method is selected to be 'approx'
[16:37:07] /home/zhijiehuang/github/xgboost/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 242 extra nodes, 0 pruned nodes, max_depth=7
[16:37:08] Tree method is selected to be 'approx'
[16:37:58] /home/zhijiehuang/github/xgboost/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 248 extra nodes, 0 pruned nodes, max_depth=7
[16:37:58] Tree method is selected to be 'approx'
[16:38:45] /home/zhijiehuang/github/xgboost/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 244 extra nodes, 0 pruned nodes, max_depth=7
[16:39:07] /home/zhijiehuang/github/xgboost/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 246 extra nodes, 0 pruned nodes, max_depth=7
[16:39:29] /home/zhijiehuang/github/xgboost/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 240 extra nodes, 0 pruned nodes, max_depth=7
[16:39:50] /home/zhijiehuang/github/xgboost/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 244 extra nodes, 0 pruned nodes, max_depth=7
[16:40:12] /home/zhijiehuang/github/xgboost/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 250 extra nodes, 0 pruned nodes, max_depth=7
[16:40:34] /home/zhijiehuang/github/xgboost/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 248 extra nodes, 0 pruned nodes, max_depth=7
[16:40:56] /home/zhijiehuang/github/xgboost/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 250 extra nodes, 0 pruned nodes, max_depth=7
[16:41:18] /home/zhijiehuang/github/xgboost/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 244 extra nodes, 0 pruned nodes, max_depth=7
[16:41:40] /home/zhijiehuang/github/xgboost/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 244 extra nodes, 0 pruned nodes, max_depth=7
[16:42:02] /home/zhijiehuang/github/xgboost/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 252 extra nodes, 0 pruned nodes, max_depth=7
[16:42:24] /home/zhijiehuang/github/xgboost/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 246 extra nodes, 0 pruned nodes, max_depth=7
[16:42:45] /home/zhijiehuang/github/xgboost/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 238 extra nodes, 0 pruned nodes, max_depth=7
[16:43:07] /home/zhijiehuang/github/xgboost/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 246 extra nodes, 0 pruned nodes, max_depth=7
[16:43:29] /home/zhijiehuang/github/xgboost/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 238 extra nodes, 0 pruned nodes, max_depth=7
[16:43:50] /home/zhijiehuang/github/xgboost/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 234 extra nodes, 0 pruned nodes, max_depth=7
[16:44:12] /home/zhijiehuang/github/xgboost/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 236 extra nodes, 0 pruned nodes, max_depth=7
[16:44:34] /home/zhijiehuang/github/xgboost/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 248 extra nodes, 0 pruned nodes, max_depth=7
[16:44:56] /home/zhijiehuang/github/xgboost/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 232 extra nodes, 0 pruned nodes, max_depth=7
[16:45:17] /home/zhijiehuang/github/xgboost/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 236 extra nodes, 0 pruned nodes, max_depth=7
[16:45:39] /home/zhijiehuang/github/xgboost/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 252 extra nodes, 0 pruned nodes, max_depth=7
[16:46:01] /home/zhijiehuang/github/xgboost/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 242 extra nodes, 0 pruned nodes, max_depth=7
[16:46:23] /home/zhijiehuang/github/xgboost/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 254 extra nodes, 0 pruned nodes, max_depth=7
[16:46:45] /home/zhijiehuang/github/xgboost/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 252 extra nodes, 0 pruned nodes, max_depth=7
[16:47:07] /home/zhijiehuang/github/xgboost/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 250 extra nodes, 0 pruned nodes, max_depth=7
[16:47:29] /home/zhijiehuang/github/xgboost/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 240 extra nodes, 0 pruned nodes, max_depth=7
[16:47:51] /home/zhijiehuang/github/xgboost/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 242 extra nodes, 0 pruned nodes, max_depth=7
[16:48:12] /home/zhijiehuang/github/xgboost/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 238 extra nodes, 0 pruned nodes, max_depth=7
[16:48:34] /home/zhijiehuang/github/xgboost/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 246 extra nodes, 0 pruned nodes, max_depth=7
[16:48:56] /home/zhijiehuang/github/xgboost/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 252 extra nodes, 0 pruned nodes, max_depth=7
[16:49:17] /home/zhijiehuang/github/xgboost/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 238 extra nodes, 0 pruned nodes, max_depth=7
[16:49:39] /home/zhijiehuang/github/xgboost/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 234 extra nodes, 0 pruned nodes, max_depth=7
[16:50:02] /home/zhijiehuang/github/xgboost/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 250 extra nodes, 0 pruned nodes, max_depth=7
[16:50:23] /home/zhijiehuang/github/xgboost/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 240 extra nodes, 0 pruned nodes, max_depth=7
[16:50:45] /home/zhijiehuang/github/xgboost/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 244 extra nodes, 0 pruned nodes, max_depth=7
[16:51:07] /home/zhijiehuang/github/xgboost/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 246 extra nodes, 0 pruned nodes, max_depth=7
[16:51:29] /home/zhijiehuang/github/xgboost/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 244 extra nodes, 0 pruned nodes, max_depth=7
[16:51:50] /home/zhijiehuang/github/xgboost/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 246 extra nodes, 0 pruned nodes, max_depth=7
[16:52:12] /home/zhijiehuang/github/xgboost/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 242 extra nodes, 0 pruned nodes, max_depth=7
[16:52:34] /home/zhijiehuang/github/xgboost/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 248 extra nodes, 0 pruned nodes, max_depth=7
[16:52:56] /home/zhijiehuang/github/xgboost/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 242 extra nodes, 0 pruned nodes, max_depth=7
[16:53:18] /home/zhijiehuang/github/xgboost/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 248 extra nodes, 0 pruned nodes, max_depth=7
[16:53:40] /home/zhijiehuang/github/xgboost/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 246 extra nodes, 0 pruned nodes, max_depth=7
[16:54:02] /home/zhijiehuang/github/xgboost/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 252 extra nodes, 0 pruned nodes, max_depth=7
[16:54:24] /home/zhijiehuang/github/xgboost/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 232 extra nodes, 0 pruned nodes, max_depth=7
[16:54:46] /home/zhijiehuang/github/xgboost/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 248 extra nodes, 0 pruned nodes, max_depth=7
[16:55:08] /home/zhijiehuang/github/xgboost/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 252 extra nodes, 0 pruned nodes, max_depth=7
[16:55:30] /home/zhijiehuang/github/xgboost/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 230 extra nodes, 0 pruned nodes, max_depth=7
[16:55:52] /home/zhijiehuang/github/xgboost/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 246 extra nodes, 0 pruned nodes, max_depth=7
[16:56:14] /home/zhijiehuang/github/xgboost/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 254 extra nodes, 0 pruned nodes, max_depth=7
[16:56:36] /home/zhijiehuang/github/xgboost/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 252 extra nodes, 0 pruned nodes, max_depth=7
[16:56:58] /home/zhijiehuang/github/xgboost/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 254 extra nodes, 0 pruned nodes, max_depth=7
[16:57:20] /home/zhijiehuang/github/xgboost/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 236 extra nodes, 0 pruned nodes, max_depth=7
[16:57:42] /home/zhijiehuang/github/xgboost/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 250 extra nodes, 0 pruned nodes, max_depth=7
[16:58:04] /home/zhijiehuang/github/xgboost/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 240 extra nodes, 0 pruned nodes, max_depth=7
[16:58:26] /home/zhijiehuang/github/xgboost/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 254 extra nodes, 0 pruned nodes, max_depth=7
[16:58:48] /home/zhijiehuang/github/xgboost/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 254 extra nodes, 0 pruned nodes, max_depth=7
[16:59:09] /home/zhijiehuang/github/xgboost/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 254 extra nodes, 0 pruned nodes, max_depth=7
[16:59:32] /home/zhijiehuang/github/xgboost/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 254 extra nodes, 0 pruned nodes, max_depth=7
[16:59:54] /home/zhijiehuang/github/xgboost/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 254 extra nodes, 0 pruned nodes, max_depth=7
[17:00:16] /home/zhijiehuang/github/xgboost/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 246 extra nodes, 0 pruned nodes, max_depth=7
[17:00:37] /home/zhijiehuang/github/xgboost/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 252 extra nodes, 0 pruned nodes, max_depth=7
[17:00:59] /home/zhijiehuang/github/xgboost/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 244 extra nodes, 0 pruned nodes, max_depth=7
[17:01:21] /home/zhijiehuang/github/xgboost/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 242 extra nodes, 0 pruned nodes, max_depth=7
[17:01:43] /home/zhijiehuang/github/xgboost/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 250 extra nodes, 0 pruned nodes, max_depth=7
[17:02:05] /home/zhijiehuang/github/xgboost/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 254 extra nodes, 0 pruned nodes, max_depth=7
[17:02:27] /home/zhijiehuang/github/xgboost/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 236 extra nodes, 0 pruned nodes, max_depth=7
[17:02:49] /home/zhijiehuang/github/xgboost/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 254 extra nodes, 0 pruned nodes, max_depth=7
[17:03:12] /home/zhijiehuang/github/xgboost/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 250 extra nodes, 0 pruned nodes, max_depth=7
[17:03:33] /home/zhijiehuang/github/xgboost/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 246 extra nodes, 0 pruned nodes, max_depth=7
[17:03:55] /home/zhijiehuang/github/xgboost/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 246 extra nodes, 0 pruned nodes, max_depth=7
[17:04:17] /home/zhijiehuang/github/xgboost/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 254 extra nodes, 0 pruned nodes, max_depth=7
[17:04:39] /home/zhijiehuang/github/xgboost/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 248 extra nodes, 0 pruned nodes, max_depth=7
[17:05:01] /home/zhijiehuang/github/xgboost/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 244 extra nodes, 0 pruned nodes, max_depth=7
[17:05:23] /home/zhijiehuang/github/xgboost/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 248 extra nodes, 0 pruned nodes, max_depth=7
[17:05:44] /home/zhijiehuang/github/xgboost/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 252 extra nodes, 0 pruned nodes, max_depth=7
[17:06:06] /home/zhijiehuang/github/xgboost/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 254 extra nodes, 0 pruned nodes, max_depth=7
[17:06:28] /home/zhijiehuang/github/xgboost/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 254 extra nodes, 0 pruned nodes, max_depth=7
[17:06:50] /home/zhijiehuang/github/xgboost/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 226 extra nodes, 0 pruned nodes, max_depth=7
[17:07:12] /home/zhijiehuang/github/xgboost/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 248 extra nodes, 0 pruned nodes, max_depth=7
[17:07:34] /home/zhijiehuang/github/xgboost/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 248 extra nodes, 0 pruned nodes, max_depth=7
[17:07:56] /home/zhijiehuang/github/xgboost/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 250 extra nodes, 0 pruned nodes, max_depth=7
[17:08:18] /home/zhijiehuang/github/xgboost/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 254 extra nodes, 0 pruned nodes, max_depth=7
[17:08:40] /home/zhijiehuang/github/xgboost/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 240 extra nodes, 0 pruned nodes, max_depth=7
[17:09:01] /home/zhijiehuang/github/xgboost/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 246 extra nodes, 0 pruned nodes, max_depth=7
[17:09:23] /home/zhijiehuang/github/xgboost/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 242 extra nodes, 0 pruned nodes, max_depth=7
[17:09:45] /home/zhijiehuang/github/xgboost/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 252 extra nodes, 0 pruned nodes, max_depth=7
[17:10:07] /home/zhijiehuang/github/xgboost/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 240 extra nodes, 0 pruned nodes, max_depth=7
[17:10:29] /home/zhijiehuang/github/xgboost/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 232 extra nodes, 0 pruned nodes, max_depth=7
[17:10:51] /home/zhijiehuang/github/xgboost/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 238 extra nodes, 0 pruned nodes, max_depth=7
[17:11:13] /home/zhijiehuang/github/xgboost/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 248 extra nodes, 0 pruned nodes, max_depth=7
[17:11:35] /home/zhijiehuang/github/xgboost/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 244 extra nodes, 0 pruned nodes, max_depth=7
[17:11:57] /home/zhijiehuang/github/xgboost/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 248 extra nodes, 0 pruned nodes, max_depth=7
[17:12:19] /home/zhijiehuang/github/xgboost/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 248 extra nodes, 0 pruned nodes, max_depth=7
[17:12:41] /home/zhijiehuang/github/xgboost/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 254 extra nodes, 0 pruned nodes, max_depth=7
[17:13:03] /home/zhijiehuang/github/xgboost/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 240 extra nodes, 0 pruned nodes, max_depth=7
[17:13:25] /home/zhijiehuang/github/xgboost/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 234 extra nodes, 0 pruned nodes, max_depth=7
[17:13:47] /home/zhijiehuang/github/xgboost/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 246 extra nodes, 0 pruned nodes, max_depth=7
[17:14:09] /home/zhijiehuang/github/xgboost/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 254 extra nodes, 0 pruned nodes, max_depth=7
[17:14:31] /home/zhijiehuang/github/xgboost/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 224 extra nodes, 0 pruned nodes, max_depth=7
[17:14:53] /home/zhijiehuang/github/xgboost/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 254 extra nodes, 0 pruned nodes, max_depth=7
[17:15:15] /home/zhijiehuang/github/xgboost/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 252 extra nodes, 0 pruned nodes, max_depth=7
[17:15:37] /home/zhijiehuang/github/xgboost/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 228 extra nodes, 0 pruned nodes, max_depth=7
[17:15:59] /home/zhijiehuang/github/xgboost/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 244 extra nodes, 0 pruned nodes, max_depth=7
[17:16:21] /home/zhijiehuang/github/xgboost/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 244 extra nodes, 0 pruned nodes, max_depth=7
[17:16:42] /home/zhijiehuang/github/xgboost/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 252 extra nodes, 0 pruned nodes, max_depth=7
[17:17:04] /home/zhijiehuang/github/xgboost/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 252 extra nodes, 0 pruned nodes, max_depth=7
[17:17:26] /home/zhijiehuang/github/xgboost/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 252 extra nodes, 0 pruned nodes, max_depth=7
[17:17:48] /home/zhijiehuang/github/xgboost/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 236 extra nodes, 0 pruned nodes, max_depth=7
[17:18:10] /home/zhijiehuang/github/xgboost/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 228 extra nodes, 0 pruned nodes, max_depth=7
[17:18:33] /home/zhijiehuang/github/xgboost/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 250 extra nodes, 0 pruned nodes, max_depth=7
[17:18:54] /home/zhijiehuang/github/xgboost/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 244 extra nodes, 0 pruned nodes, max_depth=7
[17:19:16] /home/zhijiehuang/github/xgboost/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 230 extra nodes, 0 pruned nodes, max_depth=7
[17:19:38] /home/zhijiehuang/github/xgboost/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 248 extra nodes, 0 pruned nodes, max_depth=7
[17:20:00] /home/zhijiehuang/github/xgboost/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 234 extra nodes, 0 pruned nodes, max_depth=7
[17:20:22] /home/zhijiehuang/github/xgboost/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 254 extra nodes, 0 pruned nodes, max_depth=7
[17:20:44] /home/zhijiehuang/github/xgboost/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 250 extra nodes, 0 pruned nodes, max_depth=7
[17:21:06] /home/zhijiehuang/github/xgboost/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 234 extra nodes, 0 pruned nodes, max_depth=7
[17:21:28] /home/zhijiehuang/github/xgboost/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 254 extra nodes, 0 pruned nodes, max_depth=7
[17:21:50] /home/zhijiehuang/github/xgboost/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 252 extra nodes, 0 pruned nodes, max_depth=7
2018-07-01 17:23:39,897 - DEBUG - data_preprocessing.py:204 - data1.shape:(6865066, 5)
2018-07-01 17:23:39,898 - DEBUG - data_preprocessing.py:205 - data2.shape:(6865066, 5)
2018-07-01 17:23:40,222 - DEBUG - data_preprocessing.py:208 - 结果.shape:(6865066, 10)
2018-07-01 17:23:40,222 - DEBUG - data_preprocessing.py:209 - 耗时0.00013637542724609375
2018-07-01 17:24:04,568 - DEBUG - data_preprocessing.py:204 - data1.shape:(6865066, 10)
2018-07-01 17:24:04,569 - DEBUG - data_preprocessing.py:205 - data2.shape:(6865066, 60)
2018-07-01 17:24:06,815 - DEBUG - data_preprocessing.py:208 - 结果.shape:(6865066, 70)
2018-07-01 17:24:06,815 - DEBUG - data_preprocessing.py:209 - 耗时0.00015044212341308594
2018-07-01 17:24:11,202 - DEBUG - data_preprocessing.py:204 - data1.shape:(6865066, 70)
2018-07-01 17:24:11,202 - DEBUG - data_preprocessing.py:205 - data2.shape:(6865066, 11)
2018-07-01 17:24:17,816 - DEBUG - data_preprocessing.py:208 - 结果.shape:(6865066, 81)
2018-07-01 17:24:17,816 - DEBUG - data_preprocessing.py:209 - 耗时0.00014662742614746094
2018-07-01 17:24:35,536 - DEBUG - data_preprocessing.py:204 - data1.shape:(6865066, 81)
2018-07-01 17:24:35,536 - DEBUG - data_preprocessing.py:205 - data2.shape:(6865066, 20)
2018-07-01 17:24:43,248 - DEBUG - data_preprocessing.py:208 - 结果.shape:(6865066, 101)
2018-07-01 17:24:43,248 - DEBUG - data_preprocessing.py:209 - 耗时0.00014495849609375
2018-07-01 17:24:43,353 - DEBUG - data_preprocessing.py:320 - Index(['C14', 'C17', 'C21', 'device_model', 'site_domain', 'one_day',
       'one_day_hour', 'day_hour_prev', 'day_hour_next', 'is_work_day',
       ...
       'exptv_C17C21', 'cnttv_C17C21', 'exptv_C17site_domain',
       'cnttv_C17site_domain', 'exptv_C21device_model',
       'cnttv_C21device_model', 'exptv_C21site_domain', 'cnttv_C21site_domain',
       'exptv_site_domaindevice_model', 'cnttv_site_domaindevice_model'],
      dtype='object', length=101)
2018-07-01 17:24:45,041 - DEBUG - data_preprocessing.py:204 - data1.shape:(4577464, 5)
2018-07-01 17:24:45,041 - DEBUG - data_preprocessing.py:205 - data2.shape:(4577464, 5)
2018-07-01 17:24:45,126 - DEBUG - data_preprocessing.py:208 - 结果.shape:(4577464, 10)
2018-07-01 17:24:45,126 - DEBUG - data_preprocessing.py:209 - 耗时0.00014019012451171875
2018-07-01 17:24:59,570 - DEBUG - data_preprocessing.py:204 - data1.shape:(4577464, 10)
2018-07-01 17:24:59,570 - DEBUG - data_preprocessing.py:205 - data2.shape:(4577464, 60)
2018-07-01 17:25:01,013 - DEBUG - data_preprocessing.py:208 - 结果.shape:(4577464, 70)
2018-07-01 17:25:01,013 - DEBUG - data_preprocessing.py:209 - 耗时0.00014829635620117188
2018-07-01 17:25:03,889 - DEBUG - data_preprocessing.py:204 - data1.shape:(4577464, 70)
2018-07-01 17:25:03,889 - DEBUG - data_preprocessing.py:205 - data2.shape:(4577464, 11)
2018-07-01 17:25:08,252 - DEBUG - data_preprocessing.py:208 - 结果.shape:(4577464, 81)
2018-07-01 17:25:08,252 - DEBUG - data_preprocessing.py:209 - 耗时0.00014543533325195312
2018-07-01 17:25:20,249 - DEBUG - data_preprocessing.py:204 - data1.shape:(4577464, 81)
2018-07-01 17:25:20,249 - DEBUG - data_preprocessing.py:205 - data2.shape:(4577464, 20)
2018-07-01 17:25:25,396 - DEBUG - data_preprocessing.py:208 - 结果.shape:(4577464, 101)
2018-07-01 17:25:25,396 - DEBUG - data_preprocessing.py:209 - 耗时0.00014972686767578125
2018-07-01 17:25:25,459 - DEBUG - data_preprocessing.py:328 - (6865066, 101)
2018-07-01 17:25:25,459 - DEBUG - data_preprocessing.py:329 - (4577464, 101)
[17:27:56] Tree method is selected to be 'approx'
[17:28:25] /home/zhijiehuang/github/xgboost/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 242 extra nodes, 0 pruned nodes, max_depth=7
[17:28:26] Tree method is selected to be 'approx'
[17:29:15] /home/zhijiehuang/github/xgboost/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 248 extra nodes, 0 pruned nodes, max_depth=7
[17:29:15] Tree method is selected to be 'approx'
[17:30:08] /home/zhijiehuang/github/xgboost/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 244 extra nodes, 0 pruned nodes, max_depth=7
[17:30:32] /home/zhijiehuang/github/xgboost/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 246 extra nodes, 0 pruned nodes, max_depth=7
[17:30:54] /home/zhijiehuang/github/xgboost/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 240 extra nodes, 0 pruned nodes, max_depth=7
[17:31:20] /home/zhijiehuang/github/xgboost/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 244 extra nodes, 0 pruned nodes, max_depth=7
[17:31:44] /home/zhijiehuang/github/xgboost/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 250 extra nodes, 0 pruned nodes, max_depth=7
[17:32:05] /home/zhijiehuang/github/xgboost/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 248 extra nodes, 0 pruned nodes, max_depth=7
[17:32:32] /home/zhijiehuang/github/xgboost/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 250 extra nodes, 0 pruned nodes, max_depth=7
[17:32:56] /home/zhijiehuang/github/xgboost/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 244 extra nodes, 0 pruned nodes, max_depth=7
[17:33:17] /home/zhijiehuang/github/xgboost/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 244 extra nodes, 0 pruned nodes, max_depth=7
[17:33:44] /home/zhijiehuang/github/xgboost/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 252 extra nodes, 0 pruned nodes, max_depth=7
[17:34:08] /home/zhijiehuang/github/xgboost/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 246 extra nodes, 0 pruned nodes, max_depth=7
[17:34:29] /home/zhijiehuang/github/xgboost/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 238 extra nodes, 0 pruned nodes, max_depth=7
[17:34:56] /home/zhijiehuang/github/xgboost/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 246 extra nodes, 0 pruned nodes, max_depth=7
[17:35:19] /home/zhijiehuang/github/xgboost/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 238 extra nodes, 0 pruned nodes, max_depth=7
[17:35:41] /home/zhijiehuang/github/xgboost/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 234 extra nodes, 0 pruned nodes, max_depth=7
[17:36:08] /home/zhijiehuang/github/xgboost/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 236 extra nodes, 0 pruned nodes, max_depth=7
[17:36:31] /home/zhijiehuang/github/xgboost/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 248 extra nodes, 0 pruned nodes, max_depth=7
[17:36:54] /home/zhijiehuang/github/xgboost/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 232 extra nodes, 0 pruned nodes, max_depth=7
[17:37:20] /home/zhijiehuang/github/xgboost/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 236 extra nodes, 0 pruned nodes, max_depth=7
[17:37:44] /home/zhijiehuang/github/xgboost/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 252 extra nodes, 0 pruned nodes, max_depth=7
